{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DrBC_module.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LydzytiM6cdF","executionInfo":{"status":"ok","timestamp":1616400629320,"user_tz":-480,"elapsed":19167,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}},"outputId":"b0fa6bed-180a-429f-d488-28b0d541caae"},"source":["import os\n","# import Google Drive 套件\n","from google.colab import drive\n","# 將自己的雲端硬碟掛載上去\n","drive.mount('/content/gdrive')\n","\n","os.chdir('./gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1')      # 檔案目錄"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UGQKYcEdVhVy"},"source":["os.chdir('./gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1')      # 檔案目錄"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"IZJ6L0KcVY7B","executionInfo":{"elapsed":1444049,"status":"ok","timestamp":1616223425932,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"b9cfc163-3669-446e-df56-fc0de0c653b7"},"source":["# import shutil\n","# copyPath = './gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1/train_data'\n","# pastePath = './train_data'\n","# shutil.copytree(copyPath, pastePath)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./train_data'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xfsPvIM577zq","executionInfo":{"elapsed":821,"status":"ok","timestamp":1616394089193,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"8ffef838-1a5b-439f-f008-2c0b441a9809"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Mar 22 06:21:28 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   64C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gckBsoD1fJ54"},"source":["# import sys\n","# sys.path.append('./gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_ZvBcSw6cdK","executionInfo":{"status":"ok","timestamp":1616400637950,"user_tz":-480,"elapsed":7258,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["import importlib\n","import random\n","import pickle\n","import logging\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import os\n","import time\n","import fun_cls as fc\n","import DrBC_modle as Dm\n","import function as func\n","from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KlsQGaWD6cdK"},"source":["# load train data"]},{"cell_type":"code","metadata":{"id":"rbGfqB2s6cdK","executionInfo":{"status":"ok","timestamp":1616400638622,"user_tz":-480,"elapsed":5757,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["# load data in trainDatas list\n","trainPath = './train_data/10000/'\n","trainFile = os.listdir(trainPath)\n","trainDatas = []\n","# for i in trainFile:\n","#     data = trainPath + i\n","#     with open(data, 'rb') as f:\n","#         trainDatas.append(pickle.load(f))\n","for i in trainFile:\n","    trainDatas.append(trainPath + i)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5Wsz7XgbZix","executionInfo":{"status":"ok","timestamp":1616400638625,"user_tz":-480,"elapsed":2067,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}},"outputId":"b923f691-ef75-434a-f7bf-0e762e854b45"},"source":["len(trainDatas)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["67"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"sjBvVtkO6cdL","executionInfo":{"status":"ok","timestamp":1616400638624,"user_tz":-480,"elapsed":2969,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["valid_size = 0.05\n","train, valid = train_test_split(trainDatas, test_size=valid_size)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YflXERo76cdL"},"source":["# module define"]},{"cell_type":"code","metadata":{"id":"GOJAjRV-6cdM","executionInfo":{"status":"ok","timestamp":1616400674538,"user_tz":-480,"elapsed":653,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["epochs = 100\n","lr = 0.001"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGpLIkgd6cdL","executionInfo":{"status":"ok","timestamp":1616400676212,"user_tz":-480,"elapsed":639,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}},"outputId":"39a049b7-86bc-4c40-df1e-08374566db68"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","DrBC_module = Dm.DrBC_module(Layer=5, device=device).to(device)\n","lossfun = Dm.lossf(device=device, testN=5000)\n","opt = torch.optim.Adam(DrBC_module.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n","device, len(list(DrBC_module.parameters()))"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(device(type='cuda', index=0), 38)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"MDpAo2ao6cdM","executionInfo":{"status":"ok","timestamp":1616400685489,"user_tz":-480,"elapsed":669,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["logger = func.create_logger('./loggers/', '5layer_logger_10000-2.txt')\n","#logger = func.create_logger('./gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1/loggers/', '5layer_logger_10000.txt')"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"tglaBfYo7dgh","executionInfo":{"status":"ok","timestamp":1616400683996,"user_tz":-480,"elapsed":780,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["# for i in logger.handlers:\n","#   logger.removeHandler(i)\n","# logger.handlers = []"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeTOTj_b2Y-g","executionInfo":{"status":"ok","timestamp":1616400691366,"user_tz":-480,"elapsed":639,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}}},"source":["train_loss = []\n","val_loss = []"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6M5kg3n46cdM","executionInfo":{"status":"ok","timestamp":1616400694122,"user_tz":-480,"elapsed":879,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"}},"outputId":"65da217a-a5cb-4d52-baad-7c05bdc879dd"},"source":["DrBC_module.load_state_dict(torch.load('./modules/DrBC_5Layer_10000.pt'))\n","#DrBC_module.load_state_dict(torch.load('./gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1/modules/5_layer_10000_point/DrBC_5Layer_10000.pt'))"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3gGn4F_06cdN","outputId":"91dc4578-09e9-43ba-f2c6-6c857beb56ff"},"source":["module_save_path = './modules/DrBC_5Layer_10000.pt'\n","loss_save_path = './modules/5Layers_loss.pickle'\n","# module_save_path = './gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1/modules/DrBC_5Layer_10000.pt'\n","# loss_save_path = './gdrive/MyDrive/Colab Notebooks/cheng_ta/hw1/modules/5Layers_loss.pickle'\n","\n","start = time.time()\n","logger.info('start at {}'.format(start))\n","\n","for epoch in range(1, epochs+1):\n","    logger.info('Epoch {}/{}'.format(epoch, epochs))\n","    logger.info('-' * 10)\n","    \n","    for phase in ['train', 'val']:\n","        if phase == 'train':\n","            DrBC_module.train(True)  # Set model to training mode\n","            running = train\n","        else:\n","            DrBC_module.train(False)  # Set model to evaluate mode\n","            running = valid\n","        ls = []\n","        \n","        for path in running:\n","            try:  \n","                with open(path, 'rb') as f:\n","                    G = pickle.load(f)\n","                output = DrBC_module(G)\n","                loss = lossfun(output, G.scoreList)\n","                if phase == 'train':\n","                    opt.zero_grad()\n","                    loss.backward()\n","                    opt.step()\n","                \n","                logger.info('{}:  {}/{}, loss:{}'.format(phase, epoch, epochs, loss.item()))\n","                ls.append(loss.item())\n","\n","            except Exception as e:\n","                logger.error(e, exc_info=True)\n","\n","        if phase == 'train':\n","            train_loss.append(ls)\n","\n","        elif phase == 'val':\n","            val_loss.append(ls)\n","        loss_dict = {'train':train_loss, 'val':val_loss}\n","        with open(loss_save_path, 'wb') as f:\n","            pickle.dump(loss_dict, f)\n","\n","    train_time = time.time() - start\n","    torch.save(DrBC_module.state_dict(), module_save_path)\n","    logger.info('train time {}, {}/{}'.format(train_time, epoch, epochs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-03-22 08:11:41,053 INFO start at 1616400701.05367\n","2021-03-22 08:11:41,055 INFO Epoch 1/100\n","2021-03-22 08:11:41,056 INFO ----------\n","2021-03-22 08:11:48,058 INFO train:  1/100, loss:49.01279830932617\n","2021-03-22 08:11:53,546 INFO train:  1/100, loss:49.01285171508789\n","2021-03-22 08:11:59,182 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:12:04,944 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:12:10,501 INFO train:  1/100, loss:49.01285171508789\n","2021-03-22 08:12:16,306 INFO train:  1/100, loss:49.01286315917969\n","2021-03-22 08:12:29,675 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:12:35,632 INFO train:  1/100, loss:49.0128059387207\n","2021-03-22 08:12:44,430 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:12:55,176 INFO train:  1/100, loss:49.01285934448242\n","2021-03-22 08:13:07,554 INFO train:  1/100, loss:49.01285171508789\n","2021-03-22 08:13:20,315 INFO train:  1/100, loss:49.01283264160156\n","2021-03-22 08:13:34,158 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:13:41,956 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:13:51,630 INFO train:  1/100, loss:49.01282501220703\n","2021-03-22 08:14:02,979 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:14:13,673 INFO train:  1/100, loss:49.01285171508789\n","2021-03-22 08:14:23,097 INFO train:  1/100, loss:49.01287841796875\n","2021-03-22 08:14:33,170 INFO train:  1/100, loss:49.0128059387207\n","2021-03-22 08:14:44,046 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:14:55,090 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:15:04,526 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:15:16,696 INFO train:  1/100, loss:49.01283645629883\n","2021-03-22 08:15:26,271 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:15:36,417 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:15:47,658 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:15:57,621 INFO train:  1/100, loss:49.012855529785156\n","2021-03-22 08:16:07,843 INFO train:  1/100, loss:49.01285934448242\n","2021-03-22 08:16:18,387 INFO train:  1/100, loss:49.0128059387207\n","2021-03-22 08:16:28,646 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:16:38,404 INFO train:  1/100, loss:49.01280212402344\n","2021-03-22 08:16:48,764 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:16:58,995 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:17:09,436 INFO train:  1/100, loss:49.01283264160156\n","2021-03-22 08:17:24,582 INFO train:  1/100, loss:49.01286697387695\n","2021-03-22 08:17:30,174 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:17:40,305 INFO train:  1/100, loss:49.01286697387695\n","2021-03-22 08:17:50,389 INFO train:  1/100, loss:49.01283264160156\n","2021-03-22 08:18:00,466 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:18:11,720 INFO train:  1/100, loss:49.01286697387695\n","2021-03-22 08:18:21,732 INFO train:  1/100, loss:49.01283264160156\n","2021-03-22 08:18:32,487 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:18:45,209 INFO train:  1/100, loss:49.01286315917969\n","2021-03-22 08:18:56,692 INFO train:  1/100, loss:49.01279830932617\n","2021-03-22 08:19:06,605 INFO train:  1/100, loss:49.01283264160156\n","2021-03-22 08:19:16,785 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:19:26,991 INFO train:  1/100, loss:49.012855529785156\n","2021-03-22 08:19:37,589 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:19:49,867 INFO train:  1/100, loss:49.01285171508789\n","2021-03-22 08:19:59,656 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:20:10,046 INFO train:  1/100, loss:49.01283645629883\n","2021-03-22 08:20:19,808 INFO train:  1/100, loss:49.01282501220703\n","2021-03-22 08:20:30,039 INFO train:  1/100, loss:49.012874603271484\n","2021-03-22 08:20:40,084 INFO train:  1/100, loss:49.01282501220703\n","2021-03-22 08:20:53,177 INFO train:  1/100, loss:49.01284408569336\n","2021-03-22 08:21:04,547 INFO train:  1/100, loss:49.01282501220703\n","2021-03-22 08:21:14,129 INFO train:  1/100, loss:49.012840270996094\n","2021-03-22 08:21:24,258 INFO train:  1/100, loss:49.01282501220703\n","2021-03-22 08:21:34,935 INFO train:  1/100, loss:49.0128059387207\n","2021-03-22 08:21:44,696 INFO train:  1/100, loss:49.01285934448242\n","2021-03-22 08:21:55,498 INFO train:  1/100, loss:49.01283645629883\n","2021-03-22 08:22:04,701 INFO train:  1/100, loss:49.01286697387695\n","2021-03-22 08:22:16,148 INFO train:  1/100, loss:49.01288986206055\n","2021-03-22 08:22:25,498 INFO val:  1/100, loss:49.01284408569336\n","2021-03-22 08:22:35,674 INFO val:  1/100, loss:49.0128059387207\n","2021-03-22 08:22:45,825 INFO val:  1/100, loss:49.01287078857422\n","2021-03-22 08:22:56,124 INFO val:  1/100, loss:49.012855529785156\n","2021-03-22 08:22:59,039 INFO train time 677.7297353744507, 1/100\n","2021-03-22 08:22:59,041 INFO Epoch 2/100\n","2021-03-22 08:22:59,045 INFO ----------\n","2021-03-22 08:23:10,944 INFO train:  2/100, loss:49.0128059387207\n","2021-03-22 08:23:19,843 INFO train:  2/100, loss:49.012813568115234\n","2021-03-22 08:23:35,094 INFO train:  2/100, loss:49.012874603271484\n","2021-03-22 08:23:42,775 INFO train:  2/100, loss:49.01285934448242\n","2021-03-22 08:23:55,436 INFO train:  2/100, loss:49.012813568115234\n","2021-03-22 08:24:02,377 INFO train:  2/100, loss:49.01285934448242\n","2021-03-22 08:24:11,730 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:24:23,411 INFO train:  2/100, loss:49.0128059387207\n","2021-03-22 08:24:32,720 INFO train:  2/100, loss:49.01280975341797\n","2021-03-22 08:24:43,513 INFO train:  2/100, loss:49.012855529785156\n","2021-03-22 08:24:53,916 INFO train:  2/100, loss:49.01280975341797\n","2021-03-22 08:25:04,879 INFO train:  2/100, loss:49.01283264160156\n","2021-03-22 08:25:15,211 INFO train:  2/100, loss:49.01279830932617\n","2021-03-22 08:25:26,793 INFO train:  2/100, loss:49.01286315917969\n","2021-03-22 08:25:37,360 INFO train:  2/100, loss:49.01286697387695\n","2021-03-22 08:25:48,250 INFO train:  2/100, loss:49.01285171508789\n","2021-03-22 08:25:59,748 INFO train:  2/100, loss:49.01279830932617\n","2021-03-22 08:26:10,738 INFO train:  2/100, loss:49.012855529785156\n","2021-03-22 08:26:21,979 INFO train:  2/100, loss:49.01282501220703\n","2021-03-22 08:26:31,839 INFO train:  2/100, loss:49.012840270996094\n","2021-03-22 08:26:45,410 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:26:56,826 INFO train:  2/100, loss:49.012847900390625\n","2021-03-22 08:27:11,525 INFO train:  2/100, loss:49.01283264160156\n","2021-03-22 08:27:17,625 INFO train:  2/100, loss:49.01285171508789\n","2021-03-22 08:27:28,376 INFO train:  2/100, loss:49.01282501220703\n","2021-03-22 08:27:38,861 INFO train:  2/100, loss:49.01286697387695\n","2021-03-22 08:27:48,359 INFO train:  2/100, loss:49.012847900390625\n","2021-03-22 08:28:00,752 INFO train:  2/100, loss:49.01285934448242\n","2021-03-22 08:28:15,136 INFO train:  2/100, loss:49.012840270996094\n","2021-03-22 08:28:21,172 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:28:32,145 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:28:41,333 INFO train:  2/100, loss:49.012840270996094\n","2021-03-22 08:28:51,349 INFO train:  2/100, loss:49.0128059387207\n","2021-03-22 08:29:04,047 INFO train:  2/100, loss:49.01282501220703\n","2021-03-22 08:29:13,277 INFO train:  2/100, loss:49.01287841796875\n","2021-03-22 08:29:23,779 INFO train:  2/100, loss:49.01285934448242\n","2021-03-22 08:29:34,355 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:29:45,277 INFO train:  2/100, loss:49.01279830932617\n","2021-03-22 08:29:56,832 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:30:06,454 INFO train:  2/100, loss:49.01285934448242\n","2021-03-22 08:30:16,729 INFO train:  2/100, loss:49.01286697387695\n","2021-03-22 08:30:27,752 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:30:39,368 INFO train:  2/100, loss:49.01286315917969\n","2021-03-22 08:30:49,469 INFO train:  2/100, loss:49.0128288269043\n","2021-03-22 08:31:04,245 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:31:12,281 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:31:21,595 INFO train:  2/100, loss:49.01283264160156\n","2021-03-22 08:31:31,451 INFO train:  2/100, loss:49.0128288269043\n","2021-03-22 08:31:41,923 INFO train:  2/100, loss:49.01284408569336\n","2021-03-22 08:31:52,966 INFO train:  2/100, loss:49.012855529785156\n","2021-03-22 08:32:04,099 INFO train:  2/100, loss:49.012855529785156\n","2021-03-22 08:32:13,009 INFO train:  2/100, loss:49.0128059387207\n","2021-03-22 08:32:25,461 INFO train:  2/100, loss:49.01283264160156\n","2021-03-22 08:32:35,126 INFO train:  2/100, loss:49.01282501220703\n","2021-03-22 08:32:44,687 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:32:54,401 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:33:06,339 INFO train:  2/100, loss:49.0128173828125\n","2021-03-22 08:33:14,897 INFO train:  2/100, loss:49.0128059387207\n","2021-03-22 08:33:25,917 INFO train:  2/100, loss:49.012855529785156\n","2021-03-22 08:33:38,350 INFO train:  2/100, loss:49.012840270996094\n","2021-03-22 08:33:46,084 INFO train:  2/100, loss:49.01282501220703\n","2021-03-22 08:33:59,146 INFO train:  2/100, loss:49.0128288269043\n","2021-03-22 08:34:07,610 INFO train:  2/100, loss:49.01277542114258\n","2021-03-22 08:34:16,321 INFO val:  2/100, loss:49.012855529785156\n","2021-03-22 08:34:32,758 INFO val:  2/100, loss:49.01285934448242\n","2021-03-22 08:34:38,758 INFO val:  2/100, loss:49.01275634765625\n","2021-03-22 08:34:50,082 INFO val:  2/100, loss:49.0128173828125\n","2021-03-22 08:34:51,494 INFO train time 1390.2087700366974, 2/100\n","2021-03-22 08:34:51,496 INFO Epoch 3/100\n","2021-03-22 08:34:51,502 INFO ----------\n","2021-03-22 08:35:03,402 INFO train:  3/100, loss:49.01280975341797\n","2021-03-22 08:35:15,437 INFO train:  3/100, loss:49.01287078857422\n","2021-03-22 08:35:22,247 INFO train:  3/100, loss:49.01287078857422\n","2021-03-22 08:35:33,702 INFO train:  3/100, loss:49.012840270996094\n","2021-03-22 08:35:42,798 INFO train:  3/100, loss:49.01283645629883\n","2021-03-22 08:35:54,428 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:36:04,672 INFO train:  3/100, loss:49.012882232666016\n","2021-03-22 08:36:16,407 INFO train:  3/100, loss:49.012821197509766\n","2021-03-22 08:36:27,770 INFO train:  3/100, loss:49.012840270996094\n","2021-03-22 08:36:39,541 INFO train:  3/100, loss:49.012847900390625\n","2021-03-22 08:36:48,975 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:37:03,689 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:37:13,722 INFO train:  3/100, loss:49.01279830932617\n","2021-03-22 08:37:24,618 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:37:36,539 INFO train:  3/100, loss:49.01282501220703\n","2021-03-22 08:37:50,276 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:37:59,360 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:38:07,915 INFO train:  3/100, loss:49.01286697387695\n","2021-03-22 08:38:19,762 INFO train:  3/100, loss:49.0128173828125\n","2021-03-22 08:38:32,742 INFO train:  3/100, loss:49.01286697387695\n","2021-03-22 08:38:39,793 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:38:50,582 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:39:00,518 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:39:12,537 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:39:22,581 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:39:32,595 INFO train:  3/100, loss:49.012760162353516\n","2021-03-22 08:39:43,882 INFO train:  3/100, loss:49.01283264160156\n","2021-03-22 08:39:53,548 INFO train:  3/100, loss:49.01283264160156\n","2021-03-22 08:40:03,988 INFO train:  3/100, loss:49.0128059387207\n","2021-03-22 08:40:14,114 INFO train:  3/100, loss:49.01283264160156\n","2021-03-22 08:40:24,678 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:40:35,280 INFO train:  3/100, loss:49.012821197509766\n","2021-03-22 08:40:45,263 INFO train:  3/100, loss:49.012874603271484\n","2021-03-22 08:40:56,074 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:41:06,638 INFO train:  3/100, loss:49.0128173828125\n","2021-03-22 08:41:18,516 INFO train:  3/100, loss:49.012847900390625\n","2021-03-22 08:41:32,590 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:41:39,630 INFO train:  3/100, loss:49.012840270996094\n","2021-03-22 08:41:47,933 INFO train:  3/100, loss:49.0128288269043\n","2021-03-22 08:41:58,341 INFO train:  3/100, loss:49.01283264160156\n","2021-03-22 08:42:10,783 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:42:18,911 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:42:29,953 INFO train:  3/100, loss:49.01278305053711\n","2021-03-22 08:42:39,755 INFO train:  3/100, loss:49.01279830932617\n","2021-03-22 08:42:49,334 INFO train:  3/100, loss:49.012847900390625\n","2021-03-22 08:43:02,896 INFO train:  3/100, loss:49.012855529785156\n","2021-03-22 08:43:15,886 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:43:24,890 INFO train:  3/100, loss:49.01282501220703\n","2021-03-22 08:43:35,593 INFO train:  3/100, loss:49.012760162353516\n","2021-03-22 08:43:46,560 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:43:57,856 INFO train:  3/100, loss:49.01284408569336\n","2021-03-22 08:44:06,383 INFO train:  3/100, loss:49.01279067993164\n","2021-03-22 08:44:15,994 INFO train:  3/100, loss:49.01287841796875\n","2021-03-22 08:44:27,552 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:44:37,620 INFO train:  3/100, loss:49.01268768310547\n","2021-03-22 08:44:49,432 INFO train:  3/100, loss:49.01285934448242\n","2021-03-22 08:45:00,162 INFO train:  3/100, loss:49.01278305053711\n","2021-03-22 08:45:10,559 INFO train:  3/100, loss:49.01285171508789\n","2021-03-22 08:45:20,787 INFO train:  3/100, loss:49.012794494628906\n","2021-03-22 08:45:30,571 INFO train:  3/100, loss:49.01280975341797\n","2021-03-22 08:45:41,049 INFO train:  3/100, loss:49.01283264160156\n","2021-03-22 08:45:53,312 INFO train:  3/100, loss:49.01282501220703\n","2021-03-22 08:46:02,374 INFO train:  3/100, loss:49.012813568115234\n","2021-03-22 08:46:12,476 INFO val:  3/100, loss:49.0128059387207\n","2021-03-22 08:46:22,571 INFO val:  3/100, loss:49.012847900390625\n","2021-03-22 08:46:34,148 INFO val:  3/100, loss:49.012840270996094\n","2021-03-22 08:46:43,516 INFO val:  3/100, loss:49.01287841796875\n","2021-03-22 08:46:45,062 INFO train time 2103.800654888153, 3/100\n","2021-03-22 08:46:45,064 INFO Epoch 4/100\n","2021-03-22 08:46:45,069 INFO ----------\n","2021-03-22 08:46:53,846 INFO train:  4/100, loss:49.012699127197266\n","2021-03-22 08:47:04,039 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:47:13,884 INFO train:  4/100, loss:49.01285934448242\n","2021-03-22 08:47:27,422 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:47:34,414 INFO train:  4/100, loss:49.01283264160156\n","2021-03-22 08:47:46,301 INFO train:  4/100, loss:49.012874603271484\n","2021-03-22 08:47:55,553 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:48:07,969 INFO train:  4/100, loss:49.012874603271484\n","2021-03-22 08:48:17,810 INFO train:  4/100, loss:49.0128173828125\n","2021-03-22 08:48:31,712 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:48:38,577 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:48:48,793 INFO train:  4/100, loss:49.01285934448242\n","2021-03-22 08:49:02,862 INFO train:  4/100, loss:49.012752532958984\n","2021-03-22 08:49:08,771 INFO train:  4/100, loss:49.01286315917969\n","2021-03-22 08:49:20,177 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:49:35,325 INFO train:  4/100, loss:49.01283645629883\n","2021-03-22 08:49:40,951 INFO train:  4/100, loss:49.012855529785156\n","2021-03-22 08:49:52,430 INFO train:  4/100, loss:49.012855529785156\n","2021-03-22 08:50:06,464 INFO train:  4/100, loss:49.01278305053711\n","2021-03-22 08:50:13,784 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:50:23,323 INFO train:  4/100, loss:49.01285171508789\n","2021-03-22 08:50:37,418 INFO train:  4/100, loss:49.01285171508789\n","2021-03-22 08:50:43,639 INFO train:  4/100, loss:49.0128288269043\n","2021-03-22 08:50:54,810 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:51:04,378 INFO train:  4/100, loss:49.01275634765625\n","2021-03-22 08:51:15,779 INFO train:  4/100, loss:49.01282501220703\n","2021-03-22 08:51:27,131 INFO train:  4/100, loss:49.01278305053711\n","2021-03-22 08:51:37,320 INFO train:  4/100, loss:49.01287078857422\n","2021-03-22 08:51:47,497 INFO train:  4/100, loss:49.0128173828125\n","2021-03-22 08:52:01,419 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:52:08,847 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:52:18,899 INFO train:  4/100, loss:49.01285171508789\n","2021-03-22 08:52:28,944 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:52:41,272 INFO train:  4/100, loss:49.01285934448242\n","2021-03-22 08:52:50,037 INFO train:  4/100, loss:49.01287841796875\n","2021-03-22 08:52:59,951 INFO train:  4/100, loss:49.01285934448242\n","2021-03-22 08:53:12,173 INFO train:  4/100, loss:49.012813568115234\n","2021-03-22 08:53:21,883 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:53:33,469 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:53:44,690 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:53:54,789 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:54:06,124 INFO train:  4/100, loss:49.01285934448242\n","2021-03-22 08:54:15,332 INFO train:  4/100, loss:49.0128173828125\n","2021-03-22 08:54:25,893 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:54:37,134 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:54:47,408 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:54:57,011 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:55:09,877 INFO train:  4/100, loss:49.01283264160156\n","2021-03-22 08:55:18,573 INFO train:  4/100, loss:49.01282501220703\n","2021-03-22 08:55:28,800 INFO train:  4/100, loss:49.01283264160156\n","2021-03-22 08:55:39,956 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:55:50,915 INFO train:  4/100, loss:49.01277542114258\n","2021-03-22 08:56:02,479 INFO train:  4/100, loss:49.01278305053711\n","2021-03-22 08:56:13,412 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:56:28,897 INFO train:  4/100, loss:49.0128173828125\n","2021-03-22 08:56:34,857 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:56:45,450 INFO train:  4/100, loss:49.01278305053711\n","2021-03-22 08:57:00,955 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:57:08,354 INFO train:  4/100, loss:49.01280212402344\n","2021-03-22 08:57:18,610 INFO train:  4/100, loss:49.012840270996094\n","2021-03-22 08:57:28,827 INFO train:  4/100, loss:49.01286697387695\n","2021-03-22 08:57:39,295 INFO train:  4/100, loss:49.01284408569336\n","2021-03-22 08:57:50,268 INFO train:  4/100, loss:49.012821197509766\n","2021-03-22 08:58:04,980 INFO val:  4/100, loss:49.01280975341797\n","2021-03-22 08:58:13,025 INFO val:  4/100, loss:49.01287078857422\n","2021-03-22 08:58:23,263 INFO val:  4/100, loss:49.01284408569336\n","2021-03-22 08:58:35,446 INFO val:  4/100, loss:49.01285934448242\n","2021-03-22 08:58:36,610 INFO train time 2814.40154671669, 4/100\n","2021-03-22 08:58:36,612 INFO Epoch 5/100\n","2021-03-22 08:58:36,619 INFO ----------\n","2021-03-22 08:58:49,835 INFO train:  5/100, loss:49.01279830932617\n","2021-03-22 08:59:01,399 INFO train:  5/100, loss:49.01283264160156\n","2021-03-22 08:59:15,345 INFO train:  5/100, loss:49.012821197509766\n","2021-03-22 08:59:22,818 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 08:59:34,272 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 08:59:43,697 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 08:59:54,789 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 09:00:06,515 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:00:17,226 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 09:00:26,862 INFO train:  5/100, loss:49.012855529785156\n","2021-03-22 09:00:37,922 INFO train:  5/100, loss:49.012821197509766\n","2021-03-22 09:00:47,505 INFO train:  5/100, loss:49.01286697387695\n","2021-03-22 09:00:59,978 INFO train:  5/100, loss:49.012840270996094\n","2021-03-22 09:01:08,918 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 09:01:19,926 INFO train:  5/100, loss:49.012786865234375\n","2021-03-22 09:01:33,160 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 09:01:40,859 INFO train:  5/100, loss:49.01283645629883\n","2021-03-22 09:01:51,613 INFO train:  5/100, loss:49.012840270996094\n","2021-03-22 09:02:02,263 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:02:13,656 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:02:23,548 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 09:02:34,903 INFO train:  5/100, loss:49.012847900390625\n","2021-03-22 09:02:45,966 INFO train:  5/100, loss:49.01280212402344\n","2021-03-22 09:02:55,407 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:03:06,268 INFO train:  5/100, loss:49.0128173828125\n","2021-03-22 09:03:15,980 INFO train:  5/100, loss:49.01280212402344\n","2021-03-22 09:03:26,491 INFO train:  5/100, loss:49.0128288269043\n","2021-03-22 09:03:39,537 INFO train:  5/100, loss:49.012847900390625\n","2021-03-22 09:03:50,488 INFO train:  5/100, loss:49.0128059387207\n","2021-03-22 09:04:03,642 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:04:11,925 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:04:20,712 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 09:04:32,473 INFO train:  5/100, loss:49.01280212402344\n","2021-03-22 09:04:42,096 INFO train:  5/100, loss:49.01283645629883\n","2021-03-22 09:04:56,279 INFO train:  5/100, loss:49.012882232666016\n","2021-03-22 09:05:04,686 INFO train:  5/100, loss:49.012855529785156\n","2021-03-22 09:05:15,767 INFO train:  5/100, loss:49.0128173828125\n","2021-03-22 09:05:25,520 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:05:36,712 INFO train:  5/100, loss:49.01286697387695\n","2021-03-22 09:05:46,502 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:05:56,730 INFO train:  5/100, loss:49.01275634765625\n","2021-03-22 09:06:09,855 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 09:06:19,491 INFO train:  5/100, loss:49.01283264160156\n","2021-03-22 09:06:29,488 INFO train:  5/100, loss:49.01287078857422\n","2021-03-22 09:06:42,185 INFO train:  5/100, loss:49.01284408569336\n","2021-03-22 09:06:51,941 INFO train:  5/100, loss:49.01285934448242\n","2021-03-22 09:07:03,731 INFO train:  5/100, loss:49.01285934448242\n","2021-03-22 09:07:13,226 INFO train:  5/100, loss:49.01286697387695\n","2021-03-22 09:07:23,936 INFO train:  5/100, loss:49.012847900390625\n","2021-03-22 09:07:36,637 INFO train:  5/100, loss:49.0128059387207\n","2021-03-22 09:07:45,619 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:07:57,287 INFO train:  5/100, loss:49.01285934448242\n","2021-03-22 09:08:06,785 INFO train:  5/100, loss:49.01279067993164\n","2021-03-22 09:08:17,912 INFO train:  5/100, loss:49.012847900390625\n","2021-03-22 09:08:27,971 INFO train:  5/100, loss:49.01282501220703\n","2021-03-22 09:08:38,543 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:08:49,551 INFO train:  5/100, loss:49.01286697387695\n","2021-03-22 09:09:02,845 INFO train:  5/100, loss:49.01285934448242\n","2021-03-22 09:09:15,929 INFO train:  5/100, loss:49.012874603271484\n","2021-03-22 09:09:23,852 INFO train:  5/100, loss:49.012840270996094\n","2021-03-22 09:09:33,192 INFO train:  5/100, loss:49.01287841796875\n","2021-03-22 09:09:46,803 INFO train:  5/100, loss:49.01285171508789\n","2021-03-22 09:09:54,499 INFO train:  5/100, loss:49.012821197509766\n","2021-03-22 09:10:08,583 INFO val:  5/100, loss:49.012840270996094\n","2021-03-22 09:10:20,700 INFO val:  5/100, loss:49.01286697387695\n","2021-03-22 09:10:33,071 INFO val:  5/100, loss:49.01286697387695\n","2021-03-22 09:10:39,325 INFO val:  5/100, loss:49.012847900390625\n","2021-03-22 09:10:41,452 INFO train time 3540.1636004447937, 5/100\n","2021-03-22 09:10:41,454 INFO Epoch 6/100\n","2021-03-22 09:10:41,458 INFO ----------\n","2021-03-22 09:10:50,595 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:10:59,763 INFO train:  6/100, loss:49.01283645629883\n","2021-03-22 09:11:11,273 INFO train:  6/100, loss:49.0128059387207\n","2021-03-22 09:11:21,025 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:11:32,447 INFO train:  6/100, loss:49.012847900390625\n","2021-03-22 09:11:42,170 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:11:53,583 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:12:02,494 INFO train:  6/100, loss:49.01278305053711\n","2021-03-22 09:12:14,182 INFO train:  6/100, loss:49.01286697387695\n","2021-03-22 09:12:26,650 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:12:36,803 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:12:47,216 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:12:56,385 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:13:07,446 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:13:17,676 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:13:32,007 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:13:37,887 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:13:47,870 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:13:58,779 INFO train:  6/100, loss:49.01287841796875\n","2021-03-22 09:14:08,894 INFO train:  6/100, loss:49.012855529785156\n","2021-03-22 09:14:20,296 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:14:33,776 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:14:43,267 INFO train:  6/100, loss:49.01274871826172\n","2021-03-22 09:14:50,418 INFO train:  6/100, loss:49.01285171508789\n","2021-03-22 09:15:01,660 INFO train:  6/100, loss:49.0128059387207\n","2021-03-22 09:15:11,556 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:15:21,268 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:15:31,868 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:15:44,042 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:15:55,433 INFO train:  6/100, loss:49.012855529785156\n","2021-03-22 09:16:04,370 INFO train:  6/100, loss:49.01280975341797\n","2021-03-22 09:16:15,673 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:16:25,241 INFO train:  6/100, loss:49.01285171508789\n","2021-03-22 09:16:35,769 INFO train:  6/100, loss:49.0128288269043\n","2021-03-22 09:16:47,983 INFO train:  6/100, loss:49.01288986206055\n","2021-03-22 09:16:55,883 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:17:05,466 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:17:15,781 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:17:29,474 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:17:37,869 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:17:51,067 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:18:00,199 INFO train:  6/100, loss:49.01287841796875\n","2021-03-22 09:18:11,013 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:18:22,917 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:18:33,892 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:18:44,411 INFO train:  6/100, loss:49.01286697387695\n","2021-03-22 09:18:54,170 INFO train:  6/100, loss:49.0128173828125\n","2021-03-22 09:19:04,055 INFO train:  6/100, loss:49.0128059387207\n","2021-03-22 09:19:16,034 INFO train:  6/100, loss:49.01285934448242\n","2021-03-22 09:19:24,391 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:19:35,886 INFO train:  6/100, loss:49.01286697387695\n","2021-03-22 09:19:45,407 INFO train:  6/100, loss:49.012813568115234\n","2021-03-22 09:19:57,180 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:20:07,693 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:20:18,095 INFO train:  6/100, loss:49.0128173828125\n","2021-03-22 09:20:28,475 INFO train:  6/100, loss:49.01284408569336\n","2021-03-22 09:20:39,551 INFO train:  6/100, loss:49.0128173828125\n","2021-03-22 09:20:48,939 INFO train:  6/100, loss:49.01286315917969\n","2021-03-22 09:21:03,369 INFO train:  6/100, loss:49.012847900390625\n","2021-03-22 09:21:09,933 INFO train:  6/100, loss:49.012855529785156\n","2021-03-22 09:21:21,597 INFO train:  6/100, loss:49.012840270996094\n","2021-03-22 09:21:30,993 INFO train:  6/100, loss:49.01282501220703\n","2021-03-22 09:21:42,624 INFO train:  6/100, loss:49.01283264160156\n","2021-03-22 09:21:52,055 INFO val:  6/100, loss:49.01285934448242\n","2021-03-22 09:22:01,870 INFO val:  6/100, loss:49.01285934448242\n","2021-03-22 09:22:13,850 INFO val:  6/100, loss:49.01285934448242\n","2021-03-22 09:22:23,402 INFO val:  6/100, loss:49.012813568115234\n","2021-03-22 09:22:25,515 INFO train time 4244.190140008926, 6/100\n","2021-03-22 09:22:25,517 INFO Epoch 7/100\n","2021-03-22 09:22:25,522 INFO ----------\n","2021-03-22 09:22:33,361 INFO train:  7/100, loss:49.012882232666016\n","2021-03-22 09:22:44,233 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:22:55,157 INFO train:  7/100, loss:49.01286315917969\n","2021-03-22 09:23:09,866 INFO train:  7/100, loss:49.01280212402344\n","2021-03-22 09:23:18,084 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:23:30,066 INFO train:  7/100, loss:49.01285934448242\n","2021-03-22 09:23:38,974 INFO train:  7/100, loss:49.01285934448242\n","2021-03-22 09:23:51,474 INFO train:  7/100, loss:49.01279830932617\n","2021-03-22 09:24:00,934 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:24:10,489 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:24:21,766 INFO train:  7/100, loss:49.01284408569336\n","2021-03-22 09:24:33,635 INFO train:  7/100, loss:49.01280975341797\n","2021-03-22 09:24:42,505 INFO train:  7/100, loss:49.01282501220703\n","2021-03-22 09:24:52,913 INFO train:  7/100, loss:49.012874603271484\n","2021-03-22 09:25:04,119 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:25:14,598 INFO train:  7/100, loss:49.01284408569336\n","2021-03-22 09:25:27,332 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:25:36,755 INFO train:  7/100, loss:49.01287841796875\n","2021-03-22 09:25:46,913 INFO train:  7/100, loss:49.01283264160156\n","2021-03-22 09:25:58,438 INFO train:  7/100, loss:49.01286315917969\n","2021-03-22 09:26:07,505 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:26:18,408 INFO train:  7/100, loss:49.01286315917969\n","2021-03-22 09:26:29,192 INFO train:  7/100, loss:49.01279830932617\n","2021-03-22 09:26:40,513 INFO train:  7/100, loss:49.01283645629883\n","2021-03-22 09:26:50,509 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:27:02,268 INFO train:  7/100, loss:49.01282501220703\n","2021-03-22 09:27:12,166 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:27:23,534 INFO train:  7/100, loss:49.012821197509766\n","2021-03-22 09:27:34,364 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:27:45,695 INFO train:  7/100, loss:49.012821197509766\n","2021-03-22 09:27:54,577 INFO train:  7/100, loss:49.01284408569336\n","2021-03-22 09:28:05,440 INFO train:  7/100, loss:49.0128059387207\n","2021-03-22 09:28:15,352 INFO train:  7/100, loss:49.01285934448242\n","2021-03-22 09:28:26,276 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:28:36,356 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:28:48,097 INFO train:  7/100, loss:49.01283645629883\n","2021-03-22 09:28:57,750 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:29:08,665 INFO train:  7/100, loss:49.0128288269043\n","2021-03-22 09:29:17,775 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:29:27,978 INFO train:  7/100, loss:49.01285934448242\n","2021-03-22 09:29:39,735 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:29:49,244 INFO train:  7/100, loss:49.0128059387207\n","2021-03-22 09:30:00,876 INFO train:  7/100, loss:49.012855529785156\n","2021-03-22 09:30:10,970 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:30:20,811 INFO train:  7/100, loss:49.01282501220703\n","2021-03-22 09:30:33,746 INFO train:  7/100, loss:49.01280975341797\n","2021-03-22 09:30:43,426 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:30:52,903 INFO train:  7/100, loss:49.01286697387695\n","2021-03-22 09:31:04,311 INFO train:  7/100, loss:49.01280975341797\n","2021-03-22 09:31:14,743 INFO train:  7/100, loss:49.01287078857422\n","2021-03-22 09:31:25,584 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:31:39,675 INFO train:  7/100, loss:49.01285934448242\n","2021-03-22 09:31:46,644 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:31:57,843 INFO train:  7/100, loss:49.01283264160156\n","2021-03-22 09:32:08,611 INFO train:  7/100, loss:49.0128173828125\n","2021-03-22 09:32:18,755 INFO train:  7/100, loss:49.012840270996094\n","2021-03-22 09:32:31,886 INFO train:  7/100, loss:49.012874603271484\n","2021-03-22 09:32:39,935 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:32:51,963 INFO train:  7/100, loss:49.01285171508789\n","2021-03-22 09:33:00,835 INFO train:  7/100, loss:49.01284408569336\n","2021-03-22 09:33:12,328 INFO train:  7/100, loss:49.01286697387695\n","2021-03-22 09:33:23,270 INFO train:  7/100, loss:49.01284408569336\n","2021-03-22 09:33:34,344 INFO train:  7/100, loss:49.01280975341797\n","2021-03-22 09:33:42,914 INFO val:  7/100, loss:49.01285171508789\n","2021-03-22 09:33:55,447 INFO val:  7/100, loss:49.01287078857422\n","2021-03-22 09:34:05,119 INFO val:  7/100, loss:49.012794494628906\n","2021-03-22 09:34:17,317 INFO val:  7/100, loss:49.01283264160156\n","2021-03-22 09:34:18,125 INFO train time 4956.277936935425, 7/100\n","2021-03-22 09:34:18,126 INFO Epoch 8/100\n","2021-03-22 09:34:18,131 INFO ----------\n","2021-03-22 09:34:33,165 INFO train:  8/100, loss:49.01274490356445\n","2021-03-22 09:34:40,186 INFO train:  8/100, loss:49.01284408569336\n","2021-03-22 09:34:52,261 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:35:00,829 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:35:11,553 INFO train:  8/100, loss:49.01286315917969\n","2021-03-22 09:35:21,734 INFO train:  8/100, loss:49.01283645629883\n","2021-03-22 09:35:33,968 INFO train:  8/100, loss:49.012855529785156\n","2021-03-22 09:35:45,624 INFO train:  8/100, loss:49.012882232666016\n","2021-03-22 09:35:55,674 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:36:06,967 INFO train:  8/100, loss:49.012855529785156\n","2021-03-22 09:36:16,758 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:36:27,247 INFO train:  8/100, loss:49.012882232666016\n","2021-03-22 09:36:37,930 INFO train:  8/100, loss:49.0128059387207\n","2021-03-22 09:36:49,210 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:37:02,945 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:37:11,765 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:37:21,126 INFO train:  8/100, loss:49.012840270996094\n","2021-03-22 09:37:33,731 INFO train:  8/100, loss:49.01284408569336\n","2021-03-22 09:37:42,511 INFO train:  8/100, loss:49.01280975341797\n","2021-03-22 09:37:54,540 INFO train:  8/100, loss:49.012847900390625\n","2021-03-22 09:38:04,928 INFO train:  8/100, loss:49.01280975341797\n","2021-03-22 09:38:16,943 INFO train:  8/100, loss:49.01288604736328\n","2021-03-22 09:38:31,112 INFO train:  8/100, loss:49.01284408569336\n","2021-03-22 09:38:39,566 INFO train:  8/100, loss:49.01285171508789\n","2021-03-22 09:38:48,727 INFO train:  8/100, loss:49.01279067993164\n","2021-03-22 09:39:03,593 INFO train:  8/100, loss:49.01279830932617\n","2021-03-22 09:39:09,300 INFO train:  8/100, loss:49.0128173828125\n","2021-03-22 09:39:20,534 INFO train:  8/100, loss:49.01286697387695\n","2021-03-22 09:39:31,509 INFO train:  8/100, loss:49.01286315917969\n","2021-03-22 09:39:41,781 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:39:51,751 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:40:09,331 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:40:14,671 INFO train:  8/100, loss:49.0128173828125\n","2021-03-22 09:40:25,605 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:40:39,957 INFO train:  8/100, loss:49.01287078857422\n","2021-03-22 09:40:46,581 INFO train:  8/100, loss:49.01286315917969\n","2021-03-22 09:40:58,473 INFO train:  8/100, loss:49.01282501220703\n","2021-03-22 09:41:12,506 INFO train:  8/100, loss:49.0128288269043\n","2021-03-22 09:41:19,815 INFO train:  8/100, loss:49.012855529785156\n","2021-03-22 09:41:31,981 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:41:41,214 INFO train:  8/100, loss:49.012847900390625\n","2021-03-22 09:41:52,313 INFO train:  8/100, loss:49.01282501220703\n","2021-03-22 09:42:02,284 INFO train:  8/100, loss:49.01285171508789\n","2021-03-22 09:42:12,111 INFO train:  8/100, loss:49.012874603271484\n","2021-03-22 09:42:22,667 INFO train:  8/100, loss:49.0128288269043\n","2021-03-22 09:42:33,329 INFO train:  8/100, loss:49.012840270996094\n","2021-03-22 09:42:46,368 INFO train:  8/100, loss:49.01283645629883\n","2021-03-22 09:42:53,519 INFO train:  8/100, loss:49.01282501220703\n","2021-03-22 09:43:05,078 INFO train:  8/100, loss:49.01285171508789\n","2021-03-22 09:43:16,016 INFO train:  8/100, loss:49.01285934448242\n","2021-03-22 09:43:25,855 INFO train:  8/100, loss:49.01286697387695\n","2021-03-22 09:43:37,095 INFO train:  8/100, loss:49.01284408569336\n","2021-03-22 09:43:47,821 INFO train:  8/100, loss:49.01279830932617\n","2021-03-22 09:43:58,472 INFO train:  8/100, loss:49.012813568115234\n","2021-03-22 09:44:09,027 INFO train:  8/100, loss:49.012813568115234\n","2021-03-22 09:44:18,601 INFO train:  8/100, loss:49.01286697387695\n","2021-03-22 09:44:33,370 INFO train:  8/100, loss:49.01287841796875\n","2021-03-22 09:44:40,611 INFO train:  8/100, loss:49.01284408569336\n","2021-03-22 09:44:50,679 INFO train:  8/100, loss:49.01277542114258\n","2021-03-22 09:45:00,845 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:45:14,402 INFO train:  8/100, loss:49.01283264160156\n","2021-03-22 09:45:22,404 INFO train:  8/100, loss:49.01280975341797\n","2021-03-22 09:45:35,779 INFO train:  8/100, loss:49.0128173828125\n","2021-03-22 09:45:45,130 INFO val:  8/100, loss:49.0128288269043\n","2021-03-22 09:45:55,148 INFO val:  8/100, loss:49.01282501220703\n","2021-03-22 09:46:07,934 INFO val:  8/100, loss:49.01277542114258\n","2021-03-22 09:46:14,802 INFO val:  8/100, loss:49.01287841796875\n","2021-03-22 09:46:17,311 INFO train time 5676.022748231888, 8/100\n","2021-03-22 09:46:17,312 INFO Epoch 9/100\n","2021-03-22 09:46:17,317 INFO ----------\n","2021-03-22 09:46:25,248 INFO train:  9/100, loss:49.012813568115234\n","2021-03-22 09:46:35,403 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:46:46,658 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:46:56,055 INFO train:  9/100, loss:49.01285171508789\n","2021-03-22 09:47:07,528 INFO train:  9/100, loss:49.01279830932617\n","2021-03-22 09:47:19,598 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:47:28,693 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:47:40,162 INFO train:  9/100, loss:49.012760162353516\n","2021-03-22 09:47:49,230 INFO train:  9/100, loss:49.01282501220703\n","2021-03-22 09:48:01,634 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:48:09,558 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:48:20,894 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:48:32,239 INFO train:  9/100, loss:49.01279830932617\n","2021-03-22 09:48:40,636 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:48:51,181 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:49:00,829 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:49:12,730 INFO train:  9/100, loss:49.01286697387695\n","2021-03-22 09:49:22,834 INFO train:  9/100, loss:49.01287841796875\n","2021-03-22 09:49:32,689 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:49:43,400 INFO train:  9/100, loss:49.01287078857422\n","2021-03-22 09:49:53,378 INFO train:  9/100, loss:49.01279830932617\n","2021-03-22 09:50:04,010 INFO train:  9/100, loss:49.0128173828125\n","2021-03-22 09:51:09,564 INFO train:  9/100, loss:49.0128059387207\n","2021-03-22 09:51:15,159 INFO train:  9/100, loss:49.01283645629883\n","2021-03-22 09:51:22,007 INFO train:  9/100, loss:49.01283264160156\n","2021-03-22 09:51:28,058 INFO train:  9/100, loss:49.012813568115234\n","2021-03-22 09:51:33,527 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:51:41,080 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:51:48,333 INFO train:  9/100, loss:49.012874603271484\n","2021-03-22 09:52:00,513 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:52:08,246 INFO train:  9/100, loss:49.01279067993164\n","2021-03-22 09:52:19,835 INFO train:  9/100, loss:49.01271438598633\n","2021-03-22 09:52:31,222 INFO train:  9/100, loss:49.01286697387695\n","2021-03-22 09:52:39,470 INFO train:  9/100, loss:49.01285934448242\n","2021-03-22 09:52:53,140 INFO train:  9/100, loss:49.012874603271484\n","2021-03-22 09:53:02,369 INFO train:  9/100, loss:49.01286315917969\n","2021-03-22 09:53:11,698 INFO train:  9/100, loss:49.012855529785156\n","2021-03-22 09:53:23,976 INFO train:  9/100, loss:49.01285171508789\n","2021-03-22 09:53:33,053 INFO train:  9/100, loss:49.01280975341797\n","2021-03-22 09:53:43,072 INFO train:  9/100, loss:49.01286697387695\n","2021-03-22 09:53:52,633 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:54:02,915 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:54:14,870 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:54:23,480 INFO train:  9/100, loss:49.012855529785156\n","2021-03-22 09:54:34,193 INFO train:  9/100, loss:49.01283264160156\n","2021-03-22 09:54:45,074 INFO train:  9/100, loss:49.01286697387695\n","2021-03-22 09:54:55,742 INFO train:  9/100, loss:49.01286697387695\n","2021-03-22 09:55:07,807 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:55:17,420 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:55:31,303 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:55:37,921 INFO train:  9/100, loss:49.01282501220703\n","2021-03-22 09:55:48,960 INFO train:  9/100, loss:49.01282501220703\n","2021-03-22 09:56:02,897 INFO train:  9/100, loss:49.01282501220703\n","2021-03-22 09:56:10,162 INFO train:  9/100, loss:49.01283264160156\n","2021-03-22 09:56:19,663 INFO train:  9/100, loss:49.01279830932617\n","2021-03-22 09:56:32,871 INFO train:  9/100, loss:49.012840270996094\n","2021-03-22 09:56:40,116 INFO train:  9/100, loss:49.01283264160156\n","2021-03-22 09:56:52,137 INFO train:  9/100, loss:49.012813568115234\n","2021-03-22 09:57:03,123 INFO train:  9/100, loss:49.01280212402344\n","2021-03-22 09:57:11,736 INFO train:  9/100, loss:49.012874603271484\n","2021-03-22 09:57:22,599 INFO train:  9/100, loss:49.01284408569336\n","2021-03-22 09:57:33,085 INFO train:  9/100, loss:49.01283264160156\n","2021-03-22 09:57:47,270 INFO train:  9/100, loss:49.012855529785156\n","2021-03-22 09:57:54,232 INFO val:  9/100, loss:49.0128288269043\n","2021-03-22 09:58:03,134 INFO val:  9/100, loss:49.012855529785156\n","2021-03-22 09:58:13,631 INFO val:  9/100, loss:49.0128059387207\n","2021-03-22 09:58:25,563 INFO val:  9/100, loss:49.01285171508789\n","2021-03-22 09:58:27,711 INFO train time 6406.418705701828, 9/100\n","2021-03-22 09:58:27,714 INFO Epoch 10/100\n","2021-03-22 09:58:27,719 INFO ----------\n","2021-03-22 09:58:35,876 INFO train:  10/100, loss:49.0128288269043\n","2021-03-22 09:58:46,456 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 09:58:56,118 INFO train:  10/100, loss:49.01286697387695\n","2021-03-22 09:59:06,075 INFO train:  10/100, loss:49.01287841796875\n","2021-03-22 09:59:20,378 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 09:59:30,626 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 09:59:39,178 INFO train:  10/100, loss:49.01283645629883\n","2021-03-22 09:59:49,943 INFO train:  10/100, loss:49.01282501220703\n","2021-03-22 10:00:00,416 INFO train:  10/100, loss:49.01283264160156\n","2021-03-22 10:00:10,363 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:00:21,888 INFO train:  10/100, loss:49.01280975341797\n","2021-03-22 10:00:33,359 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:00:42,628 INFO train:  10/100, loss:49.012847900390625\n","2021-03-22 10:00:53,043 INFO train:  10/100, loss:49.01285171508789\n","2021-03-22 10:01:05,169 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:01:15,176 INFO train:  10/100, loss:49.01286697387695\n","2021-03-22 10:01:25,389 INFO train:  10/100, loss:49.01286697387695\n","2021-03-22 10:01:35,388 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:01:46,088 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:01:57,597 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:02:06,089 INFO train:  10/100, loss:49.01285171508789\n","2021-03-22 10:02:16,761 INFO train:  10/100, loss:49.01280975341797\n","2021-03-22 10:02:27,280 INFO train:  10/100, loss:49.0128059387207\n","2021-03-22 10:02:38,335 INFO train:  10/100, loss:49.01286697387695\n","2021-03-22 10:02:49,383 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:03:03,480 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:03:09,756 INFO train:  10/100, loss:49.012874603271484\n","2021-03-22 10:03:21,407 INFO train:  10/100, loss:49.012874603271484\n","2021-03-22 10:03:32,906 INFO train:  10/100, loss:49.01279830932617\n","2021-03-22 10:03:42,013 INFO train:  10/100, loss:49.01287078857422\n","2021-03-22 10:03:51,749 INFO train:  10/100, loss:49.01280212402344\n","2021-03-22 10:04:04,871 INFO train:  10/100, loss:49.0128173828125\n","2021-03-22 10:04:12,729 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:04:23,005 INFO train:  10/100, loss:49.01285934448242\n","2021-03-22 10:04:34,977 INFO train:  10/100, loss:49.01261520385742\n","2021-03-22 10:04:44,044 INFO train:  10/100, loss:49.01285171508789\n","2021-03-22 10:04:54,079 INFO train:  10/100, loss:49.012821197509766\n","2021-03-22 10:05:05,125 INFO train:  10/100, loss:49.01282501220703\n","2021-03-22 10:05:15,421 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:05:26,612 INFO train:  10/100, loss:49.01285934448242\n","2021-03-22 10:05:37,327 INFO train:  10/100, loss:49.012813568115234\n","2021-03-22 10:05:47,269 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:05:59,301 INFO train:  10/100, loss:49.01282501220703\n","2021-03-22 10:06:07,903 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:06:19,136 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:06:32,217 INFO train:  10/100, loss:49.01283645629883\n","2021-03-22 10:06:39,377 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:06:50,579 INFO train:  10/100, loss:49.012847900390625\n","2021-03-22 10:07:02,141 INFO train:  10/100, loss:49.0128059387207\n","2021-03-22 10:07:11,243 INFO train:  10/100, loss:49.01285934448242\n","2021-03-22 10:07:21,828 INFO train:  10/100, loss:49.012882232666016\n","2021-03-22 10:07:32,856 INFO train:  10/100, loss:49.0128173828125\n","2021-03-22 10:07:42,517 INFO train:  10/100, loss:49.0128288269043\n","2021-03-22 10:07:53,747 INFO train:  10/100, loss:49.012821197509766\n","2021-03-22 10:08:02,535 INFO train:  10/100, loss:49.01278305053711\n","2021-03-22 10:08:12,936 INFO train:  10/100, loss:49.012874603271484\n","2021-03-22 10:08:24,106 INFO train:  10/100, loss:49.01287841796875\n","2021-03-22 10:08:34,960 INFO train:  10/100, loss:49.01285171508789\n","2021-03-22 10:08:45,335 INFO train:  10/100, loss:49.01286697387695\n","2021-03-22 10:08:56,177 INFO train:  10/100, loss:49.012840270996094\n","2021-03-22 10:09:06,647 INFO train:  10/100, loss:49.01284408569336\n","2021-03-22 10:09:16,973 INFO train:  10/100, loss:49.01282501220703\n","2021-03-22 10:09:30,989 INFO train:  10/100, loss:49.012874603271484\n","2021-03-22 10:09:36,997 INFO val:  10/100, loss:49.01282501220703\n","2021-03-22 10:09:47,280 INFO val:  10/100, loss:49.012840270996094\n","2021-03-22 10:10:00,099 INFO val:  10/100, loss:49.01287841796875\n","2021-03-22 10:10:07,302 INFO val:  10/100, loss:49.012840270996094\n","2021-03-22 10:10:09,685 INFO train time 7108.374993562698, 10/100\n","2021-03-22 10:10:09,686 INFO Epoch 11/100\n","2021-03-22 10:10:09,692 INFO ----------\n","2021-03-22 10:10:18,191 INFO train:  11/100, loss:49.012840270996094\n","2021-03-22 10:10:32,891 INFO train:  11/100, loss:49.01282501220703\n","2021-03-22 10:10:40,360 INFO train:  11/100, loss:49.01283645629883\n","2021-03-22 10:10:49,920 INFO train:  11/100, loss:49.01280975341797\n","2021-03-22 10:11:02,139 INFO train:  11/100, loss:49.0128173828125\n","2021-03-22 10:11:10,623 INFO train:  11/100, loss:49.01283645629883\n","2021-03-22 10:11:22,409 INFO train:  11/100, loss:49.012794494628906\n","2021-03-22 10:11:31,493 INFO train:  11/100, loss:49.0128173828125\n","2021-03-22 10:11:46,008 INFO train:  11/100, loss:49.0128288269043\n","2021-03-22 10:11:55,306 INFO train:  11/100, loss:49.012840270996094\n","2021-03-22 10:12:05,325 INFO train:  11/100, loss:49.01287078857422\n","2021-03-22 10:12:15,185 INFO train:  11/100, loss:49.01283264160156\n","2021-03-22 10:12:25,826 INFO train:  11/100, loss:49.01279830932617\n","2021-03-22 10:12:35,519 INFO train:  11/100, loss:49.012840270996094\n","2021-03-22 10:12:46,180 INFO train:  11/100, loss:49.012847900390625\n","2021-03-22 10:12:58,034 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:13:09,533 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:13:23,527 INFO train:  11/100, loss:49.01286315917969\n","2021-03-22 10:13:33,648 INFO train:  11/100, loss:49.0128288269043\n","2021-03-22 10:13:43,670 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:13:54,584 INFO train:  11/100, loss:49.01285934448242\n","2021-03-22 10:14:10,330 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:14:16,563 INFO train:  11/100, loss:49.0128059387207\n","2021-03-22 10:14:27,292 INFO train:  11/100, loss:49.0128288269043\n","2021-03-22 10:14:40,083 INFO train:  11/100, loss:49.012813568115234\n","2021-03-22 10:14:47,956 INFO train:  11/100, loss:49.0128173828125\n","2021-03-22 10:15:01,031 INFO train:  11/100, loss:49.01282501220703\n","2021-03-22 10:15:10,097 INFO train:  11/100, loss:49.012855529785156\n","2021-03-22 10:15:20,650 INFO train:  11/100, loss:49.01278305053711\n","2021-03-22 10:15:32,210 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:15:40,773 INFO train:  11/100, loss:49.012847900390625\n","2021-03-22 10:15:50,823 INFO train:  11/100, loss:49.01277542114258\n","2021-03-22 10:16:01,742 INFO train:  11/100, loss:49.01285934448242\n","2021-03-22 10:16:11,441 INFO train:  11/100, loss:49.01284408569336\n","2021-03-22 10:16:21,467 INFO train:  11/100, loss:49.01287078857422\n","2021-03-22 10:16:33,238 INFO train:  11/100, loss:49.0128288269043\n","2021-03-22 10:16:42,260 INFO train:  11/100, loss:49.01286697387695\n","2021-03-22 10:16:53,150 INFO train:  11/100, loss:49.01285934448242\n","2021-03-22 10:17:04,340 INFO train:  11/100, loss:49.01283264160156\n","2021-03-22 10:17:14,529 INFO train:  11/100, loss:49.01280212402344\n","2021-03-22 10:17:25,324 INFO train:  11/100, loss:49.01283645629883\n","2021-03-22 10:17:35,452 INFO train:  11/100, loss:49.01283264160156\n","2021-03-22 10:17:50,223 INFO train:  11/100, loss:49.01285934448242\n","2021-03-22 10:18:00,915 INFO train:  11/100, loss:49.01280975341797\n","2021-03-22 10:18:10,397 INFO train:  11/100, loss:49.01284408569336\n","2021-03-22 10:18:21,740 INFO train:  11/100, loss:49.012840270996094\n","2021-03-22 10:18:32,596 INFO train:  11/100, loss:49.0128059387207\n","2021-03-22 10:18:42,384 INFO train:  11/100, loss:49.01289367675781\n","2021-03-22 10:18:50,909 INFO train:  11/100, loss:49.01285934448242\n","2021-03-22 10:19:02,578 INFO train:  11/100, loss:49.01284408569336\n","2021-03-22 10:19:13,386 INFO train:  11/100, loss:49.012847900390625\n","2021-03-22 10:19:22,941 INFO train:  11/100, loss:49.0128059387207\n","2021-03-22 10:19:34,033 INFO train:  11/100, loss:49.01282501220703\n","2021-03-22 10:19:43,598 INFO train:  11/100, loss:49.01279067993164\n","2021-03-22 10:19:56,178 INFO train:  11/100, loss:49.01284408569336\n","2021-03-22 10:20:05,771 INFO train:  11/100, loss:49.01283264160156\n","2021-03-22 10:20:17,919 INFO train:  11/100, loss:49.012840270996094\n","2021-03-22 10:20:26,785 INFO train:  11/100, loss:49.01283264160156\n","2021-03-22 10:20:40,038 INFO train:  11/100, loss:49.012821197509766\n","2021-03-22 10:20:47,321 INFO train:  11/100, loss:49.0128059387207\n","2021-03-22 10:20:58,096 INFO train:  11/100, loss:49.012794494628906\n","2021-03-22 10:21:08,867 INFO train:  11/100, loss:49.01285171508789\n","2021-03-22 10:21:24,832 INFO train:  11/100, loss:49.01284408569336\n","2021-03-22 10:21:33,001 INFO val:  11/100, loss:49.0128288269043\n","2021-03-22 10:21:43,293 INFO val:  11/100, loss:49.012840270996094\n","2021-03-22 10:21:55,955 INFO val:  11/100, loss:49.01285171508789\n","2021-03-22 10:22:05,173 INFO val:  11/100, loss:49.01280975341797\n","2021-03-22 10:22:06,638 INFO train time 7825.3058660030365, 11/100\n","2021-03-22 10:22:06,639 INFO Epoch 12/100\n","2021-03-22 10:22:06,645 INFO ----------\n","2021-03-22 10:22:16,511 INFO train:  12/100, loss:49.01288604736328\n","2021-03-22 10:22:26,309 INFO train:  12/100, loss:49.01284408569336\n","2021-03-22 10:22:37,441 INFO train:  12/100, loss:49.01279067993164\n","2021-03-22 10:22:46,796 INFO train:  12/100, loss:49.01287078857422\n","2021-03-22 10:22:57,797 INFO train:  12/100, loss:49.01280975341797\n","2021-03-22 10:23:12,796 INFO train:  12/100, loss:49.01285171508789\n","2021-03-22 10:23:21,581 INFO train:  12/100, loss:49.01284408569336\n","2021-03-22 10:23:32,110 INFO train:  12/100, loss:49.01280975341797\n","2021-03-22 10:23:42,222 INFO train:  12/100, loss:49.01286315917969\n","2021-03-22 10:23:52,661 INFO train:  12/100, loss:49.012847900390625\n","2021-03-22 10:24:03,604 INFO train:  12/100, loss:49.012847900390625\n","2021-03-22 10:24:18,516 INFO train:  12/100, loss:49.012821197509766\n","2021-03-22 10:24:25,248 INFO train:  12/100, loss:49.01285171508789\n","2021-03-22 10:24:36,971 INFO train:  12/100, loss:49.01286315917969\n","2021-03-22 10:24:46,111 INFO train:  12/100, loss:49.012874603271484\n","2021-03-22 10:25:01,020 INFO train:  12/100, loss:49.012847900390625\n","2021-03-22 10:25:09,340 INFO train:  12/100, loss:49.0128173828125\n","2021-03-22 10:25:23,601 INFO train:  12/100, loss:49.01286697387695\n","2021-03-22 10:25:30,213 INFO train:  12/100, loss:49.01286315917969\n","2021-03-22 10:25:40,486 INFO train:  12/100, loss:49.0128288269043\n","2021-03-22 10:25:54,944 INFO train:  12/100, loss:49.0128173828125\n","2021-03-22 10:26:03,223 INFO train:  12/100, loss:49.01284408569336\n","2021-03-22 10:26:11,221 INFO train:  12/100, loss:49.01286697387695\n","2021-03-22 10:26:25,181 INFO train:  12/100, loss:49.0128173828125\n","2021-03-22 10:26:32,112 INFO train:  12/100, loss:49.0128173828125\n","2021-03-22 10:26:42,492 INFO train:  12/100, loss:49.01279067993164\n","2021-03-22 10:26:54,703 INFO train:  12/100, loss:49.01284408569336\n","2021-03-22 10:27:02,911 INFO train:  12/100, loss:49.0128059387207\n","2021-03-22 10:27:12,967 INFO train:  12/100, loss:49.01275634765625\n","2021-03-22 10:27:24,475 INFO train:  12/100, loss:49.01285171508789\n","2021-03-22 10:27:33,847 INFO train:  12/100, loss:49.012821197509766\n","2021-03-22 10:27:45,616 INFO train:  12/100, loss:49.012821197509766\n","2021-03-22 10:27:55,442 INFO train:  12/100, loss:49.012855529785156\n","2021-03-22 10:28:05,709 INFO train:  12/100, loss:49.012813568115234\n","2021-03-22 10:28:16,148 INFO train:  12/100, loss:49.012733459472656\n","2021-03-22 10:28:28,199 INFO train:  12/100, loss:49.01286315917969\n","2021-03-22 10:28:37,642 INFO train:  12/100, loss:49.01287841796875\n","2021-03-22 10:28:50,300 INFO train:  12/100, loss:49.01283264160156\n","2021-03-22 10:28:59,809 INFO train:  12/100, loss:49.012855529785156\n","2021-03-22 10:29:09,330 INFO train:  12/100, loss:49.0128173828125\n","2021-03-22 10:29:19,669 INFO train:  12/100, loss:49.012840270996094\n","2021-03-22 10:29:33,979 INFO train:  12/100, loss:49.01276397705078\n","2021-03-22 10:29:40,361 INFO train:  12/100, loss:49.01287841796875\n","2021-03-22 10:29:51,971 INFO train:  12/100, loss:49.01283645629883\n","2021-03-22 10:30:00,571 INFO train:  12/100, loss:49.012855529785156\n","2021-03-22 10:30:11,529 INFO train:  12/100, loss:49.01284408569336\n","2021-03-22 10:30:21,703 INFO train:  12/100, loss:49.01287841796875\n","2021-03-22 10:30:34,537 INFO train:  12/100, loss:49.01283264160156\n","2021-03-22 10:30:43,236 INFO train:  12/100, loss:49.01285171508789\n","2021-03-22 10:30:54,535 INFO train:  12/100, loss:49.01283264160156\n","2021-03-22 10:31:04,302 INFO train:  12/100, loss:49.01285171508789\n","2021-03-22 10:31:14,012 INFO train:  12/100, loss:49.01283645629883\n","2021-03-22 10:31:24,800 INFO train:  12/100, loss:49.012855529785156\n","2021-03-22 10:31:37,234 INFO train:  12/100, loss:49.01278305053711\n","2021-03-22 10:31:47,658 INFO train:  12/100, loss:49.01282501220703\n","2021-03-22 10:31:56,403 INFO train:  12/100, loss:49.01285934448242\n","2021-03-22 10:32:06,375 INFO train:  12/100, loss:49.01285934448242\n","2021-03-22 10:32:17,775 INFO train:  12/100, loss:49.01283645629883\n","2021-03-22 10:32:26,940 INFO train:  12/100, loss:49.012855529785156\n","2021-03-22 10:32:37,749 INFO train:  12/100, loss:49.01283264160156\n","2021-03-22 10:32:50,752 INFO train:  12/100, loss:49.01283645629883\n","2021-03-22 10:32:57,279 INFO train:  12/100, loss:49.0128288269043\n","2021-03-22 10:33:07,435 INFO train:  12/100, loss:49.01280975341797\n","2021-03-22 10:33:22,774 INFO val:  12/100, loss:49.012840270996094\n","2021-03-22 10:33:28,502 INFO val:  12/100, loss:49.0128059387207\n","2021-03-22 10:33:38,313 INFO val:  12/100, loss:49.0128059387207\n","2021-03-22 10:33:49,177 INFO val:  12/100, loss:49.01280975341797\n","2021-03-22 10:33:51,296 INFO train time 8530.006287574768, 12/100\n","2021-03-22 10:33:51,297 INFO Epoch 13/100\n","2021-03-22 10:33:51,305 INFO ----------\n","2021-03-22 10:34:02,126 INFO train:  13/100, loss:49.01280212402344\n","2021-03-22 10:34:13,649 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:34:22,809 INFO train:  13/100, loss:49.0128059387207\n","2021-03-22 10:34:36,877 INFO train:  13/100, loss:49.01279067993164\n","2021-03-22 10:34:46,405 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:34:56,514 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:35:07,275 INFO train:  13/100, loss:49.01283264160156\n","2021-03-22 10:35:19,472 INFO train:  13/100, loss:49.01283264160156\n","2021-03-22 10:35:29,544 INFO train:  13/100, loss:49.0128173828125\n","2021-03-22 10:35:44,369 INFO train:  13/100, loss:49.01286697387695\n","2021-03-22 10:35:50,524 INFO train:  13/100, loss:49.0128173828125\n","2021-03-22 10:36:02,455 INFO train:  13/100, loss:49.012847900390625\n","2021-03-22 10:36:11,234 INFO train:  13/100, loss:49.01284408569336\n","2021-03-22 10:36:21,079 INFO train:  13/100, loss:49.01286697387695\n","2021-03-22 10:36:34,013 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:36:42,312 INFO train:  13/100, loss:49.01284408569336\n","2021-03-22 10:36:53,671 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:37:06,478 INFO train:  13/100, loss:49.012874603271484\n","2021-03-22 10:37:12,971 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:37:23,572 INFO train:  13/100, loss:49.01286697387695\n","2021-03-22 10:37:38,516 INFO train:  13/100, loss:49.012855529785156\n","2021-03-22 10:37:47,836 INFO train:  13/100, loss:49.01283264160156\n","2021-03-22 10:37:54,579 INFO train:  13/100, loss:49.012874603271484\n","2021-03-22 10:38:09,287 INFO train:  13/100, loss:49.0128059387207\n","2021-03-22 10:38:16,480 INFO train:  13/100, loss:49.01278305053711\n","2021-03-22 10:38:26,516 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:38:36,043 INFO train:  13/100, loss:49.01284408569336\n","2021-03-22 10:38:46,219 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:38:58,197 INFO train:  13/100, loss:49.012847900390625\n","2021-03-22 10:39:09,027 INFO train:  13/100, loss:49.01283264160156\n","2021-03-22 10:39:19,819 INFO train:  13/100, loss:49.0128059387207\n","2021-03-22 10:39:32,703 INFO train:  13/100, loss:49.01277542114258\n","2021-03-22 10:39:41,551 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:39:50,961 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:40:03,253 INFO train:  13/100, loss:49.012664794921875\n","2021-03-22 10:40:12,500 INFO train:  13/100, loss:49.01285171508789\n","2021-03-22 10:40:21,669 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:40:32,156 INFO train:  13/100, loss:49.012840270996094\n","2021-03-22 10:40:47,995 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:40:53,505 INFO train:  13/100, loss:49.01282501220703\n","2021-03-22 10:41:05,151 INFO train:  13/100, loss:49.01286697387695\n","2021-03-22 10:41:14,391 INFO train:  13/100, loss:49.01284408569336\n","2021-03-22 10:41:25,858 INFO train:  13/100, loss:49.01287078857422\n","2021-03-22 10:41:37,767 INFO train:  13/100, loss:49.01286697387695\n","2021-03-22 10:41:48,251 INFO train:  13/100, loss:49.012794494628906\n","2021-03-22 10:41:58,756 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:42:10,343 INFO train:  13/100, loss:49.0128173828125\n","2021-03-22 10:42:20,311 INFO train:  13/100, loss:49.012847900390625\n","2021-03-22 10:42:30,863 INFO train:  13/100, loss:49.01278305053711\n","2021-03-22 10:42:42,403 INFO train:  13/100, loss:49.012847900390625\n","2021-03-22 10:42:53,322 INFO train:  13/100, loss:49.01287841796875\n","2021-03-22 10:43:03,469 INFO train:  13/100, loss:49.012855529785156\n","2021-03-22 10:43:17,889 INFO train:  13/100, loss:49.01277542114258\n","2021-03-22 10:43:31,877 INFO train:  13/100, loss:49.01279830932617\n","2021-03-22 10:43:37,979 INFO train:  13/100, loss:49.01282501220703\n","2021-03-22 10:43:48,407 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:44:02,562 INFO train:  13/100, loss:49.01278305053711\n","2021-03-22 10:44:09,706 INFO train:  13/100, loss:49.012813568115234\n","2021-03-22 10:44:19,449 INFO train:  13/100, loss:49.01282501220703\n","2021-03-22 10:44:34,625 INFO train:  13/100, loss:49.01286315917969\n","2021-03-22 10:44:40,215 INFO train:  13/100, loss:49.01286315917969\n","2021-03-22 10:44:51,011 INFO train:  13/100, loss:49.01283264160156\n","2021-03-22 10:45:02,085 INFO train:  13/100, loss:49.01285934448242\n","2021-03-22 10:45:11,073 INFO val:  13/100, loss:49.01279830932617\n","2021-03-22 10:45:20,375 INFO val:  13/100, loss:49.01284408569336\n","2021-03-22 10:45:33,106 INFO val:  13/100, loss:49.012874603271484\n","2021-03-22 10:45:43,105 INFO val:  13/100, loss:49.01284408569336\n","2021-03-22 10:45:45,321 INFO train time 9243.971933841705, 13/100\n","2021-03-22 10:45:45,323 INFO Epoch 14/100\n","2021-03-22 10:45:45,328 INFO ----------\n","2021-03-22 10:45:57,442 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:46:03,715 INFO train:  14/100, loss:49.0128059387207\n","2021-03-22 10:46:13,918 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:46:25,473 INFO train:  14/100, loss:49.01283645629883\n","2021-03-22 10:46:35,049 INFO train:  14/100, loss:49.012847900390625\n","2021-03-22 10:46:45,971 INFO train:  14/100, loss:49.0128288269043\n","2021-03-22 10:46:55,785 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:47:06,766 INFO train:  14/100, loss:49.0128059387207\n","2021-03-22 10:47:17,159 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:47:26,673 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:47:36,546 INFO train:  14/100, loss:49.01285934448242\n","2021-03-22 10:47:46,914 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:47:58,759 INFO train:  14/100, loss:49.01282501220703\n","2021-03-22 10:48:07,859 INFO train:  14/100, loss:49.01285934448242\n","2021-03-22 10:48:17,911 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:48:29,753 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:48:41,557 INFO train:  14/100, loss:49.012847900390625\n","2021-03-22 10:48:52,832 INFO train:  14/100, loss:49.01285934448242\n","2021-03-22 10:49:04,299 INFO train:  14/100, loss:49.01286697387695\n","2021-03-22 10:49:14,123 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:49:23,971 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:49:34,678 INFO train:  14/100, loss:49.012794494628906\n","2021-03-22 10:49:46,289 INFO train:  14/100, loss:49.01285934448242\n","2021-03-22 10:49:57,609 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:50:07,331 INFO train:  14/100, loss:49.012779235839844\n","2021-03-22 10:50:18,921 INFO train:  14/100, loss:49.012855529785156\n","2021-03-22 10:50:32,682 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:50:39,150 INFO train:  14/100, loss:49.012874603271484\n","2021-03-22 10:50:49,119 INFO train:  14/100, loss:49.01282501220703\n","2021-03-22 10:51:02,816 INFO train:  14/100, loss:49.01282501220703\n","2021-03-22 10:51:11,970 INFO train:  14/100, loss:49.012855529785156\n","2021-03-22 10:51:22,996 INFO train:  14/100, loss:49.01278305053711\n","2021-03-22 10:51:33,802 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:51:43,601 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:51:55,172 INFO train:  14/100, loss:49.0128173828125\n","2021-03-22 10:52:05,659 INFO train:  14/100, loss:49.012874603271484\n","2021-03-22 10:52:17,736 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:52:29,313 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:52:38,604 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:52:49,541 INFO train:  14/100, loss:49.01283645629883\n","2021-03-22 10:53:00,896 INFO train:  14/100, loss:49.01286315917969\n","2021-03-22 10:53:08,975 INFO train:  14/100, loss:49.012855529785156\n","2021-03-22 10:53:21,156 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:53:32,227 INFO train:  14/100, loss:49.01279830932617\n","2021-03-22 10:53:42,868 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:53:53,866 INFO train:  14/100, loss:49.01285934448242\n","2021-03-22 10:54:10,898 INFO train:  14/100, loss:49.01286697387695\n","2021-03-22 10:54:17,586 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:54:27,298 INFO train:  14/100, loss:49.01276397705078\n","2021-03-22 10:54:39,236 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:54:49,269 INFO train:  14/100, loss:49.01280975341797\n","2021-03-22 10:55:02,579 INFO train:  14/100, loss:49.0128059387207\n","2021-03-22 10:55:10,753 INFO train:  14/100, loss:49.0128059387207\n","2021-03-22 10:55:20,942 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:55:31,477 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:55:44,782 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:55:57,104 INFO train:  14/100, loss:49.01282501220703\n","2021-03-22 10:56:04,244 INFO train:  14/100, loss:49.012840270996094\n","2021-03-22 10:56:17,659 INFO train:  14/100, loss:49.012821197509766\n","2021-03-22 10:56:24,713 INFO train:  14/100, loss:49.01283264160156\n","2021-03-22 10:56:35,349 INFO train:  14/100, loss:49.01285171508789\n","2021-03-22 10:56:44,844 INFO train:  14/100, loss:49.012821197509766\n","2021-03-22 10:56:57,073 INFO train:  14/100, loss:49.01284408569336\n","2021-03-22 10:57:06,493 INFO val:  14/100, loss:49.0128173828125\n","2021-03-22 10:57:19,265 INFO val:  14/100, loss:49.0128173828125\n","2021-03-22 10:57:28,288 INFO val:  14/100, loss:49.01276397705078\n","2021-03-22 10:57:39,064 INFO val:  14/100, loss:49.012882232666016\n","2021-03-22 10:57:40,788 INFO train time 9959.493768453598, 14/100\n","2021-03-22 10:57:40,789 INFO Epoch 15/100\n","2021-03-22 10:57:40,795 INFO ----------\n","2021-03-22 10:57:49,186 INFO train:  15/100, loss:49.012882232666016\n","2021-03-22 10:58:01,364 INFO train:  15/100, loss:49.012874603271484\n","2021-03-22 10:58:11,113 INFO train:  15/100, loss:49.01285171508789\n","2021-03-22 10:58:26,191 INFO train:  15/100, loss:49.01285171508789\n","2021-03-22 10:58:34,010 INFO train:  15/100, loss:49.012874603271484\n","2021-03-22 10:58:42,528 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 10:58:57,253 INFO train:  15/100, loss:49.0128059387207\n","2021-03-22 10:59:04,174 INFO train:  15/100, loss:49.012786865234375\n","2021-03-22 10:59:14,903 INFO train:  15/100, loss:49.01287841796875\n","2021-03-22 10:59:24,727 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 10:59:34,669 INFO train:  15/100, loss:49.01280975341797\n","2021-03-22 10:59:46,196 INFO train:  15/100, loss:49.01282501220703\n","2021-03-22 10:59:56,406 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:00:05,970 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:00:17,694 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 11:00:28,337 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:00:39,021 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 11:00:49,313 INFO train:  15/100, loss:49.012874603271484\n","2021-03-22 11:00:59,828 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:01:11,720 INFO train:  15/100, loss:49.01287841796875\n","2021-03-22 11:01:23,308 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:01:33,961 INFO train:  15/100, loss:49.01286697387695\n","2021-03-22 11:01:45,695 INFO train:  15/100, loss:49.0128173828125\n","2021-03-22 11:01:56,017 INFO train:  15/100, loss:49.012847900390625\n","2021-03-22 11:02:10,766 INFO train:  15/100, loss:49.01283264160156\n","2021-03-22 11:02:16,483 INFO train:  15/100, loss:49.01286697387695\n","2021-03-22 11:02:26,299 INFO train:  15/100, loss:49.0128059387207\n","2021-03-22 11:02:37,407 INFO train:  15/100, loss:49.0128288269043\n","2021-03-22 11:02:46,911 INFO train:  15/100, loss:49.01277160644531\n","2021-03-22 11:02:59,942 INFO train:  15/100, loss:49.01282501220703\n","2021-03-22 11:03:14,040 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:03:19,683 INFO train:  15/100, loss:49.0128059387207\n","2021-03-22 11:03:30,388 INFO train:  15/100, loss:49.01285171508789\n","2021-03-22 11:03:41,147 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 11:03:51,327 INFO train:  15/100, loss:49.01279830932617\n","2021-03-22 11:04:04,032 INFO train:  15/100, loss:49.01287841796875\n","2021-03-22 11:04:16,364 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:04:26,244 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:04:37,272 INFO train:  15/100, loss:49.012813568115234\n","2021-03-22 11:04:46,993 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:04:59,035 INFO train:  15/100, loss:49.0128173828125\n","2021-03-22 11:05:08,896 INFO train:  15/100, loss:49.012786865234375\n","2021-03-22 11:05:19,620 INFO train:  15/100, loss:49.01280975341797\n","2021-03-22 11:05:32,502 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:05:41,150 INFO train:  15/100, loss:49.012855529785156\n","2021-03-22 11:05:55,560 INFO train:  15/100, loss:49.01286315917969\n","2021-03-22 11:06:01,382 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:06:12,385 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:06:22,062 INFO train:  15/100, loss:49.01285934448242\n","2021-03-22 11:06:31,901 INFO train:  15/100, loss:49.012855529785156\n","2021-03-22 11:06:43,298 INFO train:  15/100, loss:49.01282501220703\n","2021-03-22 11:06:57,310 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 11:07:04,631 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:07:14,457 INFO train:  15/100, loss:49.0128059387207\n","2021-03-22 11:07:24,861 INFO train:  15/100, loss:49.01279067993164\n","2021-03-22 11:07:34,724 INFO train:  15/100, loss:49.01285171508789\n","2021-03-22 11:07:45,239 INFO train:  15/100, loss:49.01279830932617\n","2021-03-22 11:07:59,000 INFO train:  15/100, loss:49.0128288269043\n","2021-03-22 11:08:06,225 INFO train:  15/100, loss:49.0128059387207\n","2021-03-22 11:08:17,873 INFO train:  15/100, loss:49.012840270996094\n","2021-03-22 11:08:26,899 INFO train:  15/100, loss:49.01284408569336\n","2021-03-22 11:08:37,531 INFO train:  15/100, loss:49.01283264160156\n","2021-03-22 11:08:47,030 INFO train:  15/100, loss:49.01280975341797\n","2021-03-22 11:08:56,788 INFO val:  15/100, loss:49.01279067993164\n","2021-03-22 11:09:07,245 INFO val:  15/100, loss:49.0128288269043\n","2021-03-22 11:09:18,484 INFO val:  15/100, loss:49.01285171508789\n","2021-03-22 11:09:29,129 INFO val:  15/100, loss:49.01285171508789\n","2021-03-22 11:09:29,948 INFO train time 10668.657012701035, 15/100\n","2021-03-22 11:09:29,950 INFO Epoch 16/100\n","2021-03-22 11:09:29,957 INFO ----------\n","2021-03-22 11:09:39,601 INFO train:  16/100, loss:49.012847900390625\n","2021-03-22 11:09:52,888 INFO train:  16/100, loss:49.012821197509766\n","2021-03-22 11:10:05,024 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:10:14,820 INFO train:  16/100, loss:49.01285171508789\n","2021-03-22 11:10:26,166 INFO train:  16/100, loss:49.0128059387207\n","2021-03-22 11:10:39,110 INFO train:  16/100, loss:49.012874603271484\n","2021-03-22 11:10:47,279 INFO train:  16/100, loss:49.01287078857422\n","2021-03-22 11:10:56,413 INFO train:  16/100, loss:49.01279830932617\n","2021-03-22 11:11:09,015 INFO train:  16/100, loss:49.01287841796875\n","2021-03-22 11:11:17,897 INFO train:  16/100, loss:49.01285171508789\n","2021-03-22 11:11:26,918 INFO train:  16/100, loss:49.012847900390625\n","2021-03-22 11:11:36,986 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:11:48,883 INFO train:  16/100, loss:49.01277160644531\n","2021-03-22 11:11:57,575 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:12:08,271 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:12:18,276 INFO train:  16/100, loss:49.01286697387695\n","2021-03-22 11:12:28,189 INFO train:  16/100, loss:49.01287841796875\n","2021-03-22 11:12:38,897 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:12:52,185 INFO train:  16/100, loss:49.0128173828125\n","2021-03-22 11:12:59,375 INFO train:  16/100, loss:49.01276779174805\n","2021-03-22 11:13:10,530 INFO train:  16/100, loss:49.012821197509766\n","2021-03-22 11:13:19,554 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:13:32,353 INFO train:  16/100, loss:49.01279830932617\n","2021-03-22 11:13:40,861 INFO train:  16/100, loss:49.012855529785156\n","2021-03-22 11:13:50,989 INFO train:  16/100, loss:49.0128059387207\n","2021-03-22 11:14:01,648 INFO train:  16/100, loss:49.01278305053711\n","2021-03-22 11:14:11,458 INFO train:  16/100, loss:49.01280975341797\n","2021-03-22 11:14:22,736 INFO train:  16/100, loss:49.01286697387695\n","2021-03-22 11:14:33,656 INFO train:  16/100, loss:49.01274108886719\n","2021-03-22 11:14:45,105 INFO train:  16/100, loss:49.012847900390625\n","2021-03-22 11:14:54,315 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:15:04,042 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:15:16,097 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:15:24,841 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:15:35,320 INFO train:  16/100, loss:49.01287841796875\n","2021-03-22 11:15:46,516 INFO train:  16/100, loss:49.01287841796875\n","2021-03-22 11:15:57,110 INFO train:  16/100, loss:49.012840270996094\n","2021-03-22 11:16:08,743 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:16:23,405 INFO train:  16/100, loss:49.01287078857422\n","2021-03-22 11:16:33,548 INFO train:  16/100, loss:49.01285171508789\n","2021-03-22 11:16:43,598 INFO train:  16/100, loss:49.012840270996094\n","2021-03-22 11:16:54,879 INFO train:  16/100, loss:49.0128059387207\n","2021-03-22 11:17:04,465 INFO train:  16/100, loss:49.01287078857422\n","2021-03-22 11:17:14,687 INFO train:  16/100, loss:49.012813568115234\n","2021-03-22 11:17:26,974 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:17:36,640 INFO train:  16/100, loss:49.01287841796875\n","2021-03-22 11:17:49,459 INFO train:  16/100, loss:49.012855529785156\n","2021-03-22 11:18:02,930 INFO train:  16/100, loss:49.01285934448242\n","2021-03-22 11:18:09,608 INFO train:  16/100, loss:49.01282501220703\n","2021-03-22 11:18:20,756 INFO train:  16/100, loss:49.01283264160156\n","2021-03-22 11:18:32,581 INFO train:  16/100, loss:49.01283264160156\n","2021-03-22 11:18:44,014 INFO train:  16/100, loss:49.01282501220703\n","2021-03-22 11:18:55,039 INFO train:  16/100, loss:49.01279067993164\n","2021-03-22 11:19:12,115 INFO train:  16/100, loss:49.01279830932617\n","2021-03-22 11:19:18,739 INFO train:  16/100, loss:49.01280975341797\n","2021-03-22 11:19:27,753 INFO train:  16/100, loss:49.01286697387695\n","2021-03-22 11:19:41,077 INFO train:  16/100, loss:49.01282501220703\n","2021-03-22 11:19:49,624 INFO train:  16/100, loss:49.012821197509766\n","2021-03-22 11:20:00,921 INFO train:  16/100, loss:49.01282501220703\n","2021-03-22 11:20:14,907 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:20:21,542 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:20:32,692 INFO train:  16/100, loss:49.01284408569336\n","2021-03-22 11:20:46,143 INFO train:  16/100, loss:49.01283645629883\n","2021-03-22 11:20:53,703 INFO val:  16/100, loss:49.01283264160156\n","2021-03-22 11:21:03,949 INFO val:  16/100, loss:49.01285934448242\n","2021-03-22 11:21:13,326 INFO val:  16/100, loss:49.01287841796875\n","2021-03-22 11:21:23,937 INFO val:  16/100, loss:49.01283645629883\n","2021-03-22 11:21:25,887 INFO train time 11384.622381925583, 16/100\n","2021-03-22 11:21:25,888 INFO Epoch 17/100\n","2021-03-22 11:21:25,895 INFO ----------\n","2021-03-22 11:21:34,646 INFO train:  17/100, loss:49.0128288269043\n","2021-03-22 11:21:45,257 INFO train:  17/100, loss:49.01282501220703\n","2021-03-22 11:21:56,844 INFO train:  17/100, loss:49.01282501220703\n","2021-03-22 11:22:06,511 INFO train:  17/100, loss:49.01280975341797\n","2021-03-22 11:22:17,549 INFO train:  17/100, loss:49.01283264160156\n","2021-03-22 11:22:28,540 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:22:39,564 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:22:54,280 INFO train:  17/100, loss:49.01280975341797\n","2021-03-22 11:23:00,431 INFO train:  17/100, loss:49.01285934448242\n","2021-03-22 11:23:10,712 INFO train:  17/100, loss:49.012855529785156\n","2021-03-22 11:23:23,397 INFO train:  17/100, loss:49.01280975341797\n","2021-03-22 11:23:32,494 INFO train:  17/100, loss:49.012840270996094\n","2021-03-22 11:23:43,514 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:23:54,079 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:24:05,506 INFO train:  17/100, loss:49.01286315917969\n","2021-03-22 11:24:15,135 INFO train:  17/100, loss:49.01282501220703\n","2021-03-22 11:24:29,439 INFO train:  17/100, loss:49.0128173828125\n","2021-03-22 11:24:38,722 INFO train:  17/100, loss:49.01285934448242\n","2021-03-22 11:24:49,407 INFO train:  17/100, loss:49.01279830932617\n","2021-03-22 11:25:02,992 INFO train:  17/100, loss:49.01286697387695\n","2021-03-22 11:25:11,183 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:25:20,313 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:25:32,814 INFO train:  17/100, loss:49.01282501220703\n","2021-03-22 11:25:42,386 INFO train:  17/100, loss:49.01285934448242\n","2021-03-22 11:25:51,584 INFO train:  17/100, loss:49.012786865234375\n","2021-03-22 11:26:05,915 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:26:12,445 INFO train:  17/100, loss:49.0128173828125\n","2021-03-22 11:26:24,072 INFO train:  17/100, loss:49.012840270996094\n","2021-03-22 11:26:33,381 INFO train:  17/100, loss:49.0128173828125\n","2021-03-22 11:26:43,934 INFO train:  17/100, loss:49.012874603271484\n","2021-03-22 11:26:54,876 INFO train:  17/100, loss:49.012840270996094\n","2021-03-22 11:27:09,589 INFO train:  17/100, loss:49.01276397705078\n","2021-03-22 11:27:17,961 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:27:27,144 INFO train:  17/100, loss:49.0128059387207\n","2021-03-22 11:27:38,829 INFO train:  17/100, loss:49.01279067993164\n","2021-03-22 11:27:52,020 INFO train:  17/100, loss:49.01287078857422\n","2021-03-22 11:28:04,778 INFO train:  17/100, loss:49.012840270996094\n","2021-03-22 11:28:15,442 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:28:30,448 INFO train:  17/100, loss:49.012847900390625\n","2021-03-22 11:28:39,390 INFO train:  17/100, loss:49.01285934448242\n","2021-03-22 11:28:48,437 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:28:59,296 INFO train:  17/100, loss:49.01280212402344\n","2021-03-22 11:29:09,383 INFO train:  17/100, loss:49.01285171508789\n","2021-03-22 11:29:19,222 INFO train:  17/100, loss:49.01279067993164\n","2021-03-22 11:29:29,903 INFO train:  17/100, loss:49.0128059387207\n","2021-03-22 11:29:42,512 INFO train:  17/100, loss:49.012855529785156\n","2021-03-22 11:29:50,319 INFO train:  17/100, loss:49.01286315917969\n","2021-03-22 11:30:01,215 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:30:10,832 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:30:24,167 INFO train:  17/100, loss:49.01283645629883\n","2021-03-22 11:30:33,829 INFO train:  17/100, loss:49.012847900390625\n","2021-03-22 11:30:47,912 INFO train:  17/100, loss:49.012840270996094\n","2021-03-22 11:30:54,813 INFO train:  17/100, loss:49.01280975341797\n","2021-03-22 11:31:06,203 INFO train:  17/100, loss:49.0128173828125\n","2021-03-22 11:31:15,839 INFO train:  17/100, loss:49.01283264160156\n","2021-03-22 11:31:27,633 INFO train:  17/100, loss:49.01283264160156\n","2021-03-22 11:31:37,627 INFO train:  17/100, loss:49.01279067993164\n","2021-03-22 11:31:49,529 INFO train:  17/100, loss:49.01286697387695\n","2021-03-22 11:31:58,541 INFO train:  17/100, loss:49.01278305053711\n","2021-03-22 11:32:09,845 INFO train:  17/100, loss:49.012794494628906\n","2021-03-22 11:32:19,415 INFO train:  17/100, loss:49.01286697387695\n","2021-03-22 11:32:30,290 INFO train:  17/100, loss:49.01284408569336\n","2021-03-22 11:32:39,586 INFO train:  17/100, loss:49.0128288269043\n","2021-03-22 11:32:50,319 INFO val:  17/100, loss:49.012840270996094\n","2021-03-22 11:33:04,320 INFO val:  17/100, loss:49.01284408569336\n","2021-03-22 11:33:13,405 INFO val:  17/100, loss:49.012855529785156\n","2021-03-22 11:33:23,328 INFO val:  17/100, loss:49.0128173828125\n","2021-03-22 11:33:24,805 INFO train time 12103.503679037094, 17/100\n","2021-03-22 11:33:24,806 INFO Epoch 18/100\n","2021-03-22 11:33:24,813 INFO ----------\n","2021-03-22 11:33:35,237 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:33:45,256 INFO train:  18/100, loss:49.01285934448242\n","2021-03-22 11:33:57,287 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:34:06,713 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:34:17,693 INFO train:  18/100, loss:49.012847900390625\n","2021-03-22 11:34:28,043 INFO train:  18/100, loss:49.01286315917969\n","2021-03-22 11:34:39,056 INFO train:  18/100, loss:49.01277160644531\n","2021-03-22 11:34:48,127 INFO train:  18/100, loss:49.01285934448242\n","2021-03-22 11:34:59,509 INFO train:  18/100, loss:49.01284408569336\n","2021-03-22 11:35:10,525 INFO train:  18/100, loss:49.012840270996094\n","2021-03-22 11:35:22,712 INFO train:  18/100, loss:49.012840270996094\n","2021-03-22 11:35:33,191 INFO train:  18/100, loss:49.01283264160156\n","2021-03-22 11:35:42,734 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:35:52,211 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:36:05,395 INFO train:  18/100, loss:49.01284408569336\n","2021-03-22 11:36:14,415 INFO train:  18/100, loss:49.01283264160156\n","2021-03-22 11:36:24,512 INFO train:  18/100, loss:49.0128288269043\n","2021-03-22 11:36:36,847 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:36:46,757 INFO train:  18/100, loss:49.01283645629883\n","2021-03-22 11:36:58,862 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:37:08,245 INFO train:  18/100, loss:49.0128059387207\n","2021-03-22 11:37:19,753 INFO train:  18/100, loss:49.01279067993164\n","2021-03-22 11:37:32,560 INFO train:  18/100, loss:49.01276779174805\n","2021-03-22 11:37:39,866 INFO train:  18/100, loss:49.012847900390625\n","2021-03-22 11:37:48,532 INFO train:  18/100, loss:49.012779235839844\n","2021-03-22 11:38:01,637 INFO train:  18/100, loss:49.01283264160156\n","2021-03-22 11:38:09,933 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:38:19,565 INFO train:  18/100, loss:49.01282501220703\n","2021-03-22 11:38:35,004 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:38:45,418 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:39:02,420 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:39:08,954 INFO train:  18/100, loss:49.01283264160156\n","2021-03-22 11:39:19,918 INFO train:  18/100, loss:49.012847900390625\n","2021-03-22 11:39:30,081 INFO train:  18/100, loss:49.01282501220703\n","2021-03-22 11:39:41,339 INFO train:  18/100, loss:49.0128059387207\n","2021-03-22 11:39:50,622 INFO train:  18/100, loss:49.01285934448242\n","2021-03-22 11:40:02,653 INFO train:  18/100, loss:49.01285171508789\n","2021-03-22 11:40:11,068 INFO train:  18/100, loss:49.012874603271484\n","2021-03-22 11:40:22,083 INFO train:  18/100, loss:49.01279830932617\n","2021-03-22 11:40:34,843 INFO train:  18/100, loss:49.0128173828125\n","2021-03-22 11:40:42,096 INFO train:  18/100, loss:49.01283645629883\n","2021-03-22 11:40:51,994 INFO train:  18/100, loss:49.012882232666016\n","2021-03-22 11:41:03,211 INFO train:  18/100, loss:49.012840270996094\n","2021-03-22 11:41:12,547 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:41:23,378 INFO train:  18/100, loss:49.0128288269043\n","2021-03-22 11:41:33,755 INFO train:  18/100, loss:49.01284408569336\n","2021-03-22 11:41:43,903 INFO train:  18/100, loss:49.01287078857422\n","2021-03-22 11:41:55,902 INFO train:  18/100, loss:49.01285934448242\n","2021-03-22 11:42:05,801 INFO train:  18/100, loss:49.01282501220703\n","2021-03-22 11:42:17,014 INFO train:  18/100, loss:49.01285934448242\n","2021-03-22 11:42:26,592 INFO train:  18/100, loss:49.01282501220703\n","2021-03-22 11:42:37,807 INFO train:  18/100, loss:49.012840270996094\n","2021-03-22 11:42:47,004 INFO train:  18/100, loss:49.01287841796875\n","2021-03-22 11:42:58,347 INFO train:  18/100, loss:49.01283645629883\n","2021-03-22 11:43:07,736 INFO train:  18/100, loss:49.01279830932617\n","2021-03-22 11:43:19,823 INFO train:  18/100, loss:49.012840270996094\n","2021-03-22 11:43:32,853 INFO train:  18/100, loss:49.01279830932617\n","2021-03-22 11:43:41,055 INFO train:  18/100, loss:49.012874603271484\n","2021-03-22 11:43:51,565 INFO train:  18/100, loss:49.01282501220703\n","2021-03-22 11:44:03,068 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:44:11,468 INFO train:  18/100, loss:49.01280975341797\n","2021-03-22 11:44:24,137 INFO train:  18/100, loss:49.012821197509766\n","2021-03-22 11:44:32,902 INFO train:  18/100, loss:49.0128059387207\n","2021-03-22 11:44:44,797 INFO val:  18/100, loss:49.012840270996094\n","2021-03-22 11:44:54,163 INFO val:  18/100, loss:49.01280975341797\n","2021-03-22 11:45:05,080 INFO val:  18/100, loss:49.012733459472656\n","2021-03-22 11:45:15,432 INFO val:  18/100, loss:49.012813568115234\n","2021-03-22 11:45:17,066 INFO train time 12815.703451871872, 18/100\n","2021-03-22 11:45:17,068 INFO Epoch 19/100\n","2021-03-22 11:45:17,070 INFO ----------\n","2021-03-22 11:45:26,107 INFO train:  19/100, loss:49.01285934448242\n","2021-03-22 11:45:36,172 INFO train:  19/100, loss:49.01283264160156\n","2021-03-22 11:45:50,930 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:46:01,830 INFO train:  19/100, loss:49.012840270996094\n","2021-03-22 11:46:12,277 INFO train:  19/100, loss:49.01279067993164\n","2021-03-22 11:46:24,825 INFO train:  19/100, loss:49.012874603271484\n","2021-03-22 11:46:36,746 INFO train:  19/100, loss:49.01283264160156\n","2021-03-22 11:46:50,975 INFO train:  19/100, loss:49.012794494628906\n","2021-03-22 11:46:57,974 INFO train:  19/100, loss:49.0128288269043\n","2021-03-22 11:47:07,116 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:47:22,919 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:47:29,398 INFO train:  19/100, loss:49.012840270996094\n","2021-03-22 11:47:38,827 INFO train:  19/100, loss:49.012786865234375\n","2021-03-22 11:47:49,716 INFO train:  19/100, loss:49.012874603271484\n","2021-03-22 11:47:58,969 INFO train:  19/100, loss:49.01283645629883\n","2021-03-22 11:48:11,408 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:48:20,001 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:48:29,529 INFO train:  19/100, loss:49.012840270996094\n","2021-03-22 11:48:41,295 INFO train:  19/100, loss:49.01285171508789\n","2021-03-22 11:48:50,565 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:49:02,209 INFO train:  19/100, loss:49.01283645629883\n","2021-03-22 11:49:10,935 INFO train:  19/100, loss:49.01287841796875\n","2021-03-22 11:49:23,823 INFO train:  19/100, loss:49.01278305053711\n","2021-03-22 11:49:33,216 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:49:42,394 INFO train:  19/100, loss:49.01283264160156\n","2021-03-22 11:49:53,666 INFO train:  19/100, loss:49.01277160644531\n","2021-03-22 11:50:05,445 INFO train:  19/100, loss:49.0128173828125\n","2021-03-22 11:50:15,314 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:50:27,932 INFO train:  19/100, loss:49.01274871826172\n","2021-03-22 11:50:37,166 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:50:46,758 INFO train:  19/100, loss:49.012855529785156\n","2021-03-22 11:51:01,644 INFO train:  19/100, loss:49.012840270996094\n","2021-03-22 11:51:11,675 INFO train:  19/100, loss:49.0128059387207\n","2021-03-22 11:51:21,337 INFO train:  19/100, loss:49.01283264160156\n","2021-03-22 11:51:33,020 INFO train:  19/100, loss:49.012733459472656\n","2021-03-22 11:51:42,375 INFO train:  19/100, loss:49.01280975341797\n","2021-03-22 11:51:53,150 INFO train:  19/100, loss:49.012855529785156\n","2021-03-22 11:52:02,593 INFO train:  19/100, loss:49.01287078857422\n","2021-03-22 11:52:13,389 INFO train:  19/100, loss:49.0128059387207\n","2021-03-22 11:52:23,784 INFO train:  19/100, loss:49.01287841796875\n","2021-03-22 11:52:35,381 INFO train:  19/100, loss:49.01282501220703\n","2021-03-22 11:52:45,012 INFO train:  19/100, loss:49.01283645629883\n","2021-03-22 11:52:54,959 INFO train:  19/100, loss:49.01283645629883\n","2021-03-22 11:53:04,757 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:53:17,399 INFO train:  19/100, loss:49.012813568115234\n","2021-03-22 11:53:28,264 INFO train:  19/100, loss:49.01285934448242\n","2021-03-22 11:53:38,453 INFO train:  19/100, loss:49.01285934448242\n","2021-03-22 11:53:49,250 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:54:02,503 INFO train:  19/100, loss:49.0128173828125\n","2021-03-22 11:54:12,875 INFO train:  19/100, loss:49.01287841796875\n","2021-03-22 11:54:23,435 INFO train:  19/100, loss:49.01286697387695\n","2021-03-22 11:54:33,612 INFO train:  19/100, loss:49.012840270996094\n","2021-03-22 11:54:43,825 INFO train:  19/100, loss:49.0128173828125\n","2021-03-22 11:54:54,219 INFO train:  19/100, loss:49.01282501220703\n","2021-03-22 11:55:07,183 INFO train:  19/100, loss:49.01284408569336\n","2021-03-22 11:55:16,696 INFO train:  19/100, loss:49.01285171508789\n","2021-03-22 11:55:27,107 INFO train:  19/100, loss:49.01282501220703\n","2021-03-22 11:55:37,103 INFO train:  19/100, loss:49.01285171508789\n","2021-03-22 11:55:48,488 INFO train:  19/100, loss:49.01276779174805\n","2021-03-22 11:55:58,406 INFO train:  19/100, loss:49.012847900390625\n","2021-03-22 11:56:10,318 INFO train:  19/100, loss:49.01282501220703\n","2021-03-22 11:56:20,424 INFO train:  19/100, loss:49.01285934448242\n","2021-03-22 11:56:32,657 INFO train:  19/100, loss:49.012813568115234\n","2021-03-22 11:56:42,645 INFO val:  19/100, loss:49.012779235839844\n","2021-03-22 11:56:52,920 INFO val:  19/100, loss:49.01283645629883\n","2021-03-22 11:57:06,282 INFO val:  19/100, loss:49.01282501220703\n","2021-03-22 11:57:13,796 INFO val:  19/100, loss:49.012855529785156\n","2021-03-22 11:57:15,261 INFO train time 13533.959314346313, 19/100\n","2021-03-22 11:57:15,263 INFO Epoch 20/100\n","2021-03-22 11:57:15,270 INFO ----------\n","2021-03-22 11:57:24,650 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 11:57:34,706 INFO train:  20/100, loss:49.0128173828125\n","2021-03-22 11:57:45,487 INFO train:  20/100, loss:49.0128059387207\n","2021-03-22 11:57:56,674 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 11:58:06,969 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 11:58:17,195 INFO train:  20/100, loss:49.01285171508789\n","2021-03-22 11:58:27,442 INFO train:  20/100, loss:49.01280212402344\n","2021-03-22 11:58:42,026 INFO train:  20/100, loss:49.0128059387207\n","2021-03-22 11:58:52,566 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 11:59:07,524 INFO train:  20/100, loss:49.01286697387695\n","2021-03-22 11:59:14,225 INFO train:  20/100, loss:49.012786865234375\n","2021-03-22 11:59:22,771 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 11:59:34,377 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 11:59:44,274 INFO train:  20/100, loss:49.01286315917969\n","2021-03-22 11:59:55,906 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 12:00:10,435 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:00:18,537 INFO train:  20/100, loss:49.0128173828125\n","2021-03-22 12:00:29,460 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 12:00:38,916 INFO train:  20/100, loss:49.01282501220703\n","2021-03-22 12:00:49,062 INFO train:  20/100, loss:49.01286697387695\n","2021-03-22 12:01:03,096 INFO train:  20/100, loss:49.01286697387695\n","2021-03-22 12:01:16,009 INFO train:  20/100, loss:49.01286697387695\n","2021-03-22 12:01:25,478 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:01:35,075 INFO train:  20/100, loss:49.01287841796875\n","2021-03-22 12:01:46,599 INFO train:  20/100, loss:49.012813568115234\n","2021-03-22 12:01:56,686 INFO train:  20/100, loss:49.012840270996094\n","2021-03-22 12:02:08,241 INFO train:  20/100, loss:49.01282501220703\n","2021-03-22 12:02:22,237 INFO train:  20/100, loss:49.01285171508789\n","2021-03-22 12:02:29,256 INFO train:  20/100, loss:49.01276397705078\n","2021-03-22 12:02:38,863 INFO train:  20/100, loss:49.012840270996094\n","2021-03-22 12:02:49,209 INFO train:  20/100, loss:49.0128288269043\n","2021-03-22 12:03:01,816 INFO train:  20/100, loss:49.01287841796875\n","2021-03-22 12:03:12,106 INFO train:  20/100, loss:49.012840270996094\n","2021-03-22 12:03:22,057 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 12:03:33,935 INFO train:  20/100, loss:49.01273727416992\n","2021-03-22 12:03:42,819 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 12:03:57,550 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:04:05,366 INFO train:  20/100, loss:49.01279830932617\n","2021-03-22 12:04:16,955 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:04:28,906 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 12:04:38,586 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 12:04:48,236 INFO train:  20/100, loss:49.012874603271484\n","2021-03-22 12:05:01,866 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:05:08,807 INFO train:  20/100, loss:49.01283264160156\n","2021-03-22 12:05:18,773 INFO train:  20/100, loss:49.01283645629883\n","2021-03-22 12:05:33,463 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 12:05:40,706 INFO train:  20/100, loss:49.012874603271484\n","2021-03-22 12:05:49,584 INFO train:  20/100, loss:49.012779235839844\n","2021-03-22 12:05:59,479 INFO train:  20/100, loss:49.012874603271484\n","2021-03-22 12:06:10,447 INFO train:  20/100, loss:49.012840270996094\n","2021-03-22 12:06:20,174 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 12:06:32,276 INFO train:  20/100, loss:49.01280975341797\n","2021-03-22 12:06:41,510 INFO train:  20/100, loss:49.01287078857422\n","2021-03-22 12:06:51,884 INFO train:  20/100, loss:49.01284408569336\n","2021-03-22 12:07:07,811 INFO train:  20/100, loss:49.01279830932617\n","2021-03-22 12:07:15,499 INFO train:  20/100, loss:49.01285934448242\n","2021-03-22 12:07:24,261 INFO train:  20/100, loss:49.01279830932617\n","2021-03-22 12:07:35,671 INFO train:  20/100, loss:49.01287078857422\n","2021-03-22 12:07:44,807 INFO train:  20/100, loss:49.01286315917969\n","2021-03-22 12:07:54,641 INFO train:  20/100, loss:49.01282501220703\n","2021-03-22 12:08:05,501 INFO train:  20/100, loss:49.012840270996094\n","2021-03-22 12:08:17,824 INFO train:  20/100, loss:49.01282501220703\n","2021-03-22 12:08:30,337 INFO train:  20/100, loss:49.01271438598633\n","2021-03-22 12:08:39,437 INFO val:  20/100, loss:49.01285934448242\n","2021-03-22 12:08:51,301 INFO val:  20/100, loss:49.0128288269043\n","2021-03-22 12:09:03,711 INFO val:  20/100, loss:49.01279830932617\n","2021-03-22 12:09:12,842 INFO val:  20/100, loss:49.01284408569336\n","2021-03-22 12:09:14,952 INFO train time 14253.66442489624, 20/100\n","2021-03-22 12:09:14,956 INFO Epoch 21/100\n","2021-03-22 12:09:14,960 INFO ----------\n","2021-03-22 12:09:23,231 INFO train:  21/100, loss:49.012786865234375\n","2021-03-22 12:09:33,008 INFO train:  21/100, loss:49.01285934448242\n","2021-03-22 12:09:43,722 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:09:53,401 INFO train:  21/100, loss:49.01286697387695\n","2021-03-22 12:10:04,988 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:10:14,555 INFO train:  21/100, loss:49.01286315917969\n","2021-03-22 12:10:25,125 INFO train:  21/100, loss:49.01282501220703\n","2021-03-22 12:10:39,825 INFO train:  21/100, loss:49.01283645629883\n","2021-03-22 12:10:46,444 INFO train:  21/100, loss:49.012847900390625\n","2021-03-22 12:10:57,632 INFO train:  21/100, loss:49.01283645629883\n","2021-03-22 12:11:07,746 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:11:17,456 INFO train:  21/100, loss:49.01283645629883\n","2021-03-22 12:11:27,713 INFO train:  21/100, loss:49.01279830932617\n","2021-03-22 12:11:40,603 INFO train:  21/100, loss:49.0128173828125\n","2021-03-22 12:11:49,625 INFO train:  21/100, loss:49.012847900390625\n","2021-03-22 12:11:59,923 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:12:10,614 INFO train:  21/100, loss:49.01287078857422\n","2021-03-22 12:12:20,457 INFO train:  21/100, loss:49.0128173828125\n","2021-03-22 12:12:32,519 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:12:41,681 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:12:52,824 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:13:04,985 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:13:14,776 INFO train:  21/100, loss:49.01285934448242\n","2021-03-22 12:13:26,283 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:13:35,474 INFO train:  21/100, loss:49.01279830932617\n","2021-03-22 12:13:45,646 INFO train:  21/100, loss:49.01285934448242\n","2021-03-22 12:13:57,979 INFO train:  21/100, loss:49.01285934448242\n","2021-03-22 12:14:06,961 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:14:18,485 INFO train:  21/100, loss:49.01285934448242\n","2021-03-22 12:14:30,737 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:14:37,980 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:14:49,454 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:14:58,760 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:15:12,666 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:15:19,343 INFO train:  21/100, loss:49.01274108886719\n","2021-03-22 12:15:32,639 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:15:39,471 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:15:50,588 INFO train:  21/100, loss:49.01287078857422\n","2021-03-22 12:15:59,866 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:16:14,512 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:16:22,721 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:16:31,113 INFO train:  21/100, loss:49.01287841796875\n","2021-03-22 12:16:42,485 INFO train:  21/100, loss:49.01286697387695\n","2021-03-22 12:16:52,416 INFO train:  21/100, loss:49.01282501220703\n","2021-03-22 12:17:03,566 INFO train:  21/100, loss:49.01280212402344\n","2021-03-22 12:17:11,986 INFO train:  21/100, loss:49.01283264160156\n","2021-03-22 12:17:22,290 INFO train:  21/100, loss:49.012855529785156\n","2021-03-22 12:17:34,809 INFO train:  21/100, loss:49.01287841796875\n","2021-03-22 12:17:42,437 INFO train:  21/100, loss:49.01285171508789\n","2021-03-22 12:17:53,160 INFO train:  21/100, loss:49.012874603271484\n","2021-03-22 12:18:03,994 INFO train:  21/100, loss:49.01288604736328\n","2021-03-22 12:18:18,778 INFO train:  21/100, loss:49.012786865234375\n","2021-03-22 12:18:25,833 INFO train:  21/100, loss:49.012874603271484\n","2021-03-22 12:18:36,605 INFO train:  21/100, loss:49.0128173828125\n","2021-03-22 12:18:46,546 INFO train:  21/100, loss:49.0128173828125\n","2021-03-22 12:18:57,323 INFO train:  21/100, loss:49.012874603271484\n","2021-03-22 12:19:07,684 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:19:17,135 INFO train:  21/100, loss:49.01286315917969\n","2021-03-22 12:19:27,117 INFO train:  21/100, loss:49.01283645629883\n","2021-03-22 12:19:37,695 INFO train:  21/100, loss:49.012840270996094\n","2021-03-22 12:19:49,628 INFO train:  21/100, loss:49.0128173828125\n","2021-03-22 12:19:58,993 INFO train:  21/100, loss:49.01284408569336\n","2021-03-22 12:20:10,776 INFO train:  21/100, loss:49.0128059387207\n","2021-03-22 12:20:19,798 INFO val:  21/100, loss:49.01287841796875\n","2021-03-22 12:20:29,726 INFO val:  21/100, loss:49.012840270996094\n","2021-03-22 12:20:41,384 INFO val:  21/100, loss:49.01284408569336\n","2021-03-22 12:20:50,707 INFO val:  21/100, loss:49.01284408569336\n","2021-03-22 12:20:53,010 INFO train time 14951.660144805908, 21/100\n","2021-03-22 12:20:53,011 INFO Epoch 22/100\n","2021-03-22 12:20:53,020 INFO ----------\n","2021-03-22 12:21:02,049 INFO train:  22/100, loss:49.01276779174805\n","2021-03-22 12:21:12,320 INFO train:  22/100, loss:49.01284408569336\n","2021-03-22 12:21:24,100 INFO train:  22/100, loss:49.01283645629883\n","2021-03-22 12:21:32,871 INFO train:  22/100, loss:49.012847900390625\n","2021-03-22 12:21:44,752 INFO train:  22/100, loss:49.0128173828125\n","2021-03-22 12:21:56,185 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:22:05,425 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:22:15,277 INFO train:  22/100, loss:49.01277542114258\n","2021-03-22 12:22:26,485 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:22:36,121 INFO train:  22/100, loss:49.012874603271484\n","2021-03-22 12:22:46,923 INFO train:  22/100, loss:49.012855529785156\n","2021-03-22 12:22:57,566 INFO train:  22/100, loss:49.01283645629883\n","2021-03-22 12:23:08,595 INFO train:  22/100, loss:49.0128173828125\n","2021-03-22 12:23:18,820 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:23:30,873 INFO train:  22/100, loss:49.012855529785156\n","2021-03-22 12:23:39,466 INFO train:  22/100, loss:49.01286315917969\n","2021-03-22 12:23:52,515 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:24:03,667 INFO train:  22/100, loss:49.01283645629883\n","2021-03-22 12:24:13,677 INFO train:  22/100, loss:49.01280975341797\n","2021-03-22 12:24:25,354 INFO train:  22/100, loss:49.01284408569336\n","2021-03-22 12:24:35,130 INFO train:  22/100, loss:49.01285171508789\n","2021-03-22 12:24:45,664 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:24:57,467 INFO train:  22/100, loss:49.0128173828125\n","2021-03-22 12:25:06,343 INFO train:  22/100, loss:49.01283264160156\n","2021-03-22 12:25:17,384 INFO train:  22/100, loss:49.01280975341797\n","2021-03-22 12:25:29,343 INFO train:  22/100, loss:49.01280975341797\n","2021-03-22 12:25:39,467 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:25:50,162 INFO train:  22/100, loss:49.0128059387207\n","2021-03-22 12:26:01,676 INFO train:  22/100, loss:49.01280975341797\n","2021-03-22 12:26:10,681 INFO train:  22/100, loss:49.01287841796875\n","2021-03-22 12:26:22,344 INFO train:  22/100, loss:49.012847900390625\n","2021-03-22 12:26:31,039 INFO train:  22/100, loss:49.01279830932617\n","2021-03-22 12:26:42,098 INFO train:  22/100, loss:49.01284408569336\n","2021-03-22 12:26:54,189 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:27:05,693 INFO train:  22/100, loss:49.0128059387207\n","2021-03-22 12:27:14,950 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:27:25,794 INFO train:  22/100, loss:49.01287841796875\n","2021-03-22 12:27:36,658 INFO train:  22/100, loss:49.01279067993164\n","2021-03-22 12:27:46,970 INFO train:  22/100, loss:49.01283645629883\n","2021-03-22 12:27:57,668 INFO train:  22/100, loss:49.01280975341797\n","2021-03-22 12:28:09,385 INFO train:  22/100, loss:49.01283264160156\n","2021-03-22 12:28:18,135 INFO train:  22/100, loss:49.01283264160156\n","2021-03-22 12:28:29,328 INFO train:  22/100, loss:49.01282501220703\n","2021-03-22 12:28:39,760 INFO train:  22/100, loss:49.01287841796875\n","2021-03-22 12:28:49,624 INFO train:  22/100, loss:49.01284408569336\n","2021-03-22 12:29:03,092 INFO train:  22/100, loss:49.012855529785156\n","2021-03-22 12:29:09,883 INFO train:  22/100, loss:49.01282501220703\n","2021-03-22 12:29:19,990 INFO train:  22/100, loss:49.01283645629883\n","2021-03-22 12:29:32,403 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:29:40,847 INFO train:  22/100, loss:49.012874603271484\n","2021-03-22 12:29:52,136 INFO train:  22/100, loss:49.01285171508789\n","2021-03-22 12:30:02,379 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:30:14,825 INFO train:  22/100, loss:49.0128059387207\n","2021-03-22 12:30:25,114 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:30:36,899 INFO train:  22/100, loss:49.01279830932617\n","2021-03-22 12:30:47,790 INFO train:  22/100, loss:49.012840270996094\n","2021-03-22 12:30:57,649 INFO train:  22/100, loss:49.01274108886719\n","2021-03-22 12:31:11,507 INFO train:  22/100, loss:49.0128173828125\n","2021-03-22 12:31:17,970 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:31:30,707 INFO train:  22/100, loss:49.0128288269043\n","2021-03-22 12:31:38,974 INFO train:  22/100, loss:49.01285934448242\n","2021-03-22 12:31:49,092 INFO train:  22/100, loss:49.012821197509766\n","2021-03-22 12:31:58,798 INFO train:  22/100, loss:49.01276397705078\n","2021-03-22 12:32:10,336 INFO val:  22/100, loss:49.01287841796875\n","2021-03-22 12:32:21,392 INFO val:  22/100, loss:49.012855529785156\n","2021-03-22 12:32:36,841 INFO val:  22/100, loss:49.01284408569336\n","2021-03-22 12:32:45,567 INFO val:  22/100, loss:49.01283264160156\n","2021-03-22 12:32:45,814 INFO train time 15664.525974988937, 22/100\n","2021-03-22 12:32:45,816 INFO Epoch 23/100\n","2021-03-22 12:32:45,822 INFO ----------\n","2021-03-22 12:32:55,582 INFO train:  23/100, loss:49.012840270996094\n","2021-03-22 12:33:05,762 INFO train:  23/100, loss:49.0128173828125\n","2021-03-22 12:33:16,906 INFO train:  23/100, loss:49.01285934448242\n","2021-03-22 12:33:26,789 INFO train:  23/100, loss:49.0128059387207\n","2021-03-22 12:33:38,289 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:33:47,236 INFO train:  23/100, loss:49.01283264160156\n","2021-03-22 12:33:58,409 INFO train:  23/100, loss:49.012847900390625\n","2021-03-22 12:34:11,134 INFO train:  23/100, loss:49.01282501220703\n","2021-03-22 12:34:19,516 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:34:30,504 INFO train:  23/100, loss:49.012847900390625\n","2021-03-22 12:34:42,482 INFO train:  23/100, loss:49.01283645629883\n","2021-03-22 12:34:51,500 INFO train:  23/100, loss:49.0128288269043\n","2021-03-22 12:35:03,064 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:35:16,955 INFO train:  23/100, loss:49.01285171508789\n","2021-03-22 12:35:26,482 INFO train:  23/100, loss:49.012840270996094\n","2021-03-22 12:35:37,203 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:35:46,679 INFO train:  23/100, loss:49.01282501220703\n","2021-03-22 12:35:57,023 INFO train:  23/100, loss:49.012847900390625\n","2021-03-22 12:36:08,484 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:36:17,877 INFO train:  23/100, loss:49.01283264160156\n","2021-03-22 12:36:28,722 INFO train:  23/100, loss:49.01285934448242\n","2021-03-22 12:36:39,565 INFO train:  23/100, loss:49.01286697387695\n","2021-03-22 12:36:49,551 INFO train:  23/100, loss:49.0128288269043\n","2021-03-22 12:37:01,076 INFO train:  23/100, loss:49.012840270996094\n","2021-03-22 12:37:10,792 INFO train:  23/100, loss:49.01287078857422\n","2021-03-22 12:37:21,481 INFO train:  23/100, loss:49.01287841796875\n","2021-03-22 12:37:32,829 INFO train:  23/100, loss:49.01285171508789\n","2021-03-22 12:37:44,160 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:37:53,475 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:38:05,351 INFO train:  23/100, loss:49.01285934448242\n","2021-03-22 12:38:18,612 INFO train:  23/100, loss:49.0128059387207\n","2021-03-22 12:38:26,230 INFO train:  23/100, loss:49.01282501220703\n","2021-03-22 12:38:38,363 INFO train:  23/100, loss:49.01283645629883\n","2021-03-22 12:38:48,784 INFO train:  23/100, loss:49.012813568115234\n","2021-03-22 12:39:02,021 INFO train:  23/100, loss:49.012874603271484\n","2021-03-22 12:39:08,589 INFO train:  23/100, loss:49.01282501220703\n","2021-03-22 12:39:19,642 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:39:31,835 INFO train:  23/100, loss:49.012821197509766\n","2021-03-22 12:39:40,164 INFO train:  23/100, loss:49.01280975341797\n","2021-03-22 12:39:51,615 INFO train:  23/100, loss:49.01283264160156\n","2021-03-22 12:40:02,367 INFO train:  23/100, loss:49.01285171508789\n","2021-03-22 12:40:12,723 INFO train:  23/100, loss:49.012813568115234\n","2021-03-22 12:40:22,418 INFO train:  23/100, loss:49.01285934448242\n","2021-03-22 12:40:32,879 INFO train:  23/100, loss:49.01286315917969\n","2021-03-22 12:40:43,830 INFO train:  23/100, loss:49.012840270996094\n","2021-03-22 12:40:53,807 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:41:04,604 INFO train:  23/100, loss:49.01287841796875\n","2021-03-22 12:41:14,504 INFO train:  23/100, loss:49.01279830932617\n","2021-03-22 12:41:26,402 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:41:35,132 INFO train:  23/100, loss:49.01285171508789\n","2021-03-22 12:41:48,145 INFO train:  23/100, loss:49.01283645629883\n","2021-03-22 12:41:56,465 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:42:05,447 INFO train:  23/100, loss:49.01277160644531\n","2021-03-22 12:42:18,382 INFO train:  23/100, loss:49.012786865234375\n","2021-03-22 12:42:26,593 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:42:37,200 INFO train:  23/100, loss:49.0128173828125\n","2021-03-22 12:42:49,982 INFO train:  23/100, loss:49.01285934448242\n","2021-03-22 12:42:59,289 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:43:08,501 INFO train:  23/100, loss:49.0128059387207\n","2021-03-22 12:43:22,060 INFO train:  23/100, loss:49.0128059387207\n","2021-03-22 12:43:31,083 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:43:40,072 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:43:54,156 INFO train:  23/100, loss:49.01284408569336\n","2021-03-22 12:44:00,674 INFO val:  23/100, loss:49.01283645629883\n","2021-03-22 12:44:10,922 INFO val:  23/100, loss:49.01282501220703\n","2021-03-22 12:44:22,423 INFO val:  23/100, loss:49.01287841796875\n","2021-03-22 12:44:31,673 INFO val:  23/100, loss:49.01283264160156\n","2021-03-22 12:44:34,604 INFO train time 16373.282559871674, 23/100\n","2021-03-22 12:44:34,606 INFO Epoch 24/100\n","2021-03-22 12:44:34,613 INFO ----------\n","2021-03-22 12:44:42,584 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:44:53,788 INFO train:  24/100, loss:49.0128173828125\n","2021-03-22 12:45:05,615 INFO train:  24/100, loss:49.01285934448242\n","2021-03-22 12:45:15,681 INFO train:  24/100, loss:49.01286697387695\n","2021-03-22 12:45:26,933 INFO train:  24/100, loss:49.012847900390625\n","2021-03-22 12:45:35,773 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:45:46,993 INFO train:  24/100, loss:49.01287078857422\n","2021-03-22 12:45:57,146 INFO train:  24/100, loss:49.01283645629883\n","2021-03-22 12:46:08,524 INFO train:  24/100, loss:49.01285934448242\n","2021-03-22 12:46:18,614 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:46:29,257 INFO train:  24/100, loss:49.012855529785156\n","2021-03-22 12:46:39,656 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:46:49,479 INFO train:  24/100, loss:49.01282501220703\n","2021-03-22 12:46:59,963 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:47:09,843 INFO train:  24/100, loss:49.01286697387695\n","2021-03-22 12:47:22,611 INFO train:  24/100, loss:49.01285171508789\n","2021-03-22 12:47:31,395 INFO train:  24/100, loss:49.01282501220703\n","2021-03-22 12:47:41,679 INFO train:  24/100, loss:49.01286315917969\n","2021-03-22 12:47:54,000 INFO train:  24/100, loss:49.01280975341797\n","2021-03-22 12:48:04,440 INFO train:  24/100, loss:49.01282501220703\n","2021-03-22 12:48:14,979 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:48:26,554 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:48:35,537 INFO train:  24/100, loss:49.01283645629883\n","2021-03-22 12:48:45,659 INFO train:  24/100, loss:49.01283264160156\n","2021-03-22 12:48:56,080 INFO train:  24/100, loss:49.01285171508789\n","2021-03-22 12:49:07,121 INFO train:  24/100, loss:49.01287841796875\n","2021-03-22 12:49:17,002 INFO train:  24/100, loss:49.01279830932617\n","2021-03-22 12:49:28,721 INFO train:  24/100, loss:49.01280212402344\n","2021-03-22 12:49:37,175 INFO train:  24/100, loss:49.01279067993164\n","2021-03-22 12:49:48,804 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:49:59,103 INFO train:  24/100, loss:49.0128059387207\n","2021-03-22 12:50:08,694 INFO train:  24/100, loss:49.01282501220703\n","2021-03-22 12:50:20,912 INFO train:  24/100, loss:49.01285934448242\n","2021-03-22 12:50:30,557 INFO train:  24/100, loss:49.01285171508789\n","2021-03-22 12:50:41,564 INFO train:  24/100, loss:49.01280975341797\n","2021-03-22 12:50:50,641 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:51:02,848 INFO train:  24/100, loss:49.012874603271484\n","2021-03-22 12:51:11,999 INFO train:  24/100, loss:49.01287078857422\n","2021-03-22 12:51:21,547 INFO train:  24/100, loss:49.01285171508789\n","2021-03-22 12:51:33,941 INFO train:  24/100, loss:49.01280975341797\n","2021-03-22 12:51:43,351 INFO train:  24/100, loss:49.0128059387207\n","2021-03-22 12:51:54,932 INFO train:  24/100, loss:49.0128059387207\n","2021-03-22 12:52:04,795 INFO train:  24/100, loss:49.01286315917969\n","2021-03-22 12:52:16,693 INFO train:  24/100, loss:49.01283264160156\n","2021-03-22 12:52:24,720 INFO train:  24/100, loss:49.012874603271484\n","2021-03-22 12:52:38,281 INFO train:  24/100, loss:49.01286697387695\n","2021-03-22 12:52:50,579 INFO train:  24/100, loss:49.01286315917969\n","2021-03-22 12:53:00,005 INFO train:  24/100, loss:49.01282501220703\n","2021-03-22 12:53:10,781 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:53:21,106 INFO train:  24/100, loss:49.01283645629883\n","2021-03-22 12:53:33,101 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:53:42,618 INFO train:  24/100, loss:49.012821197509766\n","2021-03-22 12:53:53,695 INFO train:  24/100, loss:49.01278305053711\n","2021-03-22 12:54:02,621 INFO train:  24/100, loss:49.01284408569336\n","2021-03-22 12:54:13,908 INFO train:  24/100, loss:49.0128173828125\n","2021-03-22 12:54:23,940 INFO train:  24/100, loss:49.01283264160156\n","2021-03-22 12:54:35,003 INFO train:  24/100, loss:49.01285934448242\n","2021-03-22 12:54:44,941 INFO train:  24/100, loss:49.012840270996094\n","2021-03-22 12:54:55,484 INFO train:  24/100, loss:49.01280975341797\n","2021-03-22 12:55:07,239 INFO train:  24/100, loss:49.0128173828125\n","2021-03-22 12:55:16,401 INFO train:  24/100, loss:49.01283645629883\n","2021-03-22 12:55:27,477 INFO train:  24/100, loss:49.01285171508789\n","2021-03-22 12:55:38,635 INFO train:  24/100, loss:49.01287078857422\n","2021-03-22 12:55:50,703 INFO val:  24/100, loss:49.01283264160156\n","2021-03-22 12:56:04,151 INFO val:  24/100, loss:49.01285171508789\n","2021-03-22 12:56:11,277 INFO val:  24/100, loss:49.01274871826172\n","2021-03-22 12:56:21,793 INFO val:  24/100, loss:49.012794494628906\n","2021-03-22 12:56:23,197 INFO train time 17081.89007282257, 24/100\n","2021-03-22 12:56:23,199 INFO Epoch 25/100\n","2021-03-22 12:56:23,206 INFO ----------\n","2021-03-22 12:56:36,121 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 12:56:44,329 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 12:56:54,664 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 12:57:05,746 INFO train:  25/100, loss:49.01287078857422\n","2021-03-22 12:57:15,554 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 12:57:27,780 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 12:57:36,724 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 12:57:47,090 INFO train:  25/100, loss:49.01277542114258\n","2021-03-22 12:57:58,204 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 12:58:07,430 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 12:58:18,742 INFO train:  25/100, loss:49.012847900390625\n","2021-03-22 12:58:27,684 INFO train:  25/100, loss:49.01282501220703\n","2021-03-22 12:58:39,180 INFO train:  25/100, loss:49.0128173828125\n","2021-03-22 12:58:48,735 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 12:59:00,058 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 12:59:10,932 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 12:59:24,372 INFO train:  25/100, loss:49.01283645629883\n","2021-03-22 12:59:32,367 INFO train:  25/100, loss:49.01287841796875\n","2021-03-22 12:59:42,697 INFO train:  25/100, loss:49.01280212402344\n","2021-03-22 12:59:54,375 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 13:00:08,310 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 13:00:15,860 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 13:00:26,442 INFO train:  25/100, loss:49.012840270996094\n","2021-03-22 13:00:38,570 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 13:00:47,860 INFO train:  25/100, loss:49.012786865234375\n","2021-03-22 13:01:00,725 INFO train:  25/100, loss:49.01276779174805\n","2021-03-22 13:01:10,864 INFO train:  25/100, loss:49.01278305053711\n","2021-03-22 13:01:21,306 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 13:01:30,184 INFO train:  25/100, loss:49.012725830078125\n","2021-03-22 13:01:41,075 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 13:01:52,176 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 13:02:02,542 INFO train:  25/100, loss:49.01287841796875\n","2021-03-22 13:02:12,975 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 13:02:24,261 INFO train:  25/100, loss:49.01280975341797\n","2021-03-22 13:02:34,856 INFO train:  25/100, loss:49.01279067993164\n","2021-03-22 13:02:44,198 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 13:02:54,854 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 13:03:06,249 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 13:03:15,138 INFO train:  25/100, loss:49.01285934448242\n","2021-03-22 13:03:25,086 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 13:03:37,226 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 13:03:46,336 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 13:03:58,470 INFO train:  25/100, loss:49.01283645629883\n","2021-03-22 13:04:08,323 INFO train:  25/100, loss:49.0128059387207\n","2021-03-22 13:04:19,362 INFO train:  25/100, loss:49.01286697387695\n","2021-03-22 13:04:31,480 INFO train:  25/100, loss:49.012847900390625\n","2021-03-22 13:04:41,508 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 13:04:53,330 INFO train:  25/100, loss:49.012840270996094\n","2021-03-22 13:05:03,095 INFO train:  25/100, loss:49.01284408569336\n","2021-03-22 13:05:14,990 INFO train:  25/100, loss:49.01282501220703\n","2021-03-22 13:05:24,694 INFO train:  25/100, loss:49.01283264160156\n","2021-03-22 13:05:35,269 INFO train:  25/100, loss:49.012874603271484\n","2021-03-22 13:05:46,637 INFO train:  25/100, loss:49.01277542114258\n","2021-03-22 13:05:56,123 INFO train:  25/100, loss:49.01287078857422\n","2021-03-22 13:06:08,680 INFO train:  25/100, loss:49.01286697387695\n","2021-03-22 13:06:18,549 INFO train:  25/100, loss:49.01282501220703\n","2021-03-22 13:06:32,179 INFO train:  25/100, loss:49.01272964477539\n","2021-03-22 13:06:40,204 INFO train:  25/100, loss:49.01286697387695\n","2021-03-22 13:06:50,347 INFO train:  25/100, loss:49.01282501220703\n","2021-03-22 13:07:01,185 INFO train:  25/100, loss:49.0128288269043\n","2021-03-22 13:07:12,471 INFO train:  25/100, loss:49.0128173828125\n","2021-03-22 13:07:21,558 INFO train:  25/100, loss:49.01285171508789\n","2021-03-22 13:07:33,576 INFO train:  25/100, loss:49.012847900390625\n","2021-03-22 13:07:43,134 INFO val:  25/100, loss:49.01286697387695\n","2021-03-22 13:07:52,265 INFO val:  25/100, loss:49.012813568115234\n","2021-03-22 13:08:02,938 INFO val:  25/100, loss:49.012779235839844\n","2021-03-22 13:08:15,159 INFO val:  25/100, loss:49.01286697387695\n","2021-03-22 13:08:15,953 INFO train time 17794.648026943207, 25/100\n","2021-03-22 13:08:15,955 INFO Epoch 26/100\n","2021-03-22 13:08:15,962 INFO ----------\n","2021-03-22 13:08:24,238 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:08:35,242 INFO train:  26/100, loss:49.01283645629883\n","2021-03-22 13:08:46,651 INFO train:  26/100, loss:49.012821197509766\n","2021-03-22 13:08:59,310 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:09:08,349 INFO train:  26/100, loss:49.0128173828125\n","2021-03-22 13:09:24,606 INFO train:  26/100, loss:49.012840270996094\n","2021-03-22 13:09:32,016 INFO train:  26/100, loss:49.012847900390625\n","2021-03-22 13:09:42,472 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:09:52,817 INFO train:  26/100, loss:49.0128173828125\n","2021-03-22 13:10:04,861 INFO train:  26/100, loss:49.01287078857422\n","2021-03-22 13:10:13,823 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:10:24,136 INFO train:  26/100, loss:49.01285171508789\n","2021-03-22 13:10:34,934 INFO train:  26/100, loss:49.012874603271484\n","2021-03-22 13:10:44,114 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:10:55,469 INFO train:  26/100, loss:49.012840270996094\n","2021-03-22 13:11:06,797 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:11:17,940 INFO train:  26/100, loss:49.012840270996094\n","2021-03-22 13:11:26,662 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:11:36,580 INFO train:  26/100, loss:49.012840270996094\n","2021-03-22 13:11:46,867 INFO train:  26/100, loss:49.0128173828125\n","2021-03-22 13:11:58,492 INFO train:  26/100, loss:49.01287078857422\n","2021-03-22 13:12:10,155 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:12:19,291 INFO train:  26/100, loss:49.012855529785156\n","2021-03-22 13:12:33,960 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:12:42,363 INFO train:  26/100, loss:49.01277542114258\n","2021-03-22 13:12:51,522 INFO train:  26/100, loss:49.012847900390625\n","2021-03-22 13:13:03,009 INFO train:  26/100, loss:49.01278305053711\n","2021-03-22 13:13:12,262 INFO train:  26/100, loss:49.01280975341797\n","2021-03-22 13:13:23,725 INFO train:  26/100, loss:49.01285171508789\n","2021-03-22 13:13:33,405 INFO train:  26/100, loss:49.012847900390625\n","2021-03-22 13:13:45,933 INFO train:  26/100, loss:49.01282501220703\n","2021-03-22 13:13:53,314 INFO train:  26/100, loss:49.01278305053711\n","2021-03-22 13:14:04,889 INFO train:  26/100, loss:49.01285171508789\n","2021-03-22 13:14:14,797 INFO train:  26/100, loss:49.01285934448242\n","2021-03-22 13:14:24,368 INFO train:  26/100, loss:49.0128059387207\n","2021-03-22 13:14:37,227 INFO train:  26/100, loss:49.01288986206055\n","2021-03-22 13:14:46,592 INFO train:  26/100, loss:49.012874603271484\n","2021-03-22 13:14:57,100 INFO train:  26/100, loss:49.012840270996094\n","2021-03-22 13:15:08,354 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:15:19,912 INFO train:  26/100, loss:49.01285171508789\n","2021-03-22 13:15:31,694 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:15:40,332 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:15:51,601 INFO train:  26/100, loss:49.01278305053711\n","2021-03-22 13:16:01,545 INFO train:  26/100, loss:49.012874603271484\n","2021-03-22 13:16:10,582 INFO train:  26/100, loss:49.01285171508789\n","2021-03-22 13:16:21,161 INFO train:  26/100, loss:49.012874603271484\n","2021-03-22 13:16:32,184 INFO train:  26/100, loss:49.012794494628906\n","2021-03-22 13:16:41,150 INFO train:  26/100, loss:49.01283264160156\n","2021-03-22 13:16:52,115 INFO train:  26/100, loss:49.01283264160156\n","2021-03-22 13:17:02,112 INFO train:  26/100, loss:49.01287841796875\n","2021-03-22 13:17:12,735 INFO train:  26/100, loss:49.01286315917969\n","2021-03-22 13:17:24,918 INFO train:  26/100, loss:49.01280212402344\n","2021-03-22 13:17:33,735 INFO train:  26/100, loss:49.01287078857422\n","2021-03-22 13:17:44,678 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:17:56,079 INFO train:  26/100, loss:49.01280975341797\n","2021-03-22 13:18:05,555 INFO train:  26/100, loss:49.012855529785156\n","2021-03-22 13:18:17,565 INFO train:  26/100, loss:49.01285934448242\n","2021-03-22 13:18:25,853 INFO train:  26/100, loss:49.01286697387695\n","2021-03-22 13:18:35,487 INFO train:  26/100, loss:49.01282501220703\n","2021-03-22 13:18:47,917 INFO train:  26/100, loss:49.0128059387207\n","2021-03-22 13:18:58,610 INFO train:  26/100, loss:49.01282501220703\n","2021-03-22 13:19:07,512 INFO train:  26/100, loss:49.01285934448242\n","2021-03-22 13:19:17,713 INFO train:  26/100, loss:49.01284408569336\n","2021-03-22 13:19:27,357 INFO val:  26/100, loss:49.01285934448242\n","2021-03-22 13:19:39,123 INFO val:  26/100, loss:49.012840270996094\n","2021-03-22 13:19:51,862 INFO val:  26/100, loss:49.01284408569336\n","2021-03-22 13:20:01,158 INFO val:  26/100, loss:49.01283645629883\n","2021-03-22 13:20:03,983 INFO train time 18502.62239432335, 26/100\n","2021-03-22 13:20:03,984 INFO Epoch 27/100\n","2021-03-22 13:20:03,990 INFO ----------\n","2021-03-22 13:20:12,831 INFO train:  27/100, loss:49.012840270996094\n","2021-03-22 13:20:23,606 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:20:33,548 INFO train:  27/100, loss:49.0128059387207\n","2021-03-22 13:20:45,422 INFO train:  27/100, loss:49.01283645629883\n","2021-03-22 13:20:54,977 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:21:05,890 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:21:16,565 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:21:26,138 INFO train:  27/100, loss:49.01279067993164\n","2021-03-22 13:21:37,771 INFO train:  27/100, loss:49.01282501220703\n","2021-03-22 13:21:47,058 INFO train:  27/100, loss:49.01283645629883\n","2021-03-22 13:21:58,783 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:22:07,489 INFO train:  27/100, loss:49.012855529785156\n","2021-03-22 13:22:20,200 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:22:32,964 INFO train:  27/100, loss:49.0128173828125\n","2021-03-22 13:22:40,843 INFO train:  27/100, loss:49.012855529785156\n","2021-03-22 13:22:48,842 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:23:00,823 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:23:11,543 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:23:21,502 INFO train:  27/100, loss:49.0128059387207\n","2021-03-22 13:23:31,686 INFO train:  27/100, loss:49.01280212402344\n","2021-03-22 13:23:43,850 INFO train:  27/100, loss:49.0128059387207\n","2021-03-22 13:23:52,880 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:24:03,105 INFO train:  27/100, loss:49.01279830932617\n","2021-03-22 13:24:14,624 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:24:28,940 INFO train:  27/100, loss:49.012794494628906\n","2021-03-22 13:24:35,679 INFO train:  27/100, loss:49.0128288269043\n","2021-03-22 13:24:45,130 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:24:57,486 INFO train:  27/100, loss:49.01280975341797\n","2021-03-22 13:25:06,100 INFO train:  27/100, loss:49.01279067993164\n","2021-03-22 13:25:15,269 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:25:27,397 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:25:36,580 INFO train:  27/100, loss:49.012882232666016\n","2021-03-22 13:25:47,857 INFO train:  27/100, loss:49.01286315917969\n","2021-03-22 13:25:58,978 INFO train:  27/100, loss:49.01279830932617\n","2021-03-22 13:26:09,670 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:26:20,835 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:26:30,344 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:26:40,368 INFO train:  27/100, loss:49.0128288269043\n","2021-03-22 13:26:51,962 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:27:03,814 INFO train:  27/100, loss:49.01287078857422\n","2021-03-22 13:27:15,679 INFO train:  27/100, loss:49.012847900390625\n","2021-03-22 13:27:24,424 INFO train:  27/100, loss:49.01282501220703\n","2021-03-22 13:27:36,479 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:27:49,024 INFO train:  27/100, loss:49.012874603271484\n","2021-03-22 13:28:02,308 INFO train:  27/100, loss:49.012847900390625\n","2021-03-22 13:28:09,497 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:28:19,003 INFO train:  27/100, loss:49.01280975341797\n","2021-03-22 13:28:30,469 INFO train:  27/100, loss:49.01279067993164\n","2021-03-22 13:28:40,864 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:28:51,943 INFO train:  27/100, loss:49.01285171508789\n","2021-03-22 13:29:03,119 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:29:13,634 INFO train:  27/100, loss:49.01287841796875\n","2021-03-22 13:29:24,278 INFO train:  27/100, loss:49.012813568115234\n","2021-03-22 13:29:36,482 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:29:46,673 INFO train:  27/100, loss:49.01287841796875\n","2021-03-22 13:29:57,446 INFO train:  27/100, loss:49.01282501220703\n","2021-03-22 13:30:11,751 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:30:20,298 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:30:28,812 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:30:39,832 INFO train:  27/100, loss:49.01286697387695\n","2021-03-22 13:30:50,809 INFO train:  27/100, loss:49.01285934448242\n","2021-03-22 13:31:02,243 INFO train:  27/100, loss:49.01284408569336\n","2021-03-22 13:31:11,927 INFO train:  27/100, loss:49.012840270996094\n","2021-03-22 13:31:20,300 INFO val:  27/100, loss:49.01284408569336\n","2021-03-22 13:31:30,544 INFO val:  27/100, loss:49.01279830932617\n","2021-03-22 13:31:42,782 INFO val:  27/100, loss:49.01282501220703\n","2021-03-22 13:31:53,959 INFO val:  27/100, loss:49.01284408569336\n","2021-03-22 13:31:54,958 INFO train time 19213.646731376648, 27/100\n","2021-03-22 13:31:54,959 INFO Epoch 28/100\n","2021-03-22 13:31:54,967 INFO ----------\n","2021-03-22 13:32:04,859 INFO train:  28/100, loss:49.01268005371094\n","2021-03-22 13:32:14,668 INFO train:  28/100, loss:49.012786865234375\n","2021-03-22 13:32:26,670 INFO train:  28/100, loss:49.01285934448242\n","2021-03-22 13:32:36,859 INFO train:  28/100, loss:49.01285171508789\n","2021-03-22 13:32:47,204 INFO train:  28/100, loss:49.012847900390625\n","2021-03-22 13:32:59,312 INFO train:  28/100, loss:49.01286697387695\n","2021-03-22 13:33:09,751 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:33:20,176 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:33:29,603 INFO train:  28/100, loss:49.01282501220703\n","2021-03-22 13:33:44,800 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:33:55,046 INFO train:  28/100, loss:49.01283645629883\n","2021-03-22 13:34:04,381 INFO train:  28/100, loss:49.0128288269043\n","2021-03-22 13:34:13,571 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:34:23,999 INFO train:  28/100, loss:49.012840270996094\n","2021-03-22 13:34:34,942 INFO train:  28/100, loss:49.01286315917969\n","2021-03-22 13:34:45,348 INFO train:  28/100, loss:49.01286697387695\n","2021-03-22 13:34:55,651 INFO train:  28/100, loss:49.01286697387695\n","2021-03-22 13:35:06,648 INFO train:  28/100, loss:49.012840270996094\n","2021-03-22 13:35:17,737 INFO train:  28/100, loss:49.012813568115234\n","2021-03-22 13:35:28,134 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:35:39,331 INFO train:  28/100, loss:49.01285934448242\n","2021-03-22 13:35:49,764 INFO train:  28/100, loss:49.01286315917969\n","2021-03-22 13:36:03,102 INFO train:  28/100, loss:49.01286315917969\n","2021-03-22 13:36:09,793 INFO train:  28/100, loss:49.012840270996094\n","2021-03-22 13:36:19,898 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:36:32,663 INFO train:  28/100, loss:49.01284408569336\n","2021-03-22 13:36:41,366 INFO train:  28/100, loss:49.01277160644531\n","2021-03-22 13:36:52,422 INFO train:  28/100, loss:49.012840270996094\n","2021-03-22 13:37:01,642 INFO train:  28/100, loss:49.0128173828125\n","2021-03-22 13:37:12,551 INFO train:  28/100, loss:49.01285171508789\n","2021-03-22 13:37:22,435 INFO train:  28/100, loss:49.01283645629883\n","2021-03-22 13:37:34,527 INFO train:  28/100, loss:49.012821197509766\n","2021-03-22 13:37:43,837 INFO train:  28/100, loss:49.01284408569336\n","2021-03-22 13:37:54,322 INFO train:  28/100, loss:49.01284408569336\n","2021-03-22 13:38:05,497 INFO train:  28/100, loss:49.01287841796875\n","2021-03-22 13:38:16,878 INFO train:  28/100, loss:49.01283645629883\n","2021-03-22 13:38:27,008 INFO train:  28/100, loss:49.01285171508789\n","2021-03-22 13:38:36,298 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:38:46,423 INFO train:  28/100, loss:49.01286697387695\n","2021-03-22 13:38:57,941 INFO train:  28/100, loss:49.012855529785156\n","2021-03-22 13:39:06,754 INFO train:  28/100, loss:49.0128059387207\n","2021-03-22 13:39:18,879 INFO train:  28/100, loss:49.01280975341797\n","2021-03-22 13:39:27,186 INFO train:  28/100, loss:49.01285934448242\n","2021-03-22 13:39:38,443 INFO train:  28/100, loss:49.0128288269043\n","2021-03-22 13:39:49,329 INFO train:  28/100, loss:49.0128173828125\n","2021-03-22 13:40:02,590 INFO train:  28/100, loss:49.01286315917969\n","2021-03-22 13:40:12,599 INFO train:  28/100, loss:49.01287841796875\n","2021-03-22 13:40:23,811 INFO train:  28/100, loss:49.012813568115234\n","2021-03-22 13:40:33,249 INFO train:  28/100, loss:49.012821197509766\n","2021-03-22 13:40:44,843 INFO train:  28/100, loss:49.0128288269043\n","2021-03-22 13:40:56,357 INFO train:  28/100, loss:49.0128173828125\n","2021-03-22 13:41:05,145 INFO train:  28/100, loss:49.01283645629883\n","2021-03-22 13:41:15,720 INFO train:  28/100, loss:49.01276397705078\n","2021-03-22 13:41:27,649 INFO train:  28/100, loss:49.01284408569336\n","2021-03-22 13:41:37,593 INFO train:  28/100, loss:49.01279067993164\n","2021-03-22 13:41:49,359 INFO train:  28/100, loss:49.01285171508789\n","2021-03-22 13:41:58,051 INFO train:  28/100, loss:49.01286315917969\n","2021-03-22 13:42:08,408 INFO train:  28/100, loss:49.01283264160156\n","2021-03-22 13:42:17,841 INFO train:  28/100, loss:49.01282501220703\n","2021-03-22 13:42:30,566 INFO train:  28/100, loss:49.01282501220703\n","2021-03-22 13:42:39,714 INFO train:  28/100, loss:49.012847900390625\n","2021-03-22 13:42:55,416 INFO train:  28/100, loss:49.0128173828125\n","2021-03-22 13:43:01,562 INFO train:  28/100, loss:49.01279830932617\n","2021-03-22 13:43:11,285 INFO val:  28/100, loss:49.01286697387695\n","2021-03-22 13:43:21,440 INFO val:  28/100, loss:49.01282501220703\n","2021-03-22 13:43:33,479 INFO val:  28/100, loss:49.01278305053711\n","2021-03-22 13:43:42,693 INFO val:  28/100, loss:49.012847900390625\n","2021-03-22 13:43:44,549 INFO train time 19923.27039217949, 28/100\n","2021-03-22 13:43:44,551 INFO Epoch 29/100\n","2021-03-22 13:43:44,559 INFO ----------\n","2021-03-22 13:43:53,007 INFO train:  29/100, loss:49.012855529785156\n","2021-03-22 13:44:03,384 INFO train:  29/100, loss:49.01286697387695\n","2021-03-22 13:44:13,975 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:44:23,978 INFO train:  29/100, loss:49.012847900390625\n","2021-03-22 13:44:35,650 INFO train:  29/100, loss:49.01286315917969\n","2021-03-22 13:44:47,661 INFO train:  29/100, loss:49.012855529785156\n","2021-03-22 13:44:58,768 INFO train:  29/100, loss:49.012847900390625\n","2021-03-22 13:45:08,668 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:45:21,438 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:45:32,048 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:45:40,737 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:45:51,211 INFO train:  29/100, loss:49.01283645629883\n","2021-03-22 13:46:00,903 INFO train:  29/100, loss:49.01280975341797\n","2021-03-22 13:46:12,799 INFO train:  29/100, loss:49.012855529785156\n","2021-03-22 13:46:22,222 INFO train:  29/100, loss:49.01285934448242\n","2021-03-22 13:46:35,200 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:46:43,645 INFO train:  29/100, loss:49.012874603271484\n","2021-03-22 13:46:53,119 INFO train:  29/100, loss:49.01283264160156\n","2021-03-22 13:47:06,638 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:47:13,607 INFO train:  29/100, loss:49.01283264160156\n","2021-03-22 13:47:24,527 INFO train:  29/100, loss:49.01280975341797\n","2021-03-22 13:47:35,051 INFO train:  29/100, loss:49.01282501220703\n","2021-03-22 13:47:45,732 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:47:55,431 INFO train:  29/100, loss:49.01282501220703\n","2021-03-22 13:48:06,056 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:48:16,697 INFO train:  29/100, loss:49.012821197509766\n","2021-03-22 13:48:29,300 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:48:38,282 INFO train:  29/100, loss:49.01287078857422\n","2021-03-22 13:48:49,656 INFO train:  29/100, loss:49.01286697387695\n","2021-03-22 13:49:00,136 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:49:10,265 INFO train:  29/100, loss:49.01283264160156\n","2021-03-22 13:49:22,982 INFO train:  29/100, loss:49.01287078857422\n","2021-03-22 13:49:29,766 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:49:41,392 INFO train:  29/100, loss:49.0128059387207\n","2021-03-22 13:49:54,680 INFO train:  29/100, loss:49.01273727416992\n","2021-03-22 13:50:03,255 INFO train:  29/100, loss:49.01285934448242\n","2021-03-22 13:50:12,823 INFO train:  29/100, loss:49.01280212402344\n","2021-03-22 13:50:26,241 INFO train:  29/100, loss:49.01285934448242\n","2021-03-22 13:50:33,693 INFO train:  29/100, loss:49.01286315917969\n","2021-03-22 13:50:45,903 INFO train:  29/100, loss:49.01286697387695\n","2021-03-22 13:50:55,353 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:51:07,678 INFO train:  29/100, loss:49.01287841796875\n","2021-03-22 13:51:18,427 INFO train:  29/100, loss:49.01283264160156\n","2021-03-22 13:51:31,598 INFO train:  29/100, loss:49.01286697387695\n","2021-03-22 13:51:38,479 INFO train:  29/100, loss:49.012821197509766\n","2021-03-22 13:51:48,918 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:51:59,160 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:52:09,722 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:52:21,076 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:52:33,719 INFO train:  29/100, loss:49.012855529785156\n","2021-03-22 13:52:42,825 INFO train:  29/100, loss:49.01279830932617\n","2021-03-22 13:52:53,269 INFO train:  29/100, loss:49.01284408569336\n","2021-03-22 13:53:04,881 INFO train:  29/100, loss:49.01287078857422\n","2021-03-22 13:53:16,547 INFO train:  29/100, loss:49.01285934448242\n","2021-03-22 13:53:24,954 INFO train:  29/100, loss:49.01282501220703\n","2021-03-22 13:53:35,729 INFO train:  29/100, loss:49.0128173828125\n","2021-03-22 13:53:44,871 INFO train:  29/100, loss:49.01278305053711\n","2021-03-22 13:53:56,157 INFO train:  29/100, loss:49.01285171508789\n","2021-03-22 13:54:08,649 INFO train:  29/100, loss:49.0128288269043\n","2021-03-22 13:54:15,860 INFO train:  29/100, loss:49.012794494628906\n","2021-03-22 13:54:25,972 INFO train:  29/100, loss:49.0128173828125\n","2021-03-22 13:54:36,813 INFO train:  29/100, loss:49.012779235839844\n","2021-03-22 13:54:46,850 INFO train:  29/100, loss:49.012840270996094\n","2021-03-22 13:54:56,172 INFO val:  29/100, loss:49.0128059387207\n","2021-03-22 13:55:07,450 INFO val:  29/100, loss:49.01280212402344\n","2021-03-22 13:55:18,144 INFO val:  29/100, loss:49.01287841796875\n","2021-03-22 13:55:29,041 INFO val:  29/100, loss:49.01286697387695\n","2021-03-22 13:55:29,935 INFO train time 20628.004769325256, 29/100\n","2021-03-22 13:55:29,938 INFO Epoch 30/100\n","2021-03-22 13:55:29,945 INFO ----------\n","2021-03-22 13:55:38,259 INFO train:  30/100, loss:49.01283264160156\n","2021-03-22 13:55:50,134 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 13:56:02,552 INFO train:  30/100, loss:49.01286697387695\n","2021-03-22 13:56:08,966 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 13:56:19,049 INFO train:  30/100, loss:49.0128059387207\n","2021-03-22 13:56:30,990 INFO train:  30/100, loss:49.012847900390625\n","2021-03-22 13:56:40,691 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 13:56:52,732 INFO train:  30/100, loss:49.0128288269043\n","2021-03-22 13:57:03,764 INFO train:  30/100, loss:49.01282501220703\n","2021-03-22 13:57:12,856 INFO train:  30/100, loss:49.01287078857422\n","2021-03-22 13:57:23,558 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 13:57:36,390 INFO train:  30/100, loss:49.012821197509766\n","2021-03-22 13:57:47,250 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 13:57:57,425 INFO train:  30/100, loss:49.01285934448242\n","2021-03-22 13:58:07,890 INFO train:  30/100, loss:49.0128059387207\n","2021-03-22 13:58:18,208 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 13:58:30,372 INFO train:  30/100, loss:49.01282501220703\n","2021-03-22 13:58:40,605 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 13:58:50,415 INFO train:  30/100, loss:49.012847900390625\n","2021-03-22 13:59:00,773 INFO train:  30/100, loss:49.01282501220703\n","2021-03-22 13:59:11,109 INFO train:  30/100, loss:49.0128173828125\n","2021-03-22 13:59:21,113 INFO train:  30/100, loss:49.01286315917969\n","2021-03-22 13:59:33,320 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 13:59:41,729 INFO train:  30/100, loss:49.01279067993164\n","2021-03-22 13:59:52,310 INFO train:  30/100, loss:49.01279067993164\n","2021-03-22 14:00:03,431 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 14:00:12,901 INFO train:  30/100, loss:49.0128288269043\n","2021-03-22 14:00:24,883 INFO train:  30/100, loss:49.012874603271484\n","2021-03-22 14:00:33,284 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 14:00:43,724 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:00:55,271 INFO train:  30/100, loss:49.01285934448242\n","2021-03-22 14:01:05,155 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 14:01:15,595 INFO train:  30/100, loss:49.012847900390625\n","2021-03-22 14:01:25,928 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 14:01:36,506 INFO train:  30/100, loss:49.012733459472656\n","2021-03-22 14:01:46,836 INFO train:  30/100, loss:49.012874603271484\n","2021-03-22 14:01:57,359 INFO train:  30/100, loss:49.01280975341797\n","2021-03-22 14:02:08,297 INFO train:  30/100, loss:49.012821197509766\n","2021-03-22 14:02:18,086 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:02:33,005 INFO train:  30/100, loss:49.01283645629883\n","2021-03-22 14:02:40,624 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:02:50,053 INFO train:  30/100, loss:49.012821197509766\n","2021-03-22 14:03:02,260 INFO train:  30/100, loss:49.01286315917969\n","2021-03-22 14:03:13,469 INFO train:  30/100, loss:49.0128288269043\n","2021-03-22 14:03:23,617 INFO train:  30/100, loss:49.0128059387207\n","2021-03-22 14:03:35,350 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 14:03:44,987 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 14:03:55,076 INFO train:  30/100, loss:49.01280975341797\n","2021-03-22 14:04:06,624 INFO train:  30/100, loss:49.01276397705078\n","2021-03-22 14:04:18,955 INFO train:  30/100, loss:49.01280975341797\n","2021-03-22 14:04:32,246 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 14:04:40,910 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:04:49,570 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:05:00,655 INFO train:  30/100, loss:49.01280975341797\n","2021-03-22 14:05:10,091 INFO train:  30/100, loss:49.01283264160156\n","2021-03-22 14:05:20,383 INFO train:  30/100, loss:49.012874603271484\n","2021-03-22 14:05:32,551 INFO train:  30/100, loss:49.01279830932617\n","2021-03-22 14:05:41,381 INFO train:  30/100, loss:49.01280975341797\n","2021-03-22 14:05:52,640 INFO train:  30/100, loss:49.01284408569336\n","2021-03-22 14:06:03,968 INFO train:  30/100, loss:49.01285171508789\n","2021-03-22 14:06:13,171 INFO train:  30/100, loss:49.012840270996094\n","2021-03-22 14:06:24,014 INFO train:  30/100, loss:49.012847900390625\n","2021-03-22 14:06:33,924 INFO train:  30/100, loss:49.01275634765625\n","2021-03-22 14:06:44,924 INFO val:  30/100, loss:49.01284408569336\n","2021-03-22 14:06:55,886 INFO val:  30/100, loss:49.012840270996094\n","2021-03-22 14:07:08,196 INFO val:  30/100, loss:49.012847900390625\n","2021-03-22 14:07:17,579 INFO val:  30/100, loss:49.012882232666016\n","2021-03-22 14:07:19,778 INFO train time 21338.481176137924, 30/100\n","2021-03-22 14:07:19,780 INFO Epoch 31/100\n","2021-03-22 14:07:19,788 INFO ----------\n","2021-03-22 14:07:27,750 INFO train:  31/100, loss:49.01283264160156\n","2021-03-22 14:07:38,626 INFO train:  31/100, loss:49.01282501220703\n","2021-03-22 14:07:50,402 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:08:03,773 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:08:12,926 INFO train:  31/100, loss:49.0128173828125\n","2021-03-22 14:08:25,667 INFO train:  31/100, loss:49.01287841796875\n","2021-03-22 14:08:34,585 INFO train:  31/100, loss:49.01287078857422\n","2021-03-22 14:08:45,226 INFO train:  31/100, loss:49.01283645629883\n","2021-03-22 14:08:56,804 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:09:07,476 INFO train:  31/100, loss:49.012821197509766\n","2021-03-22 14:09:16,620 INFO train:  31/100, loss:49.012882232666016\n","2021-03-22 14:09:27,659 INFO train:  31/100, loss:49.01282501220703\n","2021-03-22 14:09:37,808 INFO train:  31/100, loss:49.01279830932617\n","2021-03-22 14:09:49,402 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:10:03,073 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:10:14,455 INFO train:  31/100, loss:49.01286697387695\n","2021-03-22 14:10:24,442 INFO train:  31/100, loss:49.01283264160156\n","2021-03-22 14:10:37,034 INFO train:  31/100, loss:49.012874603271484\n","2021-03-22 14:10:46,127 INFO train:  31/100, loss:49.01282501220703\n","2021-03-22 14:10:55,450 INFO train:  31/100, loss:49.0128288269043\n","2021-03-22 14:11:07,686 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:11:18,370 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:11:29,517 INFO train:  31/100, loss:49.012779235839844\n","2021-03-22 14:11:43,515 INFO train:  31/100, loss:49.012847900390625\n","2021-03-22 14:11:49,828 INFO train:  31/100, loss:49.01283264160156\n","2021-03-22 14:11:59,440 INFO train:  31/100, loss:49.01285934448242\n","2021-03-22 14:12:11,324 INFO train:  31/100, loss:49.01280975341797\n","2021-03-22 14:12:21,745 INFO train:  31/100, loss:49.01286315917969\n","2021-03-22 14:12:34,104 INFO train:  31/100, loss:49.01279067993164\n","2021-03-22 14:12:43,399 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:12:55,157 INFO train:  31/100, loss:49.01278305053711\n","2021-03-22 14:13:03,698 INFO train:  31/100, loss:49.012813568115234\n","2021-03-22 14:13:16,386 INFO train:  31/100, loss:49.01283264160156\n","2021-03-22 14:13:24,481 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:13:35,684 INFO train:  31/100, loss:49.0128173828125\n","2021-03-22 14:13:44,467 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:13:54,715 INFO train:  31/100, loss:49.01286697387695\n","2021-03-22 14:14:06,555 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:14:20,284 INFO train:  31/100, loss:49.01283264160156\n","2021-03-22 14:14:28,523 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:14:38,356 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:14:50,043 INFO train:  31/100, loss:49.01274108886719\n","2021-03-22 14:15:03,639 INFO train:  31/100, loss:49.012813568115234\n","2021-03-22 14:15:11,587 INFO train:  31/100, loss:49.01280212402344\n","2021-03-22 14:15:24,536 INFO train:  31/100, loss:49.0128059387207\n","2021-03-22 14:15:32,765 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:15:43,794 INFO train:  31/100, loss:49.01285171508789\n","2021-03-22 14:15:51,115 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:16:06,315 INFO train:  31/100, loss:49.01282501220703\n","2021-03-22 14:16:15,353 INFO train:  31/100, loss:49.0128173828125\n","2021-03-22 14:16:26,517 INFO train:  31/100, loss:49.012855529785156\n","2021-03-22 14:16:37,568 INFO train:  31/100, loss:49.01278305053711\n","2021-03-22 14:16:46,282 INFO train:  31/100, loss:49.01279830932617\n","2021-03-22 14:16:56,682 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:17:06,521 INFO train:  31/100, loss:49.012821197509766\n","2021-03-22 14:17:17,388 INFO train:  31/100, loss:49.01283645629883\n","2021-03-22 14:17:28,485 INFO train:  31/100, loss:49.012794494628906\n","2021-03-22 14:17:38,366 INFO train:  31/100, loss:49.012840270996094\n","2021-03-22 14:17:50,609 INFO train:  31/100, loss:49.01282501220703\n","2021-03-22 14:18:02,578 INFO train:  31/100, loss:49.01286315917969\n","2021-03-22 14:18:11,200 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:18:21,360 INFO train:  31/100, loss:49.01280975341797\n","2021-03-22 14:18:31,389 INFO train:  31/100, loss:49.01284408569336\n","2021-03-22 14:18:41,054 INFO val:  31/100, loss:49.012840270996094\n","2021-03-22 14:18:51,357 INFO val:  31/100, loss:49.01283645629883\n","2021-03-22 14:19:03,107 INFO val:  31/100, loss:49.01282501220703\n","2021-03-22 14:19:12,968 INFO val:  31/100, loss:49.012874603271484\n","2021-03-22 14:19:15,218 INFO train time 22053.935925006866, 31/100\n","2021-03-22 14:19:15,221 INFO Epoch 32/100\n","2021-03-22 14:19:15,227 INFO ----------\n","2021-03-22 14:19:24,383 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:19:34,184 INFO train:  32/100, loss:49.01285171508789\n","2021-03-22 14:19:44,065 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:19:54,319 INFO train:  32/100, loss:49.01283264160156\n","2021-03-22 14:20:06,108 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:20:15,474 INFO train:  32/100, loss:49.01285171508789\n","2021-03-22 14:20:27,975 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:20:37,131 INFO train:  32/100, loss:49.01286697387695\n","2021-03-22 14:20:47,568 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:20:59,714 INFO train:  32/100, loss:49.01286697387695\n","2021-03-22 14:21:10,989 INFO train:  32/100, loss:49.012813568115234\n","2021-03-22 14:21:20,425 INFO train:  32/100, loss:49.01287841796875\n","2021-03-22 14:21:30,520 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:21:41,448 INFO train:  32/100, loss:49.01285171508789\n","2021-03-22 14:21:52,045 INFO train:  32/100, loss:49.0128059387207\n","2021-03-22 14:22:03,753 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:22:14,675 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:22:24,796 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:22:35,246 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:22:45,675 INFO train:  32/100, loss:49.012847900390625\n","2021-03-22 14:22:55,131 INFO train:  32/100, loss:49.0128059387207\n","2021-03-22 14:23:05,889 INFO train:  32/100, loss:49.01285171508789\n","2021-03-22 14:23:15,686 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:23:26,321 INFO train:  32/100, loss:49.01283264160156\n","2021-03-22 14:23:37,593 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:23:47,692 INFO train:  32/100, loss:49.01286315917969\n","2021-03-22 14:23:59,595 INFO train:  32/100, loss:49.012855529785156\n","2021-03-22 14:24:09,201 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:24:20,296 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:24:33,595 INFO train:  32/100, loss:49.01285934448242\n","2021-03-22 14:24:40,840 INFO train:  32/100, loss:49.01287078857422\n","2021-03-22 14:24:51,179 INFO train:  32/100, loss:49.01278305053711\n","2021-03-22 14:25:02,762 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:25:13,097 INFO train:  32/100, loss:49.01283645629883\n","2021-03-22 14:25:24,352 INFO train:  32/100, loss:49.0128059387207\n","2021-03-22 14:25:34,847 INFO train:  32/100, loss:49.012813568115234\n","2021-03-22 14:25:44,592 INFO train:  32/100, loss:49.01283264160156\n","2021-03-22 14:25:56,013 INFO train:  32/100, loss:49.012874603271484\n","2021-03-22 14:26:06,001 INFO train:  32/100, loss:49.01283264160156\n","2021-03-22 14:26:18,151 INFO train:  32/100, loss:49.01280975341797\n","2021-03-22 14:26:30,670 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:26:38,694 INFO train:  32/100, loss:49.0128173828125\n","2021-03-22 14:26:49,351 INFO train:  32/100, loss:49.01283645629883\n","2021-03-22 14:27:00,041 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:27:10,463 INFO train:  32/100, loss:49.01286697387695\n","2021-03-22 14:27:21,666 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:27:31,570 INFO train:  32/100, loss:49.01280975341797\n","2021-03-22 14:27:41,760 INFO train:  32/100, loss:49.012882232666016\n","2021-03-22 14:27:52,476 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:28:04,903 INFO train:  32/100, loss:49.012855529785156\n","2021-03-22 14:28:12,914 INFO train:  32/100, loss:49.0128173828125\n","2021-03-22 14:28:24,551 INFO train:  32/100, loss:49.012855529785156\n","2021-03-22 14:28:34,717 INFO train:  32/100, loss:49.012874603271484\n","2021-03-22 14:28:45,304 INFO train:  32/100, loss:49.01279830932617\n","2021-03-22 14:28:57,047 INFO train:  32/100, loss:49.01286697387695\n","2021-03-22 14:29:07,092 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:29:17,248 INFO train:  32/100, loss:49.01282501220703\n","2021-03-22 14:29:29,015 INFO train:  32/100, loss:49.01284408569336\n","2021-03-22 14:29:39,883 INFO train:  32/100, loss:49.01278305053711\n","2021-03-22 14:29:49,238 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:29:59,459 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:30:11,683 INFO train:  32/100, loss:49.012840270996094\n","2021-03-22 14:30:21,605 INFO train:  32/100, loss:49.01279067993164\n","2021-03-22 14:30:31,613 INFO val:  32/100, loss:49.01282501220703\n","2021-03-22 14:30:42,697 INFO val:  32/100, loss:49.01286697387695\n","2021-03-22 14:30:53,346 INFO val:  32/100, loss:49.012855529785156\n","2021-03-22 14:31:05,237 INFO val:  32/100, loss:49.012840270996094\n","2021-03-22 14:31:06,259 INFO train time 22764.920365571976, 32/100\n","2021-03-22 14:31:06,261 INFO Epoch 33/100\n","2021-03-22 14:31:06,268 INFO ----------\n","2021-03-22 14:31:15,570 INFO train:  33/100, loss:49.012840270996094\n","2021-03-22 14:31:26,934 INFO train:  33/100, loss:49.01285934448242\n","2021-03-22 14:31:36,034 INFO train:  33/100, loss:49.01282501220703\n","2021-03-22 14:31:48,830 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:31:58,762 INFO train:  33/100, loss:49.01285934448242\n","2021-03-22 14:32:09,297 INFO train:  33/100, loss:49.01286315917969\n","2021-03-22 14:32:18,845 INFO train:  33/100, loss:49.01286315917969\n","2021-03-22 14:32:32,274 INFO train:  33/100, loss:49.012752532958984\n","2021-03-22 14:32:42,082 INFO train:  33/100, loss:49.0128173828125\n","2021-03-22 14:32:51,504 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:33:06,796 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:33:15,394 INFO train:  33/100, loss:49.012840270996094\n","2021-03-22 14:33:26,035 INFO train:  33/100, loss:49.0128173828125\n","2021-03-22 14:33:36,605 INFO train:  33/100, loss:49.01284408569336\n","2021-03-22 14:33:47,220 INFO train:  33/100, loss:49.0128059387207\n","2021-03-22 14:33:59,111 INFO train:  33/100, loss:49.012840270996094\n","2021-03-22 14:34:07,378 INFO train:  33/100, loss:49.01283264160156\n","2021-03-22 14:34:18,517 INFO train:  33/100, loss:49.01286315917969\n","2021-03-22 14:34:31,498 INFO train:  33/100, loss:49.01283264160156\n","2021-03-22 14:34:38,661 INFO train:  33/100, loss:49.012874603271484\n","2021-03-22 14:34:50,261 INFO train:  33/100, loss:49.012847900390625\n","2021-03-22 14:35:00,624 INFO train:  33/100, loss:49.01286315917969\n","2021-03-22 14:35:10,394 INFO train:  33/100, loss:49.01283264160156\n","2021-03-22 14:35:19,862 INFO train:  33/100, loss:49.012855529785156\n","2021-03-22 14:35:30,244 INFO train:  33/100, loss:49.0128059387207\n","2021-03-22 14:35:40,044 INFO train:  33/100, loss:49.01273727416992\n","2021-03-22 14:35:51,441 INFO train:  33/100, loss:49.01285934448242\n","2021-03-22 14:36:04,008 INFO train:  33/100, loss:49.0128059387207\n","2021-03-22 14:36:11,477 INFO train:  33/100, loss:49.01284408569336\n","2021-03-22 14:36:21,921 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:36:33,419 INFO train:  33/100, loss:49.01282501220703\n","2021-03-22 14:36:42,498 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:36:54,545 INFO train:  33/100, loss:49.012874603271484\n","2021-03-22 14:37:03,831 INFO train:  33/100, loss:49.01284408569336\n","2021-03-22 14:37:15,771 INFO train:  33/100, loss:49.012874603271484\n","2021-03-22 14:37:24,646 INFO train:  33/100, loss:49.012847900390625\n","2021-03-22 14:37:35,927 INFO train:  33/100, loss:49.01284408569336\n","2021-03-22 14:37:44,852 INFO train:  33/100, loss:49.012840270996094\n","2021-03-22 14:37:55,358 INFO train:  33/100, loss:49.01287841796875\n","2021-03-22 14:38:06,645 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:38:18,579 INFO train:  33/100, loss:49.01283645629883\n","2021-03-22 14:38:27,998 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:38:38,670 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:38:48,079 INFO train:  33/100, loss:49.01276779174805\n","2021-03-22 14:38:59,361 INFO train:  33/100, loss:49.012847900390625\n","2021-03-22 14:39:14,487 INFO train:  33/100, loss:49.01285934448242\n","2021-03-22 14:39:23,078 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:39:31,306 INFO train:  33/100, loss:49.0128173828125\n","2021-03-22 14:39:41,973 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:39:52,576 INFO train:  33/100, loss:49.01287078857422\n","2021-03-22 14:40:02,856 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:40:12,483 INFO train:  33/100, loss:49.01283645629883\n","2021-03-22 14:40:24,802 INFO train:  33/100, loss:49.01279830932617\n","2021-03-22 14:40:35,837 INFO train:  33/100, loss:49.01283645629883\n","2021-03-22 14:40:44,109 INFO train:  33/100, loss:49.0128288269043\n","2021-03-22 14:40:55,418 INFO train:  33/100, loss:49.012855529785156\n","2021-03-22 14:41:05,688 INFO train:  33/100, loss:49.0128173828125\n","2021-03-22 14:41:14,476 INFO train:  33/100, loss:49.012855529785156\n","2021-03-22 14:41:24,826 INFO train:  33/100, loss:49.01279830932617\n","2021-03-22 14:41:35,278 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:41:46,657 INFO train:  33/100, loss:49.012840270996094\n","2021-03-22 14:42:00,434 INFO train:  33/100, loss:49.01286697387695\n","2021-03-22 14:42:06,384 INFO train:  33/100, loss:49.01285171508789\n","2021-03-22 14:42:15,539 INFO val:  33/100, loss:49.01284408569336\n","2021-03-22 14:42:26,364 INFO val:  33/100, loss:49.01279830932617\n","2021-03-22 14:42:37,018 INFO val:  33/100, loss:49.01286697387695\n","2021-03-22 14:42:47,912 INFO val:  33/100, loss:49.01287841796875\n","2021-03-22 14:42:49,364 INFO train time 23468.061073064804, 33/100\n","2021-03-22 14:42:49,366 INFO Epoch 34/100\n","2021-03-22 14:42:49,373 INFO ----------\n","2021-03-22 14:42:57,246 INFO train:  34/100, loss:49.012794494628906\n","2021-03-22 14:43:07,482 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:43:18,610 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:43:31,718 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:43:38,714 INFO train:  34/100, loss:49.01285171508789\n","2021-03-22 14:43:51,541 INFO train:  34/100, loss:49.012874603271484\n","2021-03-22 14:43:59,392 INFO train:  34/100, loss:49.012840270996094\n","2021-03-22 14:44:11,343 INFO train:  34/100, loss:49.01280212402344\n","2021-03-22 14:44:19,845 INFO train:  34/100, loss:49.01286697387695\n","2021-03-22 14:44:31,782 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:44:39,885 INFO train:  34/100, loss:49.0128173828125\n","2021-03-22 14:44:51,134 INFO train:  34/100, loss:49.012874603271484\n","2021-03-22 14:45:01,371 INFO train:  34/100, loss:49.01283264160156\n","2021-03-22 14:45:10,914 INFO train:  34/100, loss:49.01287078857422\n","2021-03-22 14:45:21,326 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:45:33,286 INFO train:  34/100, loss:49.01283264160156\n","2021-03-22 14:45:53,813 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:45:59,580 INFO train:  34/100, loss:49.01286697387695\n","2021-03-22 14:46:05,243 INFO train:  34/100, loss:49.012840270996094\n","2021-03-22 14:46:12,135 INFO train:  34/100, loss:49.01285171508789\n","2021-03-22 14:46:22,493 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:46:33,594 INFO train:  34/100, loss:49.01286315917969\n","2021-03-22 14:46:42,795 INFO train:  34/100, loss:49.01277542114258\n","2021-03-22 14:46:54,338 INFO train:  34/100, loss:49.01285171508789\n","2021-03-22 14:47:05,259 INFO train:  34/100, loss:49.01285171508789\n","2021-03-22 14:47:16,803 INFO train:  34/100, loss:49.0128173828125\n","2021-03-22 14:47:25,164 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:47:36,031 INFO train:  34/100, loss:49.01283645629883\n","2021-03-22 14:47:45,712 INFO train:  34/100, loss:49.01280975341797\n","2021-03-22 14:47:55,733 INFO train:  34/100, loss:49.012840270996094\n","2021-03-22 14:48:06,230 INFO train:  34/100, loss:49.01282501220703\n","2021-03-22 14:48:19,860 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:48:28,209 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:48:37,977 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:48:48,005 INFO train:  34/100, loss:49.01286697387695\n","2021-03-22 14:48:59,696 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:49:08,482 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:49:21,178 INFO train:  34/100, loss:49.0128173828125\n","2021-03-22 14:49:30,877 INFO train:  34/100, loss:49.01279830932617\n","2021-03-22 14:49:41,491 INFO train:  34/100, loss:49.012855529785156\n","2021-03-22 14:49:52,689 INFO train:  34/100, loss:49.01282501220703\n","2021-03-22 14:50:03,325 INFO train:  34/100, loss:49.01280975341797\n","2021-03-22 14:50:13,727 INFO train:  34/100, loss:49.012874603271484\n","2021-03-22 14:50:24,202 INFO train:  34/100, loss:49.012840270996094\n","2021-03-22 14:50:35,607 INFO train:  34/100, loss:49.01282501220703\n","2021-03-22 14:50:46,254 INFO train:  34/100, loss:49.0128288269043\n","2021-03-22 14:50:56,251 INFO train:  34/100, loss:49.01282501220703\n","2021-03-22 14:51:08,533 INFO train:  34/100, loss:49.01277160644531\n","2021-03-22 14:51:17,199 INFO train:  34/100, loss:49.01283645629883\n","2021-03-22 14:51:27,900 INFO train:  34/100, loss:49.01286697387695\n","2021-03-22 14:51:39,228 INFO train:  34/100, loss:49.012855529785156\n","2021-03-22 14:51:50,782 INFO train:  34/100, loss:49.01285934448242\n","2021-03-22 14:52:02,710 INFO train:  34/100, loss:49.01284408569336\n","2021-03-22 14:52:11,738 INFO train:  34/100, loss:49.01285171508789\n","2021-03-22 14:52:24,596 INFO train:  34/100, loss:49.01286315917969\n","2021-03-22 14:52:32,964 INFO train:  34/100, loss:49.01286697387695\n","2021-03-22 14:52:43,714 INFO train:  34/100, loss:49.01283645629883\n","2021-03-22 14:52:58,602 INFO train:  34/100, loss:49.01287078857422\n","2021-03-22 14:53:05,873 INFO train:  34/100, loss:49.0128059387207\n","2021-03-22 14:53:15,236 INFO train:  34/100, loss:49.01279830932617\n","2021-03-22 14:53:24,046 INFO train:  34/100, loss:49.012840270996094\n","2021-03-22 14:53:35,098 INFO train:  34/100, loss:49.012855529785156\n","2021-03-22 14:53:46,925 INFO train:  34/100, loss:49.01280975341797\n","2021-03-22 14:53:56,227 INFO val:  34/100, loss:49.01283264160156\n","2021-03-22 14:54:07,528 INFO val:  34/100, loss:49.012840270996094\n","2021-03-22 14:54:19,124 INFO val:  34/100, loss:49.01285171508789\n","2021-03-22 14:54:29,967 INFO val:  34/100, loss:49.01284408569336\n","2021-03-22 14:54:31,533 INFO train time 24170.2471511364, 34/100\n","2021-03-22 14:54:31,534 INFO Epoch 35/100\n","2021-03-22 14:54:31,542 INFO ----------\n","2021-03-22 14:54:40,283 INFO train:  35/100, loss:49.012840270996094\n","2021-03-22 14:54:50,380 INFO train:  35/100, loss:49.01285934448242\n","2021-03-22 14:55:02,879 INFO train:  35/100, loss:49.01286697387695\n","2021-03-22 14:55:11,205 INFO train:  35/100, loss:49.01283264160156\n","2021-03-22 14:55:22,531 INFO train:  35/100, loss:49.01286697387695\n","2021-03-22 14:55:32,896 INFO train:  35/100, loss:49.01285171508789\n","2021-03-22 14:55:42,210 INFO train:  35/100, loss:49.01285934448242\n","2021-03-22 14:55:53,243 INFO train:  35/100, loss:49.01277542114258\n","2021-03-22 14:56:02,744 INFO train:  35/100, loss:49.01284408569336\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qleP7Pju6cdN","executionInfo":{"elapsed":547,"status":"ok","timestamp":1615043167114,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"ab86d015-fd63-432b-a0dd-1ab4e5cc2cdd"},"source":["list(DrBC_module.parameters())[2].grad"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-3.1811e-05,  0.0000e+00,  3.7338e-03, -3.9361e-02, -4.1629e-05,\n","          1.0846e-04,  0.0000e+00,  5.2710e-04, -2.0568e-02,  0.0000e+00,\n","         -2.9760e-02,  1.7371e-03, -3.9132e-02,  2.9969e-03, -1.1920e-02,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","          6.2036e-03, -8.7824e-03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n","         -5.9737e-04, -2.1687e-02, -2.5961e-02,  0.0000e+00, -3.6056e-02,\n","          0.0000e+00, -2.9821e-02,  8.6391e-03, -4.5501e-02, -2.3277e-02,\n","          0.0000e+00, -5.5303e-03, -7.9124e-03, -1.8834e-02, -4.0921e-02,\n","          0.0000e+00,  0.0000e+00, -3.2854e-02, -1.9750e-03,  0.0000e+00,\n","          0.0000e+00, -8.5776e-03, -1.4956e-02,  0.0000e+00, -4.1537e-03,\n","          6.9897e-03,  0.0000e+00, -1.5777e-02,  0.0000e+00, -1.3589e-02,\n","          1.6265e-02, -2.6415e-02,  0.0000e+00,  0.0000e+00,  1.4470e-02,\n","          0.0000e+00,  1.4925e-03, -2.1319e-02,  0.0000e+00,  0.0000e+00,\n","          0.0000e+00, -1.4259e-02, -5.6567e-04,  0.0000e+00,  1.7804e-02,\n","          0.0000e+00, -1.6949e-02, -2.9103e-02, -6.8373e-03,  4.4290e-03,\n","          0.0000e+00,  0.0000e+00, -8.2506e-03,  0.0000e+00, -2.5138e-04,\n","          0.0000e+00, -2.0314e-02,  5.3100e-03, -1.0594e-02, -8.9130e-03,\n","         -1.7126e-02,  0.0000e+00,  2.2621e-02,  0.0000e+00,  1.8669e-03,\n","         -5.1343e-02, -2.7684e-02,  0.0000e+00,  0.0000e+00, -8.4959e-03,\n","         -2.3008e-02, -3.6529e-03,  0.0000e+00, -6.5716e-04,  4.6405e-03,\n","         -2.5901e-02, -2.7156e-02,  0.0000e+00, -1.0145e-02, -3.1331e-02,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3936e-02,  0.0000e+00,\n","         -2.4679e-02, -6.3330e-03,  1.1483e-02,  7.2176e-03,  1.4327e-02,\n","         -1.5756e-02, -7.5401e-03,  0.0000e+00, -3.4181e-02, -1.3591e-02,\n","          0.0000e+00,  0.0000e+00,  0.0000e+00, -2.6521e-02,  0.0000e+00,\n","         -4.4372e-02,  0.0000e+00, -2.2033e-02]], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"BLSJa72jBN8Z"},"source":["output = DrBC_module(train[5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Y1UJGwxDuVZ"},"source":["loss = lossfun(output, train[5].scoreList)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNLcC7rzEhw9","executionInfo":{"elapsed":533,"status":"ok","timestamp":1615043114404,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"b5ef049c-fd87-4ecf-a8d5-3c5e3d222493"},"source":["output, loss"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 3.0010],\n","         [ 4.3244],\n","         [ 4.1092],\n","         ...,\n","         [-0.0694],\n","         [-0.0687],\n","         [-0.0720]], device='cuda:0', grad_fn=<AddmmBackward>),\n"," tensor([[212.2686]], device='cuda:0', grad_fn=<DivBackward0>))"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"GHNNOk986cdN","executionInfo":{"elapsed":567,"status":"error","timestamp":1615043160199,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"6f21218a-60c0-492f-855b-897690223da0"},"source":["loss.backward()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-52a0569421b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-h68SQ9O6cdN","executionInfo":{"elapsed":560,"status":"ok","timestamp":1615043177123,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"ccc8edf0-9f9a-403b-c81d-a76514a33dc3"},"source":["output[3000:3030]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0286],\n","        [ 0.0063],\n","        [-0.0685],\n","        [-0.0684],\n","        [-0.0690],\n","        [-0.0377],\n","        [-0.0382],\n","        [-0.0423],\n","        [-0.0420],\n","        [-0.0537],\n","        [-0.0516],\n","        [-0.0528],\n","        [-0.0525],\n","        [-0.0137],\n","        [-0.0692],\n","        [-0.0534],\n","        [-0.0542],\n","        [-0.0720],\n","        [-0.0115],\n","        [-0.0445],\n","        [-0.0412],\n","        [-0.0516],\n","        [-0.0378],\n","        [-0.0523],\n","        [-0.0246],\n","        [-0.0523],\n","        [-0.0408],\n","        [-0.0685],\n","        [-0.0547],\n","        [-0.0275]], device='cuda:0', grad_fn=<SliceBackward>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjaKEKo3Bepr","executionInfo":{"elapsed":1111,"status":"ok","timestamp":1615042407167,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"b2fe04a4-ee9b-4e63-d972-490263f5203c"},"source":["train[5].degreeCoeffient"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: tensor([0.0066, 0.0115, 0.0113, 0.0156, 0.0136, 0.0124, 0.0209, 0.0197, 0.0194,\n","         0.0169, 0.0150, 0.0187, 0.0249, 0.0235, 0.0205, 0.0363, 0.0285, 0.0256,\n","         0.0229, 0.0242, 0.0265, 0.0363, 0.0324, 0.0285, 0.0265, 0.0342, 0.0324,\n","         0.0363, 0.0265, 0.0274, 0.0265, 0.0324, 0.0342, 0.0342, 0.0324, 0.0309,\n","         0.0324, 0.0363, 0.0285, 0.0388, 0.0285, 0.0296, 0.0388, 0.0363, 0.0419,\n","         0.0235, 0.0342, 0.0256, 0.0324, 0.0285, 0.0363, 0.0324, 0.0388, 0.0459,\n","         0.0342, 0.0342, 0.0459, 0.0342, 0.0388, 0.0388, 0.0459, 0.0459, 0.0459,\n","         0.0324, 0.0363, 0.0419, 0.0419, 0.0388, 0.0459, 0.0342, 0.0419, 0.0419,\n","         0.0459, 0.0459, 0.0388, 0.0459, 0.0388, 0.0459, 0.0459, 0.0324, 0.0388,\n","         0.0459, 0.0419, 0.0459, 0.0459, 0.0419, 0.0459, 0.0459, 0.0419, 0.0459,\n","         0.0459, 0.0459, 0.0459, 0.0459]),\n"," 1: tensor([0.0044, 0.0076, 0.0076, 0.0063, 0.0058, 0.0073, 0.0074, 0.0057, 0.0098,\n","         0.0054, 0.0094, 0.0121, 0.0116, 0.0119, 0.0103, 0.0081, 0.0125, 0.0082,\n","         0.0091, 0.0116, 0.0130, 0.0084, 0.0138, 0.0094, 0.0151, 0.0125, 0.0086,\n","         0.0147, 0.0109, 0.0111, 0.0117, 0.0155, 0.0147, 0.0116, 0.0109, 0.0151,\n","         0.0086, 0.0169, 0.0174, 0.0195, 0.0164, 0.0159, 0.0169, 0.0125, 0.0121,\n","         0.0180, 0.0144, 0.0169, 0.0121, 0.0238, 0.0225, 0.0203, 0.0114, 0.0174,\n","         0.0125, 0.0195, 0.0203, 0.0195, 0.0132, 0.0180, 0.0195, 0.0238, 0.0164,\n","         0.0203, 0.0141, 0.0187, 0.0132, 0.0203, 0.0174, 0.0203, 0.0132, 0.0225,\n","         0.0159, 0.0225, 0.0213, 0.0213, 0.0213, 0.0195, 0.0203, 0.0225, 0.0213,\n","         0.0275, 0.0213, 0.0213, 0.0147, 0.0238, 0.0238, 0.0225, 0.0255, 0.0195,\n","         0.0225, 0.0203, 0.0255, 0.0275, 0.0302, 0.0275, 0.0203, 0.0275, 0.0302,\n","         0.0275, 0.0213, 0.0255, 0.0302, 0.0255, 0.0255, 0.0213, 0.0255, 0.0275,\n","         0.0225, 0.0302, 0.0275, 0.0275, 0.0213, 0.0225, 0.0225, 0.0275, 0.0238,\n","         0.0255, 0.0213, 0.0255, 0.0213, 0.0255, 0.0187, 0.0275, 0.0275, 0.0302,\n","         0.0275, 0.0302, 0.0302, 0.0203, 0.0238, 0.0302, 0.0255, 0.0255, 0.0302,\n","         0.0238, 0.0225, 0.0302, 0.0255, 0.0238, 0.0275, 0.0238, 0.0225, 0.0255,\n","         0.0302, 0.0275, 0.0302, 0.0302, 0.0275, 0.0302, 0.0255, 0.0302, 0.0275,\n","         0.0213, 0.0187, 0.0302, 0.0275, 0.0302, 0.0302, 0.0255, 0.0275, 0.0302,\n","         0.0302, 0.0255, 0.0255, 0.0275, 0.0275, 0.0302, 0.0302, 0.0275, 0.0275,\n","         0.0302, 0.0225, 0.0302, 0.0302, 0.0302, 0.0225, 0.0302, 0.0302, 0.0302,\n","         0.0275, 0.0302, 0.0255, 0.0255, 0.0255, 0.0302, 0.0302, 0.0275, 0.0302,\n","         0.0302, 0.0302, 0.0275, 0.0275, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302,\n","         0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0275, 0.0302, 0.0255,\n","         0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302, 0.0302,\n","         0.0302, 0.0302, 0.0302]),\n"," 2: tensor([0.0050, 0.0086, 0.0086, 0.0071, 0.0067, 0.0059, 0.0060, 0.0065, 0.0126,\n","         0.0092, 0.0134, 0.0111, 0.0107, 0.0181, 0.0167, 0.0124, 0.0148, 0.0113,\n","         0.0138, 0.0136, 0.0142, 0.0136, 0.0213, 0.0221, 0.0271, 0.0150, 0.0221,\n","         0.0176, 0.0148, 0.0128, 0.0164, 0.0271, 0.0313, 0.0167, 0.0167, 0.0205,\n","         0.0164, 0.0231, 0.0213, 0.0271, 0.0205, 0.0205, 0.0136, 0.0343, 0.0290,\n","         0.0192, 0.0198, 0.0221, 0.0164, 0.0271, 0.0181, 0.0256, 0.0205, 0.0213,\n","         0.0256, 0.0231, 0.0271, 0.0213, 0.0192, 0.0256, 0.0205, 0.0213, 0.0256,\n","         0.0231, 0.0290, 0.0290, 0.0313, 0.0192, 0.0231, 0.0271, 0.0290, 0.0290,\n","         0.0198, 0.0343, 0.0290, 0.0313, 0.0343, 0.0313, 0.0271, 0.0256, 0.0313,\n","         0.0171, 0.0343, 0.0221, 0.0256, 0.0313, 0.0290, 0.0213, 0.0290, 0.0243,\n","         0.0231, 0.0313, 0.0313, 0.0290, 0.0221, 0.0256, 0.0290, 0.0213, 0.0256,\n","         0.0290, 0.0256, 0.0243, 0.0256, 0.0290, 0.0256, 0.0271, 0.0256, 0.0290,\n","         0.0313, 0.0343, 0.0256, 0.0313, 0.0313, 0.0343, 0.0290, 0.0343, 0.0231,\n","         0.0343, 0.0343, 0.0290, 0.0313, 0.0243, 0.0313, 0.0313, 0.0256, 0.0256,\n","         0.0343, 0.0343, 0.0313, 0.0343, 0.0343, 0.0313, 0.0343, 0.0343, 0.0343,\n","         0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343,\n","         0.0343, 0.0343, 0.0290, 0.0313, 0.0343, 0.0313, 0.0343, 0.0343, 0.0343,\n","         0.0313, 0.0313, 0.0343, 0.0290, 0.0313, 0.0343, 0.0313, 0.0343, 0.0343,\n","         0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343, 0.0343]),\n"," 3: tensor([0.0065, 0.0113, 0.0108, 0.0131, 0.0204, 0.0136, 0.0129, 0.0192, 0.0156,\n","         0.0183, 0.0174, 0.0204, 0.0186, 0.0250, 0.0200, 0.0218, 0.0156, 0.0192,\n","         0.0209, 0.0236, 0.0213, 0.0174, 0.0209, 0.0267, 0.0333, 0.0229, 0.0192,\n","         0.0243, 0.0218, 0.0229, 0.0250, 0.0302, 0.0333, 0.0209, 0.0289, 0.0277,\n","         0.0333, 0.0258, 0.0333, 0.0302, 0.0302, 0.0267, 0.0267, 0.0277, 0.0408,\n","         0.0267, 0.0267, 0.0333, 0.0354, 0.0302, 0.0277, 0.0408, 0.0302, 0.0447,\n","         0.0302, 0.0267, 0.0333, 0.0408, 0.0316, 0.0354, 0.0408, 0.0354, 0.0316,\n","         0.0378, 0.0447, 0.0354, 0.0354, 0.0408, 0.0447, 0.0378, 0.0333, 0.0408,\n","         0.0447, 0.0316, 0.0408, 0.0316, 0.0378, 0.0354, 0.0408, 0.0354, 0.0447,\n","         0.0378, 0.0447, 0.0447, 0.0408, 0.0447, 0.0447, 0.0408, 0.0447, 0.0447,\n","         0.0447, 0.0447, 0.0447, 0.0447, 0.0408, 0.0447, 0.0447, 0.0447, 0.0447]),\n"," 4: tensor([0.0066, 0.0044, 0.0050, 0.0065, 0.0073, 0.0073, 0.0060, 0.0050, 0.0070,\n","         0.0071, 0.0050, 0.0132, 0.0094, 0.0081, 0.0067, 0.0116, 0.0069, 0.0091,\n","         0.0084, 0.0098, 0.0111, 0.0055, 0.0066, 0.0195, 0.0096, 0.0081, 0.0091,\n","         0.0093, 0.0120, 0.0095, 0.0105, 0.0087, 0.0113, 0.0094, 0.0089, 0.0116,\n","         0.0114, 0.0138, 0.0132, 0.0116, 0.0093, 0.0141, 0.0095, 0.0173, 0.0091,\n","         0.0118, 0.0118, 0.0120, 0.0145, 0.0124, 0.0118, 0.0102, 0.0157, 0.0124,\n","         0.0101, 0.0118, 0.0229, 0.0148, 0.0152, 0.0148, 0.0187, 0.0152, 0.0157,\n","         0.0173, 0.0162, 0.0173, 0.0148, 0.0141, 0.0135, 0.0195, 0.0138, 0.0162,\n","         0.0162, 0.0187, 0.0122, 0.0229, 0.0216, 0.0187, 0.0216, 0.0141, 0.0229,\n","         0.0157, 0.0141, 0.0162, 0.0195, 0.0167, 0.0244, 0.0157, 0.0167, 0.0205,\n","         0.0205, 0.0187, 0.0148, 0.0152, 0.0195, 0.0216, 0.0145, 0.0205, 0.0179,\n","         0.0179, 0.0229, 0.0229, 0.0264, 0.0264, 0.0173, 0.0264, 0.0205, 0.0216,\n","         0.0187, 0.0179, 0.0167, 0.0187, 0.0244, 0.0264, 0.0216, 0.0195, 0.0195,\n","         0.0173, 0.0244, 0.0187, 0.0229, 0.0244, 0.0244, 0.0264, 0.0195, 0.0187,\n","         0.0157, 0.0244, 0.0216, 0.0179, 0.0205, 0.0205, 0.0229, 0.0216, 0.0264,\n","         0.0216, 0.0205, 0.0195, 0.0229, 0.0244, 0.0264, 0.0289, 0.0229, 0.0264,\n","         0.0264, 0.0229, 0.0244, 0.0244, 0.0229, 0.0216, 0.0289, 0.0195, 0.0264,\n","         0.0289, 0.0264, 0.0216, 0.0244, 0.0179, 0.0195, 0.0264, 0.0229, 0.0289,\n","         0.0244, 0.0289, 0.0205, 0.0244, 0.0216, 0.0264, 0.0195, 0.0244, 0.0229,\n","         0.0229, 0.0229, 0.0264, 0.0229, 0.0264, 0.0264, 0.0229, 0.0229, 0.0264,\n","         0.0264, 0.0289, 0.0264, 0.0264, 0.0264, 0.0229, 0.0216, 0.0264, 0.0289,\n","         0.0244, 0.0264, 0.0289, 0.0289, 0.0229, 0.0289, 0.0289, 0.0264, 0.0244,\n","         0.0289, 0.0289, 0.0289, 0.0264, 0.0289, 0.0229, 0.0244, 0.0229, 0.0289,\n","         0.0264, 0.0264, 0.0289, 0.0289, 0.0244, 0.0289, 0.0264, 0.0289, 0.0244,\n","         0.0264, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289,\n","         0.0289, 0.0264, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289, 0.0289,\n","         0.0289, 0.0289, 0.0289, 0.0289]),\n"," 5: tensor([0.0115, 0.0076, 0.0086, 0.0073, 0.0104, 0.0090, 0.0170, 0.0170, 0.0152,\n","         0.0217, 0.0140, 0.0158, 0.0185, 0.0199, 0.0205, 0.0205, 0.0205, 0.0190,\n","         0.0273, 0.0301, 0.0258, 0.0265, 0.0301, 0.0356, 0.0258, 0.0281, 0.0209,\n","         0.0375, 0.0301, 0.0339, 0.0425, 0.0301, 0.0290, 0.0258, 0.0281, 0.0339,\n","         0.0221, 0.0375, 0.0356, 0.0459, 0.0356, 0.0425, 0.0459, 0.0398, 0.0312,\n","         0.0356, 0.0356, 0.0503, 0.0503, 0.0356, 0.0503, 0.0356, 0.0459, 0.0375,\n","         0.0503, 0.0503, 0.0375, 0.0503, 0.0356, 0.0425, 0.0459, 0.0459, 0.0459,\n","         0.0425, 0.0503, 0.0375, 0.0459, 0.0459, 0.0459, 0.0503, 0.0503, 0.0503,\n","         0.0425, 0.0503, 0.0459, 0.0459, 0.0459, 0.0459]),\n"," 6: tensor([0.0076, 0.0086, 0.0113, 0.0073, 0.0098, 0.0123, 0.0153, 0.0121, 0.0193,\n","         0.0172, 0.0152, 0.0152, 0.0185, 0.0199, 0.0225, 0.0312, 0.0339, 0.0290,\n","         0.0312, 0.0339, 0.0290, 0.0273, 0.0290, 0.0265, 0.0290, 0.0273, 0.0312,\n","         0.0301, 0.0356, 0.0398, 0.0356, 0.0398, 0.0356, 0.0459, 0.0425, 0.0375,\n","         0.0425, 0.0425, 0.0503, 0.0339, 0.0398, 0.0398, 0.0398, 0.0356, 0.0375,\n","         0.0459, 0.0375, 0.0398, 0.0339, 0.0375, 0.0503, 0.0503, 0.0459, 0.0459,\n","         0.0459, 0.0459, 0.0459, 0.0503, 0.0503, 0.0459, 0.0459, 0.0503, 0.0503,\n","         0.0503, 0.0459, 0.0503, 0.0503, 0.0503, 0.0459, 0.0503, 0.0503, 0.0503,\n","         0.0459, 0.0503, 0.0503, 0.0503, 0.0503, 0.0503]),\n"," 7: tensor([0.0063, 0.0071, 0.0060, 0.0104, 0.0081, 0.0122, 0.0072, 0.0079, 0.0130,\n","         0.0167, 0.0140, 0.0130, 0.0153, 0.0179, 0.0080, 0.0151, 0.0172, 0.0175,\n","         0.0167, 0.0164, 0.0198, 0.0172, 0.0198, 0.0232, 0.0126, 0.0167, 0.0232,\n","         0.0240, 0.0208, 0.0159, 0.0268, 0.0268, 0.0240, 0.0213, 0.0162, 0.0157,\n","         0.0379, 0.0258, 0.0294, 0.0309, 0.0415, 0.0268, 0.0280, 0.0240, 0.0258,\n","         0.0240, 0.0294, 0.0225, 0.0328, 0.0309, 0.0309, 0.0351, 0.0309, 0.0294,\n","         0.0268, 0.0415, 0.0309, 0.0225, 0.0328, 0.0309, 0.0351, 0.0415, 0.0351,\n","         0.0328, 0.0309, 0.0415, 0.0351, 0.0415, 0.0268, 0.0379, 0.0351, 0.0351,\n","         0.0415, 0.0351, 0.0351, 0.0379, 0.0415, 0.0351, 0.0294, 0.0379, 0.0379,\n","         0.0379, 0.0415, 0.0415, 0.0309, 0.0379, 0.0415, 0.0328, 0.0415, 0.0328,\n","         0.0351, 0.0415, 0.0351, 0.0415, 0.0415, 0.0379, 0.0415, 0.0351, 0.0415,\n","         0.0415, 0.0415, 0.0415, 0.0379, 0.0415, 0.0415, 0.0415, 0.0415, 0.0415,\n","         0.0415, 0.0415, 0.0415, 0.0415, 0.0415, 0.0415, 0.0415]),\n"," 8: tensor([0.0058, 0.0067, 0.0098, 0.0081, 0.0067, 0.0067, 0.0177, 0.0118, 0.0109,\n","         0.0189, 0.0217, 0.0125, 0.0177, 0.0261, 0.0129, 0.0135, 0.0147, 0.0128,\n","         0.0189, 0.0119, 0.0118, 0.0147, 0.0224, 0.0217, 0.0194, 0.0181, 0.0135,\n","         0.0170, 0.0199, 0.0170, 0.0224, 0.0204, 0.0250, 0.0217, 0.0217, 0.0173,\n","         0.0232, 0.0199, 0.0307, 0.0217, 0.0307, 0.0217, 0.0199, 0.0185, 0.0224,\n","         0.0240, 0.0204, 0.0250, 0.0185, 0.0289, 0.0274, 0.0328, 0.0307, 0.0289,\n","         0.0261, 0.0328, 0.0250, 0.0250, 0.0261, 0.0354, 0.0307, 0.0328, 0.0388,\n","         0.0328, 0.0289, 0.0354, 0.0388, 0.0307, 0.0388, 0.0274, 0.0354, 0.0328,\n","         0.0354, 0.0274, 0.0289, 0.0307, 0.0289, 0.0224, 0.0354, 0.0328, 0.0307,\n","         0.0354, 0.0307, 0.0354, 0.0328, 0.0388, 0.0354, 0.0261, 0.0328, 0.0307,\n","         0.0354, 0.0307, 0.0307, 0.0307, 0.0328, 0.0354, 0.0328, 0.0328, 0.0354,\n","         0.0289, 0.0388, 0.0388, 0.0328, 0.0354, 0.0307, 0.0388, 0.0388, 0.0354,\n","         0.0388, 0.0328, 0.0289, 0.0354, 0.0388, 0.0388, 0.0354, 0.0388, 0.0354,\n","         0.0388, 0.0328, 0.0354, 0.0388, 0.0388, 0.0354, 0.0354, 0.0388, 0.0388,\n","         0.0388, 0.0388, 0.0388, 0.0354, 0.0388, 0.0388]),\n"," 9: tensor([0.0059, 0.0050, 0.0067, 0.0084, 0.0102, 0.0113, 0.0097, 0.0139, 0.0102,\n","         0.0133, 0.0108, 0.0137, 0.0135, 0.0108, 0.0117, 0.0112, 0.0233, 0.0135,\n","         0.0274, 0.0109, 0.0126, 0.0158, 0.0155, 0.0223, 0.0137, 0.0155, 0.0173,\n","         0.0152, 0.0178, 0.0122, 0.0141, 0.0233, 0.0178, 0.0155, 0.0207, 0.0193,\n","         0.0233, 0.0144, 0.0169, 0.0346, 0.0193, 0.0258, 0.0316, 0.0200, 0.0292,\n","         0.0233, 0.0193, 0.0178, 0.0200, 0.0258, 0.0200, 0.0233, 0.0292, 0.0245,\n","         0.0245, 0.0274, 0.0215, 0.0274, 0.0316, 0.0200, 0.0223, 0.0258, 0.0292,\n","         0.0223, 0.0316, 0.0274, 0.0215, 0.0258, 0.0245, 0.0346, 0.0223, 0.0292,\n","         0.0258, 0.0233, 0.0245, 0.0223, 0.0233, 0.0233, 0.0292, 0.0274, 0.0316,\n","         0.0258, 0.0292, 0.0346, 0.0316, 0.0346, 0.0292, 0.0346, 0.0292, 0.0292,\n","         0.0258, 0.0274, 0.0316, 0.0316, 0.0245, 0.0245, 0.0258, 0.0346, 0.0215,\n","         0.0316, 0.0346, 0.0346, 0.0233, 0.0316, 0.0292, 0.0316, 0.0292, 0.0346,\n","         0.0316, 0.0233, 0.0292, 0.0346, 0.0258, 0.0316, 0.0346, 0.0346, 0.0346,\n","         0.0292, 0.0346, 0.0316, 0.0316, 0.0316, 0.0316, 0.0316, 0.0316, 0.0346,\n","         0.0346, 0.0346, 0.0316, 0.0292, 0.0274, 0.0346, 0.0346, 0.0346, 0.0346,\n","         0.0346, 0.0316, 0.0274, 0.0346, 0.0316, 0.0316, 0.0346, 0.0346, 0.0316,\n","         0.0346, 0.0316, 0.0316, 0.0346, 0.0316, 0.0346, 0.0346, 0.0346, 0.0346,\n","         0.0316, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346, 0.0346,\n","         0.0346, 0.0346, 0.0346, 0.0346]),\n"," 10: tensor([0.0073, 0.0108, 0.0070, 0.0084, 0.0142, 0.0158, 0.0152, 0.0165, 0.0140,\n","         0.0157, 0.0162, 0.0201, 0.0198, 0.0271, 0.0198, 0.0301, 0.0217, 0.0249,\n","         0.0271, 0.0243, 0.0243, 0.0301, 0.0343, 0.0290, 0.0362, 0.0313, 0.0280,\n","         0.0383, 0.0290, 0.0343, 0.0362, 0.0410, 0.0271, 0.0383, 0.0410, 0.0327,\n","         0.0327, 0.0383, 0.0280, 0.0485, 0.0362, 0.0410, 0.0410, 0.0301, 0.0383,\n","         0.0485, 0.0271, 0.0410, 0.0443, 0.0410, 0.0443, 0.0410, 0.0443, 0.0313,\n","         0.0343, 0.0443, 0.0362, 0.0443, 0.0313, 0.0383, 0.0383, 0.0327, 0.0410,\n","         0.0410, 0.0410, 0.0485, 0.0485, 0.0443, 0.0410, 0.0410, 0.0485, 0.0485,\n","         0.0485, 0.0443, 0.0443, 0.0485, 0.0443, 0.0443, 0.0410, 0.0485, 0.0485,\n","         0.0485, 0.0485, 0.0485]),\n"," 11: tensor([0.0113, 0.0074, 0.0071, 0.0123, 0.0093, 0.0167, 0.0118, 0.0145, 0.0191,\n","         0.0142, 0.0155, 0.0197, 0.0224, 0.0317, 0.0252, 0.0215, 0.0240, 0.0274,\n","         0.0259, 0.0448, 0.0366, 0.0293, 0.0366, 0.0415, 0.0347, 0.0448, 0.0317,\n","         0.0224, 0.0415, 0.0331, 0.0293, 0.0448, 0.0448, 0.0388, 0.0274, 0.0366,\n","         0.0347, 0.0448, 0.0415, 0.0388, 0.0347, 0.0448, 0.0388, 0.0448, 0.0415,\n","         0.0415, 0.0293, 0.0415, 0.0347, 0.0491, 0.0366, 0.0366, 0.0347, 0.0448,\n","         0.0448, 0.0448, 0.0491, 0.0491, 0.0448, 0.0491, 0.0491, 0.0491, 0.0491,\n","         0.0491, 0.0448, 0.0491, 0.0388, 0.0491, 0.0491, 0.0491, 0.0491, 0.0491,\n","         0.0491, 0.0415, 0.0491, 0.0491, 0.0491, 0.0491, 0.0448, 0.0491, 0.0491,\n","         0.0491]),\n"," 12: tensor([0.0131, 0.0122, 0.0102, 0.0142, 0.0200, 0.0184, 0.0328, 0.0186, 0.0280,\n","         0.0328, 0.0318, 0.0301, 0.0328, 0.0248, 0.0232, 0.0464, 0.0339, 0.0328,\n","         0.0309, 0.0496, 0.0464, 0.0379, 0.0248, 0.0328, 0.0496, 0.0351, 0.0464,\n","         0.0415, 0.0536, 0.0496, 0.0438, 0.0415, 0.0464, 0.0464, 0.0536, 0.0396,\n","         0.0464, 0.0496, 0.0536, 0.0496, 0.0438, 0.0536, 0.0536, 0.0587, 0.0536,\n","         0.0536, 0.0536, 0.0536, 0.0587, 0.0536, 0.0587, 0.0587, 0.0587, 0.0496,\n","         0.0587, 0.0587, 0.0587]),\n"," 13: tensor([0.0060, 0.0050, 0.0072, 0.0067, 0.0158, 0.0118, 0.0062, 0.0080, 0.0169,\n","         0.0128, 0.0137, 0.0194, 0.0162, 0.0128, 0.0079, 0.0149, 0.0133, 0.0135,\n","         0.0113, 0.0135, 0.0174, 0.0178, 0.0137, 0.0099, 0.0142, 0.0183, 0.0123,\n","         0.0121, 0.0245, 0.0224, 0.0194, 0.0147, 0.0183, 0.0174, 0.0155, 0.0274,\n","         0.0183, 0.0183, 0.0234, 0.0162, 0.0200, 0.0215, 0.0259, 0.0259, 0.0207,\n","         0.0158, 0.0215, 0.0234, 0.0274, 0.0207, 0.0245, 0.0245, 0.0293, 0.0165,\n","         0.0293, 0.0245, 0.0274, 0.0174, 0.0293, 0.0274, 0.0293, 0.0234, 0.0234,\n","         0.0200, 0.0174, 0.0234, 0.0224, 0.0245, 0.0317, 0.0200, 0.0200, 0.0194,\n","         0.0215, 0.0245, 0.0194, 0.0259, 0.0245, 0.0224, 0.0234, 0.0259, 0.0293,\n","         0.0274, 0.0259, 0.0224, 0.0215, 0.0274, 0.0293, 0.0317, 0.0317, 0.0259,\n","         0.0347, 0.0259, 0.0347, 0.0317, 0.0274, 0.0317, 0.0259, 0.0245, 0.0274,\n","         0.0259, 0.0224, 0.0293, 0.0245, 0.0317, 0.0274, 0.0293, 0.0347, 0.0207,\n","         0.0347, 0.0259, 0.0259, 0.0293, 0.0274, 0.0293, 0.0347, 0.0317, 0.0245,\n","         0.0347, 0.0274, 0.0293, 0.0274, 0.0259, 0.0293, 0.0274, 0.0234, 0.0317,\n","         0.0347, 0.0274, 0.0347, 0.0347, 0.0293, 0.0293, 0.0347, 0.0347, 0.0347,\n","         0.0347, 0.0347, 0.0317, 0.0317, 0.0347, 0.0317, 0.0274, 0.0347, 0.0317,\n","         0.0317, 0.0317, 0.0347, 0.0347, 0.0317, 0.0347, 0.0347, 0.0347, 0.0317,\n","         0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0347, 0.0317,\n","         0.0347, 0.0347, 0.0347]),\n"," 14: tensor([0.0204, 0.0132, 0.0177, 0.0158, 0.0355, 0.0426, 0.0445, 0.0350, 0.0468,\n","         0.0833, 0.0645, 0.0680, 0.0833, 0.0772, 0.0833, 0.0645, 0.0913, 0.0913,\n","         0.0772, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 15: tensor([0.0057, 0.0065, 0.0079, 0.0093, 0.0115, 0.0067, 0.0107, 0.0139, 0.0128,\n","         0.0206, 0.0119, 0.0177, 0.0163, 0.0108, 0.0145, 0.0117, 0.0115, 0.0185,\n","         0.0122, 0.0181, 0.0212, 0.0181, 0.0195, 0.0190, 0.0212, 0.0143, 0.0212,\n","         0.0235, 0.0152, 0.0227, 0.0283, 0.0206, 0.0235, 0.0283, 0.0268, 0.0219,\n","         0.0200, 0.0268, 0.0256, 0.0206, 0.0235, 0.0346, 0.0268, 0.0206, 0.0245,\n","         0.0177, 0.0256, 0.0268, 0.0212, 0.0181, 0.0235, 0.0219, 0.0283, 0.0256,\n","         0.0283, 0.0206, 0.0300, 0.0245, 0.0212, 0.0379, 0.0235, 0.0283, 0.0256,\n","         0.0245, 0.0256, 0.0268, 0.0245, 0.0283, 0.0346, 0.0321, 0.0245, 0.0346,\n","         0.0346, 0.0321, 0.0321, 0.0300, 0.0268, 0.0245, 0.0268, 0.0300, 0.0283,\n","         0.0283, 0.0321, 0.0321, 0.0283, 0.0346, 0.0346, 0.0219, 0.0346, 0.0346,\n","         0.0300, 0.0379, 0.0346, 0.0300, 0.0379, 0.0346, 0.0379, 0.0379, 0.0321,\n","         0.0300, 0.0321, 0.0379, 0.0346, 0.0379, 0.0379, 0.0379, 0.0346, 0.0379,\n","         0.0283, 0.0379, 0.0379, 0.0379, 0.0379, 0.0346, 0.0379, 0.0379, 0.0379,\n","         0.0379, 0.0346, 0.0346, 0.0379, 0.0379, 0.0346, 0.0346, 0.0346, 0.0379,\n","         0.0379, 0.0346, 0.0346, 0.0379, 0.0379, 0.0379, 0.0379, 0.0379, 0.0379,\n","         0.0379, 0.0379, 0.0379]),\n"," 16: tensor([0.0136, 0.0153, 0.0118, 0.0115, 0.0141, 0.0138, 0.0221, 0.0213, 0.0340,\n","         0.0173, 0.0377, 0.0312, 0.0248, 0.0393, 0.0430, 0.0556, 0.0454, 0.0410,\n","         0.0481, 0.0364, 0.0430, 0.0410, 0.0410, 0.0481, 0.0430, 0.0514, 0.0364,\n","         0.0481, 0.0481, 0.0556, 0.0609, 0.0556, 0.0454, 0.0556, 0.0430, 0.0556,\n","         0.0609, 0.0556, 0.0609, 0.0609, 0.0556, 0.0454, 0.0609, 0.0514, 0.0609,\n","         0.0556, 0.0556, 0.0609, 0.0609, 0.0609, 0.0609, 0.0609, 0.0609]),\n"," 17: tensor([0.0156, 0.0167, 0.0200, 0.0118, 0.0370, 0.0227, 0.0265, 0.0258, 0.0341,\n","         0.0370, 0.0508, 0.0394, 0.0350, 0.0311, 0.0370, 0.0359, 0.0482, 0.0408,\n","         0.0460, 0.0539, 0.0408, 0.0576, 0.0508, 0.0576, 0.0539, 0.0576, 0.0440,\n","         0.0576, 0.0508, 0.0539, 0.0623, 0.0682, 0.0682, 0.0576, 0.0576, 0.0623,\n","         0.0623, 0.0623, 0.0682, 0.0682, 0.0682, 0.0682]),\n"," 18: tensor([0.0098, 0.0094, 0.0113, 0.0158, 0.0151, 0.0271, 0.0197, 0.0250, 0.0292,\n","         0.0335, 0.0254, 0.0365, 0.0344, 0.0551, 0.0486, 0.0421, 0.0390, 0.0486,\n","         0.0461, 0.0516, 0.0421, 0.0461, 0.0516, 0.0652, 0.0486, 0.0551, 0.0595,\n","         0.0551, 0.0652, 0.0652, 0.0652, 0.0551, 0.0595, 0.0595, 0.0652, 0.0551,\n","         0.0595, 0.0516, 0.0652, 0.0652, 0.0595, 0.0652, 0.0652, 0.0652, 0.0652,\n","         0.0652]),\n"," 19: tensor([0.0054, 0.0090, 0.0062, 0.0067, 0.0111, 0.0174, 0.0120, 0.0085, 0.0105,\n","         0.0136, 0.0111, 0.0193, 0.0148, 0.0166, 0.0178, 0.0148, 0.0108, 0.0143,\n","         0.0166, 0.0205, 0.0162, 0.0119, 0.0153, 0.0183, 0.0126, 0.0141, 0.0174,\n","         0.0193, 0.0106, 0.0136, 0.0240, 0.0178, 0.0183, 0.0133, 0.0199, 0.0193,\n","         0.0178, 0.0174, 0.0213, 0.0281, 0.0252, 0.0356, 0.0325, 0.0281, 0.0252,\n","         0.0188, 0.0325, 0.0205, 0.0230, 0.0205, 0.0221, 0.0265, 0.0199, 0.0230,\n","         0.0162, 0.0221, 0.0240, 0.0281, 0.0281, 0.0252, 0.0281, 0.0221, 0.0265,\n","         0.0265, 0.0240, 0.0301, 0.0325, 0.0230, 0.0301, 0.0301, 0.0252, 0.0281,\n","         0.0301, 0.0356, 0.0281, 0.0265, 0.0281, 0.0281, 0.0265, 0.0252, 0.0301,\n","         0.0281, 0.0265, 0.0356, 0.0281, 0.0252, 0.0325, 0.0325, 0.0281, 0.0301,\n","         0.0356, 0.0325, 0.0301, 0.0301, 0.0301, 0.0281, 0.0325, 0.0325, 0.0356,\n","         0.0281, 0.0301, 0.0356, 0.0301, 0.0325, 0.0325, 0.0325, 0.0356, 0.0325,\n","         0.0281, 0.0301, 0.0356, 0.0325, 0.0281, 0.0325, 0.0301, 0.0325, 0.0356,\n","         0.0281, 0.0356, 0.0325, 0.0325, 0.0325, 0.0356, 0.0301, 0.0301, 0.0325,\n","         0.0301, 0.0356, 0.0301, 0.0325, 0.0325, 0.0356, 0.0356, 0.0325, 0.0325,\n","         0.0356, 0.0325, 0.0325, 0.0356, 0.0356, 0.0356, 0.0356, 0.0325, 0.0356,\n","         0.0356, 0.0356, 0.0356, 0.0356, 0.0356, 0.0301, 0.0356, 0.0356, 0.0356,\n","         0.0356, 0.0356, 0.0356, 0.0356]),\n"," 20: tensor([0.0094, 0.0130, 0.0152, 0.0111, 0.0214, 0.0244, 0.0256, 0.0321, 0.0260,\n","         0.0404, 0.0321, 0.0350, 0.0340, 0.0467, 0.0330, 0.0443, 0.0340, 0.0404,\n","         0.0321, 0.0443, 0.0313, 0.0362, 0.0404, 0.0330, 0.0572, 0.0572, 0.0572,\n","         0.0572, 0.0350, 0.0495, 0.0422, 0.0572, 0.0467, 0.0572, 0.0626, 0.0495,\n","         0.0443, 0.0572, 0.0495, 0.0626, 0.0529, 0.0529, 0.0572, 0.0572, 0.0626,\n","         0.0626, 0.0572, 0.0626, 0.0626, 0.0626]),\n"," 21: tensor([0.0081, 0.0109, 0.0097, 0.0107, 0.0275, 0.0176, 0.0223, 0.0128, 0.0157,\n","         0.0242, 0.0252, 0.0242, 0.0315, 0.0269, 0.0289, 0.0337, 0.0210, 0.0398,\n","         0.0275, 0.0420, 0.0337, 0.0380, 0.0563, 0.0445, 0.0380, 0.0269, 0.0476,\n","         0.0420, 0.0380, 0.0349, 0.0514, 0.0398, 0.0476, 0.0364, 0.0325, 0.0476,\n","         0.0398, 0.0563, 0.0420, 0.0445, 0.0476, 0.0563, 0.0514, 0.0514, 0.0514,\n","         0.0514, 0.0420, 0.0563, 0.0563, 0.0514, 0.0563, 0.0563, 0.0563, 0.0563,\n","         0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0563, 0.0514, 0.0563]),\n"," 22: tensor([0.0067, 0.0080, 0.0141, 0.0151, 0.0170, 0.0127, 0.0170, 0.0203, 0.0142,\n","         0.0212, 0.0221, 0.0189, 0.0251, 0.0226, 0.0160, 0.0328, 0.0139, 0.0175,\n","         0.0259, 0.0203, 0.0186, 0.0268, 0.0367, 0.0288, 0.0251, 0.0277, 0.0226,\n","         0.0367, 0.0251, 0.0367, 0.0212, 0.0367, 0.0288, 0.0259, 0.0392, 0.0423,\n","         0.0346, 0.0392, 0.0346, 0.0346, 0.0346, 0.0313, 0.0313, 0.0367, 0.0464,\n","         0.0367, 0.0367, 0.0313, 0.0367, 0.0423, 0.0299, 0.0423, 0.0423, 0.0367,\n","         0.0423, 0.0346, 0.0367, 0.0392, 0.0464, 0.0392, 0.0464, 0.0392, 0.0392,\n","         0.0423, 0.0367, 0.0464, 0.0392, 0.0423, 0.0392, 0.0423, 0.0423, 0.0423,\n","         0.0464, 0.0392, 0.0392, 0.0423, 0.0464, 0.0423, 0.0392, 0.0464, 0.0464,\n","         0.0423, 0.0423, 0.0464, 0.0464, 0.0423, 0.0423, 0.0464, 0.0464, 0.0464,\n","         0.0464, 0.0464]),\n"," 23: tensor([0.0189, 0.0169, 0.0174, 0.0275, 0.0309, 0.0318, 0.0529, 0.0294, 0.0630,\n","         0.0605, 0.0501, 0.0630, 0.0658, 0.0976, 0.0976, 0.0772, 0.0727, 0.0891,\n","         0.0891, 0.0976]),\n"," 24: tensor([0.0121, 0.0116, 0.0167, 0.0139, 0.0242, 0.0367, 0.0323, 0.0412, 0.0346,\n","         0.0518, 0.0679, 0.0498, 0.0635, 0.0635, 0.0480, 0.0803, 0.0679, 0.0568,\n","         0.0635, 0.0599, 0.0635, 0.0733, 0.0733, 0.0803, 0.0733, 0.0803, 0.0803,\n","         0.0733, 0.0733, 0.0733]),\n"," 25: tensor([0.0126, 0.0128, 0.0139, 0.0170, 0.0411, 0.0237, 0.0387, 0.0278, 0.0368,\n","         0.0496, 0.0456, 0.0548, 0.0520, 0.0621, 0.0581, 0.0520, 0.0735, 0.0735,\n","         0.0581, 0.0456, 0.0671, 0.0520, 0.0621, 0.0671, 0.0581, 0.0735, 0.0735,\n","         0.0735, 0.0671, 0.0735, 0.0621, 0.0671, 0.0735, 0.0671, 0.0735, 0.0735]),\n"," 26: tensor([0.0170, 0.0140, 0.0128, 0.0120, 0.0187, 0.0377, 0.0205, 0.0366, 0.0346,\n","         0.0238, 0.0314, 0.0455, 0.0477, 0.0418, 0.0346, 0.0570, 0.0615, 0.0615,\n","         0.0533, 0.0477, 0.0615, 0.0615, 0.0477, 0.0503, 0.0477, 0.0533, 0.0674,\n","         0.0503, 0.0570, 0.0570, 0.0674, 0.0615, 0.0674, 0.0570, 0.0615, 0.0674,\n","         0.0503, 0.0674, 0.0615, 0.0674, 0.0615, 0.0674, 0.0674]),\n"," 27: tensor([0.0069, 0.0121, 0.0118, 0.0085, 0.0199, 0.0131, 0.0162, 0.0184, 0.0160,\n","         0.0152, 0.0199, 0.0181, 0.0229, 0.0150, 0.0309, 0.0240, 0.0224, 0.0210,\n","         0.0196, 0.0246, 0.0219, 0.0287, 0.0174, 0.0253, 0.0234, 0.0268, 0.0253,\n","         0.0357, 0.0339, 0.0323, 0.0234, 0.0405, 0.0309, 0.0357, 0.0357, 0.0323,\n","         0.0438, 0.0357, 0.0287, 0.0405, 0.0323, 0.0379, 0.0438, 0.0405, 0.0379,\n","         0.0405, 0.0287, 0.0357, 0.0479, 0.0339, 0.0379, 0.0357, 0.0405, 0.0438,\n","         0.0479, 0.0405, 0.0438, 0.0438, 0.0405, 0.0405, 0.0479, 0.0438, 0.0405,\n","         0.0438, 0.0438, 0.0357, 0.0405, 0.0357, 0.0405, 0.0479, 0.0479, 0.0438,\n","         0.0479, 0.0479, 0.0479, 0.0438, 0.0479, 0.0438, 0.0479, 0.0479, 0.0479,\n","         0.0438, 0.0479, 0.0479, 0.0479, 0.0479]),\n"," 28: tensor([0.0136, 0.0102, 0.0145, 0.0105, 0.0321, 0.0197, 0.0149, 0.0227, 0.0282,\n","         0.0224, 0.0265, 0.0354, 0.0367, 0.0342, 0.0382, 0.0468, 0.0468, 0.0442,\n","         0.0442, 0.0442, 0.0541, 0.0331, 0.0367, 0.0331, 0.0501, 0.0354, 0.0321,\n","         0.0442, 0.0592, 0.0541, 0.0468, 0.0541, 0.0541, 0.0468, 0.0592, 0.0592,\n","         0.0468, 0.0468, 0.0592, 0.0541, 0.0541, 0.0541, 0.0541, 0.0541, 0.0541,\n","         0.0592, 0.0541, 0.0501, 0.0592, 0.0592, 0.0541, 0.0541, 0.0592, 0.0592,\n","         0.0592, 0.0592]),\n"," 29: tensor([0.0116, 0.0193, 0.0133, 0.0136, 0.0358, 0.0313, 0.0256, 0.0393, 0.0429,\n","         0.0606, 0.0476, 0.0700, 0.0542, 0.0700, 0.0700, 0.0606, 0.0542, 0.0648,\n","         0.0648, 0.0700, 0.0767, 0.0767, 0.0767, 0.0767, 0.0700, 0.0700, 0.0700,\n","         0.0700, 0.0700, 0.0767, 0.0767, 0.0767, 0.0767]),\n"," 30: tensor([0.0108, 0.0184, 0.0111, 0.0176, 0.0169, 0.0227, 0.0230, 0.0248, 0.0306,\n","         0.0275, 0.0422, 0.0313, 0.0280, 0.0321, 0.0388, 0.0443, 0.0374, 0.0388,\n","         0.0467, 0.0321, 0.0313, 0.0572, 0.0572, 0.0422, 0.0388, 0.0467, 0.0443,\n","         0.0495, 0.0529, 0.0529, 0.0467, 0.0495, 0.0467, 0.0388, 0.0422, 0.0572,\n","         0.0626, 0.0626, 0.0422, 0.0529, 0.0572, 0.0626, 0.0626, 0.0572, 0.0626,\n","         0.0626, 0.0626, 0.0626, 0.0626, 0.0626]),\n"," 31: tensor([0.0119, 0.0137, 0.0137, 0.0223, 0.0255, 0.0328, 0.0472, 0.0347, 0.0559,\n","         0.0299, 0.0417, 0.0354, 0.0429, 0.0559, 0.0472, 0.0386, 0.0589, 0.0533,\n","         0.0510, 0.0722, 0.0533, 0.0722, 0.0668, 0.0722, 0.0791, 0.0791, 0.0722,\n","         0.0791, 0.0722, 0.0791, 0.0791]),\n"," 32: tensor([0.0103, 0.0172, 0.0165, 0.0214, 0.0539, 0.0325, 0.0408, 0.0370, 0.0241,\n","         0.0370, 0.0359, 0.0278, 0.0359, 0.0576, 0.0423, 0.0408, 0.0508, 0.0440,\n","         0.0482, 0.0482, 0.0576, 0.0539, 0.0508, 0.0576, 0.0539, 0.0508, 0.0539,\n","         0.0539, 0.0576, 0.0682, 0.0682, 0.0539, 0.0576, 0.0682, 0.0682, 0.0623,\n","         0.0682, 0.0682, 0.0682, 0.0682, 0.0682, 0.0682]),\n"," 33: tensor([0.0124, 0.0081, 0.0092, 0.0169, 0.0198, 0.0210, 0.0284, 0.0206, 0.0246,\n","         0.0135, 0.0213, 0.0322, 0.0251, 0.0188, 0.0224, 0.0203, 0.0348, 0.0269,\n","         0.0284, 0.0322, 0.0491, 0.0426, 0.0334, 0.0491, 0.0401, 0.0538, 0.0426,\n","         0.0363, 0.0322, 0.0381, 0.0538, 0.0292, 0.0491, 0.0334, 0.0491, 0.0381,\n","         0.0538, 0.0426, 0.0426, 0.0455, 0.0426, 0.0401, 0.0538, 0.0538, 0.0455,\n","         0.0538, 0.0491, 0.0348, 0.0455, 0.0455, 0.0491, 0.0538, 0.0491, 0.0538,\n","         0.0401, 0.0455, 0.0538, 0.0538, 0.0491, 0.0538, 0.0538, 0.0538, 0.0538,\n","         0.0491, 0.0538, 0.0538, 0.0538, 0.0538]),\n"," 34: tensor([0.0134, 0.0135, 0.0191, 0.0355, 0.0335, 0.0286, 0.0303, 0.0503, 0.0435,\n","         0.0550, 0.0503, 0.0483, 0.0525, 0.0449, 0.0483, 0.0525, 0.0422, 0.0711,\n","         0.0658, 0.0658, 0.0778, 0.0778, 0.0778, 0.0778, 0.0658, 0.0778, 0.0658,\n","         0.0778, 0.0778, 0.0711, 0.0711, 0.0711]),\n"," 35: tensor([0.0206, 0.0370, 0.0193, 0.0321, 0.0917, 0.0857, 0.0626, 0.0648, 0.0990,\n","         0.0588, 0.0808, 0.0808, 0.0917, 0.1085, 0.0990, 0.1085]),\n"," 36: tensor([0.0091, 0.0130, 0.0108, 0.0119, 0.0495, 0.0230, 0.0286, 0.0313, 0.0388,\n","         0.0240, 0.0260, 0.0321, 0.0306, 0.0374, 0.0443, 0.0443, 0.0388, 0.0340,\n","         0.0330, 0.0422, 0.0422, 0.0374, 0.0350, 0.0443, 0.0422, 0.0362, 0.0388,\n","         0.0443, 0.0572, 0.0467, 0.0443, 0.0321, 0.0572, 0.0467, 0.0330, 0.0529,\n","         0.0495, 0.0529, 0.0572, 0.0572, 0.0467, 0.0626, 0.0467, 0.0572, 0.0626,\n","         0.0626, 0.0626, 0.0572, 0.0626, 0.0626]),\n"," 37: tensor([0.0129, 0.0084, 0.0140, 0.0142, 0.0111, 0.0209, 0.0192, 0.0221, 0.0358,\n","         0.0240, 0.0258, 0.0269, 0.0218, 0.0323, 0.0232, 0.0345, 0.0373, 0.0430,\n","         0.0456, 0.0296, 0.0456, 0.0430, 0.0430, 0.0430, 0.0488, 0.0408, 0.0358,\n","         0.0345, 0.0456, 0.0456, 0.0373, 0.0389, 0.0488, 0.0389, 0.0527, 0.0488,\n","         0.0408, 0.0488, 0.0488, 0.0333, 0.0527, 0.0389, 0.0456, 0.0408, 0.0488,\n","         0.0389, 0.0527, 0.0527, 0.0577, 0.0527, 0.0577, 0.0527, 0.0577, 0.0527,\n","         0.0577, 0.0577, 0.0577, 0.0577, 0.0577]),\n"," 38: tensor([0.0125, 0.0271, 0.0148, 0.0199, 0.0227, 0.0438, 0.0339, 0.0426, 0.0387,\n","         0.0464, 0.0587, 0.0536, 0.0560, 0.0536, 0.0657, 0.0702, 0.0657, 0.0702,\n","         0.0702, 0.0758, 0.0702, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n","         0.0830]),\n"," 39: tensor([0.0217, 0.0328, 0.0194, 0.0411, 0.0490, 0.0442, 0.0472, 0.0722, 0.0754,\n","         0.0754, 0.0884, 0.0945, 0.0884, 0.1118, 0.1021]),\n"," 40: tensor([0.0162, 0.0426, 0.0177, 0.0166, 0.0401, 0.0301, 0.0466, 0.0401, 0.0409,\n","         0.0659, 0.0602, 0.0491, 0.0659, 0.0851, 0.0788, 0.0933, 0.0788, 0.0851,\n","         0.0737, 0.0788, 0.0933, 0.0933]),\n"," 41: tensor([0.0082, 0.0127, 0.0131, 0.0227, 0.0105, 0.0165, 0.0165, 0.0240, 0.0235,\n","         0.0280, 0.0260, 0.0353, 0.0432, 0.0296, 0.0353, 0.0407, 0.0339, 0.0353,\n","         0.0432, 0.0407, 0.0386, 0.0353, 0.0407, 0.0315, 0.0315, 0.0327, 0.0305,\n","         0.0407, 0.0339, 0.0368, 0.0339, 0.0386, 0.0368, 0.0546, 0.0339, 0.0368,\n","         0.0407, 0.0462, 0.0499, 0.0546, 0.0368, 0.0499, 0.0499, 0.0462, 0.0499,\n","         0.0462, 0.0499, 0.0339, 0.0499, 0.0462, 0.0499, 0.0462, 0.0499, 0.0462,\n","         0.0546, 0.0462, 0.0546, 0.0499, 0.0546, 0.0546, 0.0546, 0.0546, 0.0546,\n","         0.0462, 0.0546, 0.0546]),\n"," 42: tensor([0.0098, 0.0170, 0.0117, 0.0162, 0.0308, 0.0290, 0.0366, 0.0308, 0.0321,\n","         0.0377, 0.0418, 0.0290, 0.0259, 0.0418, 0.0290, 0.0533, 0.0435, 0.0503,\n","         0.0503, 0.0435, 0.0503, 0.0533, 0.0435, 0.0503, 0.0570, 0.0533, 0.0533,\n","         0.0503, 0.0503, 0.0570, 0.0570, 0.0503, 0.0674, 0.0503, 0.0533, 0.0615,\n","         0.0615, 0.0674, 0.0674, 0.0615, 0.0674, 0.0674, 0.0674]),\n"," 43: tensor([0.0091, 0.0152, 0.0152, 0.0197, 0.0189, 0.0302, 0.0211, 0.0259, 0.0374,\n","         0.0327, 0.0389, 0.0294, 0.0426, 0.0348, 0.0449, 0.0510, 0.0348, 0.0477,\n","         0.0389, 0.0348, 0.0510, 0.0550, 0.0449, 0.0510, 0.0477, 0.0426, 0.0426,\n","         0.0449, 0.0477, 0.0477, 0.0426, 0.0603, 0.0550, 0.0550, 0.0603, 0.0603,\n","         0.0550, 0.0477, 0.0603, 0.0603, 0.0550, 0.0550, 0.0550, 0.0603, 0.0603,\n","         0.0603, 0.0603, 0.0550, 0.0550, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603]),\n"," 44: tensor([0.0111, 0.0125, 0.0112, 0.0157, 0.0179, 0.0278, 0.0278, 0.0268, 0.0331,\n","         0.0456, 0.0361, 0.0456, 0.0456, 0.0386, 0.0350, 0.0386, 0.0331, 0.0546,\n","         0.0400, 0.0510, 0.0510, 0.0373, 0.0645, 0.0481, 0.0546, 0.0589, 0.0481,\n","         0.0589, 0.0645, 0.0510, 0.0645, 0.0589, 0.0645, 0.0589, 0.0645, 0.0645,\n","         0.0645, 0.0645, 0.0546, 0.0589, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645,\n","         0.0645, 0.0645]),\n"," 45: tensor([0.0116, 0.0111, 0.0250, 0.0184, 0.0250, 0.0318, 0.0429, 0.0330, 0.0458,\n","         0.0476, 0.0542, 0.0476, 0.0542, 0.0572, 0.0393, 0.0404, 0.0572, 0.0767,\n","         0.0542, 0.0648, 0.0700, 0.0767, 0.0542, 0.0700, 0.0700, 0.0700, 0.0767,\n","         0.0700, 0.0767, 0.0767, 0.0700, 0.0767, 0.0767]),\n"," 46: tensor([0.0153, 0.0128, 0.0170, 0.0198, 0.0368, 0.0240, 0.0322, 0.0387, 0.0377,\n","         0.0496, 0.0520, 0.0581, 0.0548, 0.0496, 0.0456, 0.0581, 0.0735, 0.0520,\n","         0.0475, 0.0475, 0.0548, 0.0621, 0.0548, 0.0548, 0.0621, 0.0671, 0.0581,\n","         0.0671, 0.0671, 0.0671, 0.0621, 0.0621, 0.0735, 0.0671, 0.0735, 0.0671]),\n"," 47: tensor([0.0130, 0.0192, 0.0217, 0.0179, 0.0442, 0.0357, 0.0642, 0.0481, 0.0410,\n","         0.0467, 0.0727, 0.0514, 0.0481, 0.0534, 0.0556, 0.0642, 0.0580, 0.0786,\n","         0.0680, 0.0786, 0.0861, 0.0727, 0.0861, 0.0861, 0.0861, 0.0786]),\n"," 48: tensor([0.0055, 0.0080, 0.0111, 0.0105, 0.0107, 0.0159, 0.0126, 0.0162, 0.0109,\n","         0.0116, 0.0154, 0.0154, 0.0149, 0.0141, 0.0197, 0.0208, 0.0221, 0.0171,\n","         0.0214, 0.0192, 0.0208, 0.0171, 0.0175, 0.0168, 0.0171, 0.0229, 0.0147,\n","         0.0248, 0.0197, 0.0221, 0.0208, 0.0271, 0.0248, 0.0324, 0.0221, 0.0179,\n","         0.0350, 0.0183, 0.0208, 0.0303, 0.0238, 0.0303, 0.0238, 0.0197, 0.0192,\n","         0.0221, 0.0229, 0.0259, 0.0259, 0.0286, 0.0271, 0.0303, 0.0248, 0.0214,\n","         0.0259, 0.0259, 0.0350, 0.0286, 0.0271, 0.0286, 0.0350, 0.0259, 0.0324,\n","         0.0259, 0.0221, 0.0383, 0.0286, 0.0324, 0.0271, 0.0350, 0.0259, 0.0286,\n","         0.0286, 0.0271, 0.0383, 0.0259, 0.0303, 0.0350, 0.0303, 0.0383, 0.0383,\n","         0.0324, 0.0324, 0.0383, 0.0324, 0.0324, 0.0271, 0.0303, 0.0303, 0.0324,\n","         0.0303, 0.0324, 0.0324, 0.0303, 0.0350, 0.0350, 0.0383, 0.0324, 0.0350,\n","         0.0383, 0.0350, 0.0383, 0.0350, 0.0383, 0.0324, 0.0383, 0.0383, 0.0383,\n","         0.0383, 0.0383, 0.0350, 0.0383, 0.0350, 0.0383, 0.0324, 0.0350, 0.0383,\n","         0.0350, 0.0350, 0.0383, 0.0383, 0.0383, 0.0383, 0.0383, 0.0383, 0.0383,\n","         0.0350, 0.0383, 0.0383, 0.0383, 0.0350, 0.0383, 0.0383, 0.0383, 0.0383]),\n"," 49: tensor([0.0066, 0.0079, 0.0138, 0.0128, 0.0165, 0.0306, 0.0144, 0.0172, 0.0233,\n","         0.0262, 0.0203, 0.0216, 0.0271, 0.0239, 0.0239, 0.0203, 0.0293, 0.0222,\n","         0.0293, 0.0415, 0.0239, 0.0254, 0.0338, 0.0239, 0.0338, 0.0239, 0.0254,\n","         0.0254, 0.0338, 0.0306, 0.0262, 0.0338, 0.0293, 0.0359, 0.0293, 0.0306,\n","         0.0246, 0.0271, 0.0359, 0.0359, 0.0384, 0.0415, 0.0415, 0.0338, 0.0306,\n","         0.0359, 0.0321, 0.0384, 0.0384, 0.0384, 0.0359, 0.0415, 0.0415, 0.0415,\n","         0.0415, 0.0415, 0.0338, 0.0359, 0.0338, 0.0384, 0.0415, 0.0338, 0.0415,\n","         0.0384, 0.0384, 0.0415, 0.0415, 0.0454, 0.0454, 0.0338, 0.0454, 0.0384,\n","         0.0454, 0.0454, 0.0415, 0.0384, 0.0338, 0.0454, 0.0384, 0.0454, 0.0454,\n","         0.0384, 0.0415, 0.0454, 0.0454, 0.0454, 0.0415, 0.0415, 0.0415, 0.0454,\n","         0.0454, 0.0415, 0.0415, 0.0454, 0.0454, 0.0454]),\n"," 50: tensor([0.0084, 0.0140, 0.0187, 0.0179, 0.0185, 0.0158, 0.0253, 0.0277, 0.0358,\n","         0.0320, 0.0310, 0.0392, 0.0292, 0.0392, 0.0392, 0.0234, 0.0439, 0.0243,\n","         0.0331, 0.0374, 0.0292, 0.0392, 0.0344, 0.0469, 0.0413, 0.0439, 0.0469,\n","         0.0506, 0.0358, 0.0392, 0.0555, 0.0469, 0.0469, 0.0555, 0.0469, 0.0555,\n","         0.0555, 0.0555, 0.0555, 0.0469, 0.0555, 0.0506, 0.0555, 0.0506, 0.0392,\n","         0.0469, 0.0506, 0.0506, 0.0555, 0.0555, 0.0506, 0.0469, 0.0555, 0.0469,\n","         0.0506, 0.0506, 0.0506, 0.0469, 0.0555, 0.0555, 0.0506, 0.0506, 0.0555,\n","         0.0555]),\n"," 51: tensor([0.0151, 0.0221, 0.0209, 0.0165, 0.0253, 0.0234, 0.0363, 0.0574, 0.0434,\n","         0.0406, 0.0574, 0.0541, 0.0406, 0.0489, 0.0434, 0.0513, 0.0513, 0.0662,\n","         0.0662, 0.0613, 0.0574, 0.0613, 0.0725, 0.0613, 0.0541, 0.0574, 0.0574,\n","         0.0725, 0.0725, 0.0662, 0.0725, 0.0725, 0.0613, 0.0613, 0.0662, 0.0725,\n","         0.0725]),\n"," 52: tensor([0.0209, 0.0138, 0.0177, 0.0308, 0.0510, 0.0645, 0.0393, 0.0645, 0.0435,\n","         0.0510, 0.0481, 0.0510, 0.0772, 0.0913, 0.0913, 0.0913, 0.0833, 0.0913,\n","         0.0913, 0.0833, 0.0833, 0.0913, 0.0913]),\n"," 53: tensor([0.0195, 0.0261, 0.0233, 0.0306, 0.0806, 0.1066, 0.0953, 0.0953, 0.1231,\n","         0.1231]),\n"," 54: tensor([0.0197, 0.0163, 0.0335, 0.0401, 0.0281, 0.0442, 0.0370, 0.0642, 0.0580,\n","         0.0580, 0.0454, 0.0534, 0.0534, 0.0861, 0.0727, 0.0861, 0.0642, 0.0680,\n","         0.0642, 0.0861, 0.0680, 0.0680, 0.0861, 0.0786, 0.0861, 0.0861]),\n"," 55: tensor([0.0162, 0.0227, 0.0160, 0.0185, 0.0398, 0.0259, 0.0362, 0.0272, 0.0268,\n","         0.0342, 0.0342, 0.0333, 0.0362, 0.0385, 0.0398, 0.0413, 0.0497, 0.0304,\n","         0.0342, 0.0398, 0.0311, 0.0449, 0.0449, 0.0449, 0.0563, 0.0430, 0.0563,\n","         0.0609, 0.0563, 0.0563, 0.0471, 0.0609, 0.0667, 0.0667, 0.0527, 0.0563,\n","         0.0667, 0.0609, 0.0667, 0.0667, 0.0667, 0.0609, 0.0667, 0.0667]),\n"," 56: tensor([0.0094, 0.0107, 0.0158, 0.0189, 0.0175, 0.0204, 0.0251, 0.0237, 0.0260,\n","         0.0362, 0.0306, 0.0306, 0.0443, 0.0467, 0.0321, 0.0495, 0.0495, 0.0374,\n","         0.0495, 0.0422, 0.0529, 0.0443, 0.0529, 0.0572, 0.0572, 0.0340, 0.0572,\n","         0.0529, 0.0626, 0.0443, 0.0529, 0.0529, 0.0495, 0.0572, 0.0572, 0.0495,\n","         0.0495, 0.0572, 0.0529, 0.0572, 0.0529, 0.0572, 0.0626, 0.0495, 0.0572,\n","         0.0626, 0.0572, 0.0626, 0.0626, 0.0626]),\n"," 57: tensor([0.0096, 0.0129, 0.0197, 0.0192, 0.0292, 0.0398, 0.0277, 0.0252, 0.0272,\n","         0.0373, 0.0362, 0.0333, 0.0471, 0.0373, 0.0527, 0.0497, 0.0497, 0.0430,\n","         0.0527, 0.0385, 0.0413, 0.0527, 0.0563, 0.0449, 0.0563, 0.0527, 0.0527,\n","         0.0471, 0.0667, 0.0563, 0.0667, 0.0563, 0.0497, 0.0609, 0.0667, 0.0667,\n","         0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667]),\n"," 58: tensor([0.0135, 0.0265, 0.0244, 0.0210, 0.0246, 0.0615, 0.0329, 0.0282, 0.0363,\n","         0.0363, 0.0615, 0.0363, 0.0371, 0.0465, 0.0658, 0.0410, 0.0580, 0.0615,\n","         0.0711, 0.0711, 0.0525, 0.0465, 0.0658, 0.0658, 0.0658, 0.0580, 0.0711,\n","         0.0711, 0.0580, 0.0615, 0.0778, 0.0778]),\n"," 59: tensor([0.0156, 0.0135, 0.0213, 0.0253, 0.0341, 0.0326, 0.0417, 0.0341, 0.0521,\n","         0.0390, 0.0295, 0.0379, 0.0433, 0.0521, 0.0471, 0.0451, 0.0417, 0.0698,\n","         0.0552, 0.0590, 0.0417, 0.0698, 0.0552, 0.0698, 0.0698, 0.0590, 0.0638,\n","         0.0698, 0.0552, 0.0521, 0.0638, 0.0698, 0.0638, 0.0638, 0.0698, 0.0698,\n","         0.0552, 0.0638, 0.0698, 0.0698]),\n"," 60: tensor([0.0081, 0.0157, 0.0107, 0.0175, 0.0180, 0.0184, 0.0303, 0.0312, 0.0184,\n","         0.0280, 0.0221, 0.0334, 0.0232, 0.0273, 0.0225, 0.0312, 0.0417, 0.0225,\n","         0.0295, 0.0295, 0.0255, 0.0377, 0.0312, 0.0312, 0.0395, 0.0312, 0.0417,\n","         0.0347, 0.0334, 0.0417, 0.0472, 0.0255, 0.0472, 0.0417, 0.0510, 0.0510,\n","         0.0472, 0.0417, 0.0442, 0.0472, 0.0510, 0.0280, 0.0559, 0.0559, 0.0472,\n","         0.0417, 0.0442, 0.0559, 0.0510, 0.0510, 0.0395, 0.0442, 0.0559, 0.0510,\n","         0.0559, 0.0510, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559, 0.0559]),\n"," 61: tensor([0.0091, 0.0309, 0.0144, 0.0246, 0.0239, 0.0263, 0.0309, 0.0192, 0.0302,\n","         0.0426, 0.0471, 0.0426, 0.0354, 0.0378, 0.0354, 0.0333, 0.0343, 0.0471,\n","         0.0365, 0.0447, 0.0392, 0.0447, 0.0333, 0.0500, 0.0392, 0.0500, 0.0577,\n","         0.0426, 0.0378, 0.0500, 0.0577, 0.0365, 0.0577, 0.0500, 0.0577, 0.0471,\n","         0.0577, 0.0535, 0.0577, 0.0577, 0.0632, 0.0632, 0.0632, 0.0577, 0.0632,\n","         0.0632, 0.0632, 0.0632, 0.0632]),\n"," 62: tensor([0.0093, 0.0237, 0.0255, 0.0180, 0.0361, 0.0228, 0.0400, 0.0323, 0.0350,\n","         0.0510, 0.0386, 0.0340, 0.0481, 0.0340, 0.0361, 0.0417, 0.0456, 0.0400,\n","         0.0481, 0.0481, 0.0435, 0.0361, 0.0361, 0.0481, 0.0417, 0.0481, 0.0546,\n","         0.0481, 0.0589, 0.0510, 0.0645, 0.0645, 0.0589, 0.0589, 0.0481, 0.0645,\n","         0.0645, 0.0645, 0.0510, 0.0645, 0.0546, 0.0546, 0.0645, 0.0589, 0.0645,\n","         0.0645, 0.0645]),\n"," 63: tensor([0.0151, 0.0178, 0.0302, 0.0368, 0.0598, 0.0415, 0.0500, 0.0439, 0.0707,\n","         0.0674, 0.0913, 0.0913, 0.0791, 0.0745, 0.0913, 0.1000, 0.0913, 0.1000,\n","         0.1000]),\n"," 64: tensor([0.0147, 0.0258, 0.0172, 0.0239, 0.0274, 0.0488, 0.0378, 0.0325, 0.0436,\n","         0.0410, 0.0360, 0.0378, 0.0639, 0.0388, 0.0423, 0.0488, 0.0563, 0.0639,\n","         0.0423, 0.0598, 0.0690, 0.0535, 0.0598, 0.0598, 0.0639, 0.0756, 0.0756,\n","         0.0756, 0.0756, 0.0690, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 65: tensor([0.0125, 0.0120, 0.0172, 0.0159, 0.0305, 0.0260, 0.0396, 0.0536, 0.0702,\n","         0.0758, 0.0415, 0.0657, 0.0830, 0.0830, 0.0758, 0.0657, 0.0830, 0.0657,\n","         0.0619, 0.0702, 0.0830, 0.0758, 0.0830, 0.0758, 0.0830, 0.0830, 0.0830,\n","         0.0830]),\n"," 66: tensor([0.0274, 0.0539, 0.0495, 0.0615, 0.0811, 0.1179, 0.1066]),\n"," 67: tensor([0.0181, 0.0387, 0.0284, 0.0438, 0.0481, 0.0527, 0.0786, 0.0680, 0.0962,\n","         0.0786, 0.0745, 0.1054, 0.1054, 0.1054, 0.0833, 0.0891, 0.1054]),\n"," 68: tensor([0.0095, 0.0128, 0.0126, 0.0184, 0.0253, 0.0369, 0.0269, 0.0358, 0.0295,\n","         0.0249, 0.0233, 0.0269, 0.0330, 0.0426, 0.0322, 0.0409, 0.0491, 0.0521,\n","         0.0445, 0.0426, 0.0557, 0.0602, 0.0426, 0.0521, 0.0491, 0.0659, 0.0491,\n","         0.0659, 0.0521, 0.0557, 0.0466, 0.0659, 0.0659, 0.0602, 0.0602, 0.0659,\n","         0.0659, 0.0659, 0.0521, 0.0659, 0.0659, 0.0659, 0.0659, 0.0659, 0.0659]),\n"," 69: tensor([0.0318, 0.0250, 0.0240, 0.0281, 0.0335, 0.0266, 0.0461, 0.0405, 0.0326,\n","         0.0344, 0.0461, 0.0461, 0.0516, 0.0440, 0.0551, 0.0440, 0.0516, 0.0595,\n","         0.0595, 0.0461, 0.0551, 0.0652, 0.0595, 0.0595, 0.0486, 0.0551, 0.0595,\n","         0.0421, 0.0516, 0.0516, 0.0486, 0.0652, 0.0595, 0.0595, 0.0595, 0.0652,\n","         0.0595, 0.0652, 0.0652, 0.0652, 0.0595, 0.0516, 0.0595, 0.0652, 0.0652,\n","         0.0652]),\n"," 70: tensor([0.0149, 0.0242, 0.0290, 0.0278, 0.0401, 0.0442, 0.0497, 0.0351, 0.0312,\n","         0.0420, 0.0454, 0.0442, 0.0556, 0.0481, 0.0680, 0.0861, 0.0534, 0.0556,\n","         0.0642, 0.0680, 0.0642, 0.0786, 0.0786, 0.0786, 0.0786, 0.0786]),\n"," 71: tensor([0.0194, 0.0175, 0.0162, 0.0329, 0.0345, 0.0279, 0.0403, 0.0282, 0.0488,\n","         0.0412, 0.0434, 0.0445, 0.0598, 0.0505, 0.0714, 0.0570, 0.0714, 0.0630,\n","         0.0598, 0.0714, 0.0845, 0.0668, 0.0845, 0.0845, 0.0714, 0.0714, 0.0845]),\n"," 72: tensor([0.0086, 0.0108, 0.0109, 0.0158, 0.0232, 0.0171, 0.0228, 0.0284, 0.0291,\n","         0.0308, 0.0284, 0.0196, 0.0225, 0.0352, 0.0318, 0.0328, 0.0328, 0.0480,\n","         0.0271, 0.0402, 0.0383, 0.0449, 0.0277, 0.0383, 0.0402, 0.0259, 0.0259,\n","         0.0383, 0.0518, 0.0339, 0.0518, 0.0449, 0.0423, 0.0518, 0.0568, 0.0423,\n","         0.0480, 0.0518, 0.0568, 0.0568, 0.0402, 0.0518, 0.0480, 0.0480, 0.0568,\n","         0.0568, 0.0480, 0.0568, 0.0480, 0.0568, 0.0568, 0.0568, 0.0568, 0.0568,\n","         0.0568, 0.0480, 0.0518, 0.0568, 0.0568, 0.0568, 0.0568]),\n"," 73: tensor([0.0152, 0.0242, 0.0165, 0.0116, 0.0238, 0.0327, 0.0264, 0.0259, 0.0228,\n","         0.0374, 0.0309, 0.0318, 0.0287, 0.0449, 0.0318, 0.0374, 0.0374, 0.0407,\n","         0.0477, 0.0477, 0.0407, 0.0477, 0.0550, 0.0603, 0.0550, 0.0550, 0.0510,\n","         0.0603, 0.0426, 0.0449, 0.0550, 0.0477, 0.0603, 0.0550, 0.0477, 0.0603,\n","         0.0550, 0.0449, 0.0603, 0.0603, 0.0550, 0.0603, 0.0603, 0.0550, 0.0603,\n","         0.0603, 0.0603, 0.0603, 0.0550, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603]),\n"," 74: tensor([0.0109, 0.0155, 0.0186, 0.0152, 0.0239, 0.0272, 0.0324, 0.0239, 0.0221,\n","         0.0239, 0.0354, 0.0302, 0.0535, 0.0500, 0.0426, 0.0447, 0.0378, 0.0471,\n","         0.0471, 0.0426, 0.0426, 0.0577, 0.0577, 0.0632, 0.0500, 0.0632, 0.0471,\n","         0.0500, 0.0471, 0.0632, 0.0577, 0.0577, 0.0471, 0.0632, 0.0535, 0.0535,\n","         0.0577, 0.0577, 0.0577, 0.0632, 0.0535, 0.0577, 0.0632, 0.0577, 0.0632,\n","         0.0632, 0.0632, 0.0632, 0.0632]),\n"," 75: tensor([0.0133, 0.0145, 0.0206, 0.0253, 0.0458, 0.0336, 0.0458, 0.0383, 0.0572,\n","         0.0443, 0.0495, 0.0476, 0.0517, 0.0458, 0.0495, 0.0572, 0.0700, 0.0517,\n","         0.0648, 0.0648, 0.0767, 0.0572, 0.0700, 0.0700, 0.0648, 0.0648, 0.0700,\n","         0.0767, 0.0767, 0.0767, 0.0767, 0.0767, 0.0767]),\n"," 76: tensor([0.0183, 0.0256, 0.0345, 0.0232, 0.0205, 0.0527, 0.0339, 0.0471, 0.0333,\n","         0.0419, 0.0506, 0.0527, 0.0443, 0.0456, 0.0745, 0.0527, 0.0745, 0.0816,\n","         0.0690, 0.0745, 0.0816, 0.0816, 0.0645, 0.0816, 0.0816, 0.0816, 0.0745,\n","         0.0816, 0.0816]),\n"," 77: tensor([0.0147, 0.0167, 0.0189, 0.0341, 0.0420, 0.0772, 0.0772, 0.0583, 0.0690,\n","         0.0605, 0.0690, 0.0825, 0.0772, 0.0891, 0.0976, 0.0976, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 78: tensor([0.0169, 0.0185, 0.0286, 0.0230, 0.0399, 0.0377, 0.0350, 0.0368, 0.0520,\n","         0.0520, 0.0350, 0.0439, 0.0621, 0.0621, 0.0621, 0.0548, 0.0621, 0.0671,\n","         0.0496, 0.0735, 0.0581, 0.0671, 0.0621, 0.0548, 0.0671, 0.0621, 0.0671,\n","         0.0735, 0.0735, 0.0671, 0.0735, 0.0735, 0.0735, 0.0735, 0.0735, 0.0735]),\n"," 79: tensor([0.0109, 0.0124, 0.0105, 0.0282, 0.0267, 0.0221, 0.0354, 0.0296, 0.0291,\n","         0.0513, 0.0574, 0.0434, 0.0513, 0.0541, 0.0406, 0.0331, 0.0541, 0.0468,\n","         0.0725, 0.0541, 0.0613, 0.0513, 0.0662, 0.0662, 0.0662, 0.0725, 0.0662,\n","         0.0613, 0.0725, 0.0574, 0.0725, 0.0662, 0.0662, 0.0725, 0.0725, 0.0725,\n","         0.0725]),\n"," 80: tensor([0.0111, 0.0185, 0.0305, 0.0267, 0.0230, 0.0548, 0.0377, 0.0368, 0.0411,\n","         0.0359, 0.0377, 0.0548, 0.0581, 0.0439, 0.0411, 0.0520, 0.0621, 0.0548,\n","         0.0621, 0.0671, 0.0671, 0.0671, 0.0735, 0.0735, 0.0671, 0.0671, 0.0548,\n","         0.0735, 0.0735, 0.0671, 0.0671, 0.0671, 0.0671, 0.0735, 0.0735, 0.0735]),\n"," 81: tensor([0.0529, 0.0366, 0.0303, 0.0399, 0.0436, 0.0556, 0.0673, 0.0808, 0.0450,\n","         0.0731, 0.0731, 0.1085, 0.0990, 0.0857, 0.1085, 0.0917]),\n"," 82: tensor([0.0148, 0.0199, 0.0318, 0.0263, 0.0560, 0.0464, 0.0464, 0.0464, 0.0515,\n","         0.0560, 0.0619, 0.0515, 0.0830, 0.0560, 0.0657, 0.0830, 0.0657, 0.0657,\n","         0.0830, 0.0758, 0.0758, 0.0758, 0.0830, 0.0758, 0.0830, 0.0830, 0.0830,\n","         0.0830]),\n"," 83: tensor([0.0087, 0.0294, 0.0165, 0.0171, 0.0287, 0.0294, 0.0250, 0.0360, 0.0270,\n","         0.0246, 0.0238, 0.0250, 0.0287, 0.0294, 0.0337, 0.0318, 0.0374, 0.0550,\n","         0.0318, 0.0426, 0.0510, 0.0449, 0.0477, 0.0603, 0.0389, 0.0510, 0.0510,\n","         0.0389, 0.0449, 0.0550, 0.0360, 0.0477, 0.0449, 0.0510, 0.0603, 0.0449,\n","         0.0510, 0.0407, 0.0477, 0.0603, 0.0510, 0.0603, 0.0550, 0.0510, 0.0603,\n","         0.0603, 0.0603, 0.0603, 0.0550, 0.0603, 0.0603, 0.0603, 0.0603, 0.0603]),\n"," 84: tensor([0.0117, 0.0174, 0.0113, 0.0135, 0.0290, 0.0389, 0.0525, 0.0465, 0.0422,\n","         0.0658, 0.0615, 0.0711, 0.0525, 0.0580, 0.0658, 0.0580, 0.0615, 0.0550,\n","         0.0580, 0.0580, 0.0711, 0.0711, 0.0778, 0.0778, 0.0778, 0.0658, 0.0711,\n","         0.0711, 0.0711, 0.0658, 0.0658, 0.0778]),\n"," 85: tensor([0.0150, 0.0094, 0.0113, 0.0204, 0.0262, 0.0254, 0.0354, 0.0304, 0.0365,\n","         0.0365, 0.0326, 0.0344, 0.0354, 0.0461, 0.0390, 0.0365, 0.0516, 0.0461,\n","         0.0390, 0.0486, 0.0390, 0.0405, 0.0551, 0.0461, 0.0595, 0.0595, 0.0595,\n","         0.0461, 0.0652, 0.0652, 0.0652, 0.0551, 0.0652, 0.0652, 0.0652, 0.0595,\n","         0.0652, 0.0516, 0.0516, 0.0595, 0.0652, 0.0551, 0.0595, 0.0652, 0.0652,\n","         0.0652]),\n"," 86: tensor([0.0203, 0.0490, 0.0240, 0.0292, 0.0490, 0.0385, 0.0428, 0.0566, 0.0654,\n","         0.0693, 0.0654, 0.0620, 0.0741, 0.0620, 0.0693, 0.0620, 0.0620, 0.0801,\n","         0.0877, 0.0877, 0.0801, 0.0877, 0.0801, 0.0877, 0.0877]),\n"," 87: tensor([0.0089, 0.0119, 0.0117, 0.0142, 0.0255, 0.0367, 0.0247, 0.0324, 0.0397,\n","         0.0486, 0.0367, 0.0414, 0.0414, 0.0324, 0.0293, 0.0333, 0.0414, 0.0519,\n","         0.0434, 0.0397, 0.0367, 0.0458, 0.0397, 0.0343, 0.0519, 0.0434, 0.0397,\n","         0.0458, 0.0434, 0.0519, 0.0458, 0.0486, 0.0561, 0.0561, 0.0458, 0.0561,\n","         0.0614, 0.0519, 0.0434, 0.0561, 0.0458, 0.0561, 0.0561, 0.0486, 0.0614,\n","         0.0519, 0.0519, 0.0614, 0.0561, 0.0614, 0.0561, 0.0561]),\n"," 88: tensor([0.0118, 0.0115, 0.0108, 0.0221, 0.0290, 0.0290, 0.0330, 0.0340, 0.0481,\n","         0.0364, 0.0393, 0.0297, 0.0351, 0.0340, 0.0284, 0.0454, 0.0481, 0.0454,\n","         0.0321, 0.0410, 0.0514, 0.0454, 0.0556, 0.0481, 0.0481, 0.0454, 0.0514,\n","         0.0556, 0.0481, 0.0514, 0.0514, 0.0556, 0.0481, 0.0514, 0.0481, 0.0556,\n","         0.0609, 0.0514, 0.0514, 0.0609, 0.0556, 0.0556, 0.0609, 0.0609, 0.0556,\n","         0.0609, 0.0609, 0.0556, 0.0609, 0.0609, 0.0609, 0.0609, 0.0609]),\n"," 89: tensor([0.0116, 0.0167, 0.0154, 0.0436, 0.0202, 0.0359, 0.0284, 0.0568, 0.0518,\n","         0.0542, 0.0599, 0.0635, 0.0635, 0.0679, 0.0383, 0.0635, 0.0679, 0.0679,\n","         0.0599, 0.0542, 0.0803, 0.0679, 0.0803, 0.0679, 0.0733, 0.0733, 0.0635,\n","         0.0733, 0.0803, 0.0803]),\n"," 90: tensor([0.0114, 0.0199, 0.0164, 0.0442, 0.0308, 0.0354, 0.0328, 0.0308, 0.0340,\n","         0.0533, 0.0490, 0.0589, 0.0533, 0.0533, 0.0510, 0.0589, 0.0791, 0.0668,\n","         0.0722, 0.0791, 0.0791, 0.0722, 0.0791, 0.0722, 0.0668, 0.0722, 0.0722,\n","         0.0791, 0.0791, 0.0791, 0.0791]),\n"," 91: tensor([0.0138, 0.0198, 0.0280, 0.0287, 0.0465, 0.0465, 0.0435, 0.0383, 0.0533,\n","         0.0711, 0.0711, 0.0711, 0.0711, 0.0711, 0.0870, 0.0870, 0.0870, 0.0870,\n","         0.0953, 0.0953, 0.0953]),\n"," 92: tensor([0.0197, 0.0143, 0.0154, 0.0228, 0.0383, 0.0375, 0.0542, 0.0464, 0.0679,\n","         0.0635, 0.0599, 0.0568, 0.0518, 0.0733, 0.0542, 0.0599, 0.0599, 0.0679,\n","         0.0599, 0.0733, 0.0679, 0.0679, 0.0679, 0.0803, 0.0733, 0.0803, 0.0803,\n","         0.0803, 0.0803, 0.0803]),\n"," 93: tensor([0.0166, 0.0358, 0.0363, 0.0401, 0.0455, 0.0387, 0.0602, 0.0521, 0.0445,\n","         0.0737, 0.0851, 0.0737, 0.0788, 0.0788, 0.0788, 0.0933, 0.0933, 0.0933,\n","         0.0933, 0.0933, 0.0933, 0.0933]),\n"," 94: tensor([0.0321, 0.0233, 0.0442, 0.0556, 0.0478, 0.0574, 0.0574, 0.0811, 0.0725,\n","         0.0765, 0.0867, 0.0937, 0.1026, 0.0867, 0.0867, 0.0937, 0.1026, 0.1026]),\n"," 95: tensor([0.0204, 0.0224, 0.0367, 0.0308, 0.0468, 0.0468, 0.0546, 0.0468, 0.0615,\n","         0.0833, 0.0645, 0.0833, 0.0772, 0.0772, 0.0589, 0.0833, 0.0913, 0.0913,\n","         0.0833, 0.0833, 0.0833, 0.0913, 0.0913]),\n"," 96: tensor([0.0132, 0.0212, 0.0246, 0.0481, 0.0373, 0.0456, 0.0481, 0.0546, 0.0495,\n","         0.0566, 0.0566, 0.0772, 0.0680, 0.0645, 0.0645, 0.0833, 0.0913, 0.0913,\n","         0.0833, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 97: tensor([0.0116, 0.0323, 0.0251, 0.0262, 0.0423, 0.0402, 0.0352, 0.0599, 0.0733,\n","         0.0334, 0.0679, 0.0480, 0.0568, 0.0449, 0.0568, 0.0599, 0.0635, 0.0635,\n","         0.0542, 0.0518, 0.0635, 0.0464, 0.0679, 0.0803, 0.0635, 0.0679, 0.0733,\n","         0.0803, 0.0803, 0.0803]),\n"," 98: tensor([0.0172, 0.0201, 0.0260, 0.0328, 0.0357, 0.0587, 0.0536, 0.0450, 0.0657,\n","         0.0536, 0.0619, 0.0657, 0.0496, 0.0587, 0.0758, 0.0587, 0.0702, 0.0619,\n","         0.0830, 0.0657, 0.0758, 0.0758, 0.0830, 0.0758, 0.0758, 0.0830, 0.0830,\n","         0.0830]),\n"," 99: tensor([0.0149, 0.0135, 0.0205, 0.0202, 0.0290, 0.0281, 0.0209, 0.0174, 0.0205,\n","         0.0281, 0.0258, 0.0217, 0.0398, 0.0325, 0.0398, 0.0312, 0.0398, 0.0230,\n","         0.0273, 0.0375, 0.0301, 0.0398, 0.0230, 0.0301, 0.0339, 0.0312, 0.0258,\n","         0.0425, 0.0425, 0.0339, 0.0375, 0.0301, 0.0312, 0.0375, 0.0398, 0.0375,\n","         0.0503, 0.0339, 0.0425, 0.0375, 0.0503, 0.0425, 0.0459, 0.0459, 0.0425,\n","         0.0459, 0.0459, 0.0425, 0.0398, 0.0503, 0.0503, 0.0459, 0.0398, 0.0356,\n","         0.0459, 0.0503, 0.0425, 0.0425, 0.0503, 0.0425, 0.0425, 0.0459, 0.0459,\n","         0.0503, 0.0425, 0.0425, 0.0459, 0.0503, 0.0503, 0.0459, 0.0503, 0.0503,\n","         0.0459, 0.0503, 0.0503, 0.0459, 0.0503, 0.0503]),\n"," 100: tensor([0.0155, 0.0442, 0.0335, 0.0377, 0.0501, 0.0574, 0.0613, 0.0556, 0.0636,\n","         0.0613, 0.0811, 0.0725, 0.0937, 0.0937, 0.0937, 0.1026, 0.1026, 0.1026]),\n"," 101: tensor([0.0147, 0.0181, 0.0237, 0.0239, 0.0309, 0.0452, 0.0378, 0.0226, 0.0388,\n","         0.0488, 0.0352, 0.0563, 0.0488, 0.0639, 0.0510, 0.0535, 0.0563, 0.0598,\n","         0.0563, 0.0535, 0.0756, 0.0563, 0.0563, 0.0756, 0.0598, 0.0598, 0.0469,\n","         0.0690, 0.0690, 0.0756, 0.0690, 0.0690, 0.0756, 0.0756]),\n"," 102: tensor([0.0147, 0.0445, 0.0185, 0.0294, 0.0398, 0.0488, 0.0658, 0.0465, 0.0891,\n","         0.0658, 0.0976, 0.0825, 0.0976, 0.0825, 0.0727, 0.0825, 0.0825, 0.0891,\n","         0.0976, 0.0976]),\n"," 103: tensor([0.0328, 0.0340, 0.0510, 0.0312, 0.0533, 0.0490, 0.0449, 0.0833, 0.1118,\n","         0.0945, 0.1118, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 104: tensor([0.0148, 0.0235, 0.0278, 0.0357, 0.0442, 0.0346, 0.0556, 0.0454, 0.0454,\n","         0.0609, 0.0497, 0.0642, 0.0680, 0.0727, 0.0861, 0.0727, 0.0786, 0.0727,\n","         0.0861, 0.0786, 0.0861, 0.0786, 0.0861, 0.0786, 0.0861, 0.0727]),\n"," 105: tensor([0.0093, 0.0122, 0.0301, 0.0234, 0.0361, 0.0373, 0.0481, 0.0510, 0.0386,\n","         0.0361, 0.0386, 0.0295, 0.0273, 0.0361, 0.0510, 0.0435, 0.0481, 0.0361,\n","         0.0386, 0.0510, 0.0546, 0.0417, 0.0510, 0.0546, 0.0546, 0.0589, 0.0456,\n","         0.0546, 0.0589, 0.0589, 0.0589, 0.0481, 0.0510, 0.0510, 0.0645, 0.0645,\n","         0.0481, 0.0510, 0.0589, 0.0589, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645,\n","         0.0645, 0.0645]),\n"," 106: tensor([0.0141, 0.0309, 0.0354, 0.0465, 0.0359, 0.0386, 0.0658, 0.0445, 0.0690,\n","         0.0630, 0.0891, 0.0825, 0.0690, 0.0976, 0.0727, 0.0825, 0.0690, 0.0825,\n","         0.0891, 0.0891]),\n"," 107: tensor([0.0113, 0.0095, 0.0184, 0.0279, 0.0269, 0.0295, 0.0409, 0.0249, 0.0358,\n","         0.0466, 0.0466, 0.0358, 0.0369, 0.0338, 0.0358, 0.0466, 0.0445, 0.0369,\n","         0.0521, 0.0409, 0.0602, 0.0491, 0.0466, 0.0521, 0.0394, 0.0659, 0.0557,\n","         0.0602, 0.0602, 0.0602, 0.0521, 0.0521, 0.0659, 0.0602, 0.0557, 0.0602,\n","         0.0602, 0.0557, 0.0557, 0.0659, 0.0659, 0.0659, 0.0659, 0.0659, 0.0659]),\n"," 108: tensor([0.0135, 0.0149, 0.0254, 0.0308, 0.0313, 0.0422, 0.0483, 0.0435, 0.0525,\n","         0.0329, 0.0550, 0.0580, 0.0550, 0.0503, 0.0711, 0.0550, 0.0778, 0.0615,\n","         0.0711, 0.0778, 0.0711, 0.0711, 0.0389, 0.0525, 0.0550, 0.0580, 0.0778,\n","         0.0615, 0.0615, 0.0778, 0.0778, 0.0778]),\n"," 109: tensor([0.0224, 0.0205, 0.0497, 0.0290, 0.0516, 0.0976, 0.0861, 0.1155, 0.0976,\n","         0.0976, 0.1155, 0.1054, 0.1054, 0.0816]),\n"," 110: tensor([0.0116, 0.0350, 0.0227, 0.0221, 0.0416, 0.0393, 0.0336, 0.0429, 0.0458,\n","         0.0443, 0.0416, 0.0572, 0.0458, 0.0542, 0.0700, 0.0700, 0.0606, 0.0606,\n","         0.0700, 0.0606, 0.0648, 0.0648, 0.0542, 0.0648, 0.0648, 0.0700, 0.0648,\n","         0.0767, 0.0700, 0.0767, 0.0700, 0.0700, 0.0767]),\n"," 111: tensor([0.0205, 0.0198, 0.0313, 0.0269, 0.0351, 0.0408, 0.0365, 0.0309, 0.0456,\n","         0.0745, 0.0645, 0.0419, 0.0577, 0.0816, 0.0550, 0.0550, 0.0550, 0.0609,\n","         0.0645, 0.0506, 0.0745, 0.0745, 0.0816, 0.0690, 0.0816, 0.0816, 0.0609,\n","         0.0816, 0.0816]),\n"," 112: tensor([0.0109, 0.0126, 0.0227, 0.0274, 0.0267, 0.0242, 0.0263, 0.0513, 0.0434,\n","         0.0662, 0.0450, 0.0513, 0.0489, 0.0468, 0.0613, 0.0450, 0.0574, 0.0613,\n","         0.0574, 0.0574, 0.0662, 0.0613, 0.0725, 0.0613, 0.0541, 0.0662, 0.0725,\n","         0.0613, 0.0662, 0.0662, 0.0662, 0.0725, 0.0662, 0.0574, 0.0574, 0.0725,\n","         0.0725]),\n"," 113: tensor([0.0158, 0.0162, 0.0286, 0.0253, 0.0278, 0.0435, 0.0417, 0.0510, 0.0367,\n","         0.0546, 0.0468, 0.0913, 0.0680, 0.0833, 0.0913, 0.0645, 0.0680, 0.0913,\n","         0.0913, 0.0913, 0.0772, 0.0833, 0.0913]),\n"," 114: tensor([0.0341, 0.0313, 0.0277, 0.0363, 0.0477, 0.0415, 0.0430, 0.0415, 0.0513,\n","         0.0577, 0.0500, 0.0645, 0.0674, 0.0913, 0.0707, 0.0913, 0.1000, 0.1000,\n","         0.1000]),\n"," 115: tensor([0.0155, 0.0354, 0.0295, 0.0516, 0.0371, 0.0555, 0.0577, 0.0555, 0.0707,\n","         0.0408, 0.0408, 0.0707, 0.0667, 0.0756, 0.0632, 0.0667, 0.0816, 0.0894,\n","         0.0816, 0.0816, 0.0816, 0.0816, 0.0894, 0.0894]),\n"," 116: tensor([0.0198, 0.0181, 0.0321, 0.0533, 0.0410, 0.0396, 0.0465, 0.0570, 0.0533,\n","         0.0591, 0.0870, 0.0870, 0.0870, 0.0806, 0.0870, 0.0806, 0.0806, 0.0953,\n","         0.0870, 0.0953, 0.0953]),\n"," 117: tensor([0.0186, 0.0357, 0.0260, 0.0250, 0.0236, 0.0379, 0.0438, 0.0496, 0.0536,\n","         0.0657, 0.0702, 0.0702, 0.0536, 0.0515, 0.0702, 0.0830, 0.0619, 0.0702,\n","         0.0657, 0.0619, 0.0758, 0.0830, 0.0758, 0.0830, 0.0830, 0.0758, 0.0758,\n","         0.0830]),\n"," 118: tensor([0.0151, 0.0174, 0.0280, 0.0284, 0.0345, 0.0577, 0.0745, 0.0674, 0.0363,\n","         0.0620, 0.0913, 0.0645, 0.0674, 0.0745, 0.0791, 0.0745, 0.0913, 0.0845,\n","         0.1000]),\n"," 119: tensor([0.0232, 0.0377, 0.0377, 0.0429, 0.0693, 0.0722, 0.0625, 0.0722, 0.0884,\n","         0.1118, 0.0945, 0.0945, 0.1021, 0.1118, 0.1118]),\n"," 120: tensor([0.0230, 0.0141, 0.0359, 0.0267, 0.0377, 0.0520, 0.0359, 0.0305, 0.0411,\n","         0.0424, 0.0439, 0.0581, 0.0735, 0.0621, 0.0581, 0.0621, 0.0621, 0.0581,\n","         0.0520, 0.0439, 0.0520, 0.0671, 0.0671, 0.0581, 0.0735, 0.0735, 0.0671,\n","         0.0621, 0.0735, 0.0735, 0.0671, 0.0735, 0.0671, 0.0735, 0.0621, 0.0735]),\n"," 121: tensor([0.0173, 0.0472, 0.0458, 0.0360, 0.0458, 0.0891, 0.0945, 0.1195, 0.1010,\n","         0.1010, 0.1091, 0.1195, 0.1195]),\n"," 122: tensor([0.0250, 0.0217, 0.0271, 0.0369, 0.0791, 0.0606, 0.0884, 0.0722, 0.1021,\n","         0.1118, 0.0791, 0.0754, 0.1118, 0.0945, 0.1118]),\n"," 123: tensor([0.0229, 0.0325, 0.0350, 0.0290, 0.0435, 0.0643, 0.0674, 0.0806, 0.0674,\n","         0.0674, 0.0643, 0.0711, 0.0754, 0.0615, 0.0806, 0.0953, 0.0754, 0.0953,\n","         0.0870, 0.0953, 0.0953]),\n"," 124: tensor([0.0205, 0.0269, 0.0373, 0.0309, 0.0471, 0.0471, 0.0609, 0.0745, 0.0488,\n","         0.0443, 0.0609, 0.0645, 0.0609, 0.0745, 0.0645, 0.0745, 0.0550, 0.0550,\n","         0.0609, 0.0609, 0.0645, 0.0745, 0.0690, 0.0745, 0.0745, 0.0816, 0.0816,\n","         0.0816, 0.0816]),\n"," 125: tensor([0.0091, 0.0150, 0.0260, 0.0230, 0.0330, 0.0340, 0.0388, 0.0286, 0.0422,\n","         0.0443, 0.0306, 0.0340, 0.0467, 0.0443, 0.0330, 0.0443, 0.0495, 0.0495,\n","         0.0467, 0.0467, 0.0626, 0.0572, 0.0467, 0.0422, 0.0572, 0.0626, 0.0467,\n","         0.0467, 0.0572, 0.0529, 0.0572, 0.0495, 0.0529, 0.0495, 0.0626, 0.0626,\n","         0.0626, 0.0572, 0.0626, 0.0626, 0.0572, 0.0626, 0.0626, 0.0626, 0.0626,\n","         0.0626, 0.0626, 0.0626, 0.0626, 0.0626]),\n"," 126: tensor([0.0223, 0.0317, 0.0309, 0.0488, 0.0680, 0.0566, 0.0662, 0.1091, 0.1091,\n","         0.1021, 0.1179]),\n"," 127: tensor([0.0126, 0.0205, 0.0192, 0.0278, 0.0244, 0.0237, 0.0262, 0.0284, 0.0290,\n","         0.0321, 0.0454, 0.0364, 0.0340, 0.0556, 0.0340, 0.0364, 0.0351, 0.0454,\n","         0.0514, 0.0454, 0.0393, 0.0410, 0.0514, 0.0481, 0.0556, 0.0556, 0.0514,\n","         0.0514, 0.0481, 0.0609, 0.0556, 0.0609, 0.0609, 0.0609, 0.0514, 0.0556,\n","         0.0556, 0.0609, 0.0556, 0.0514, 0.0609, 0.0556, 0.0556, 0.0609, 0.0556,\n","         0.0609, 0.0556, 0.0609, 0.0609, 0.0609, 0.0556, 0.0609, 0.0609]),\n"," 128: tensor([0.0178, 0.0197, 0.0291, 0.0468, 0.0613, 0.0613, 0.0662, 0.0811, 0.0867,\n","         0.0811, 0.1026, 0.0811, 0.0867, 0.0636, 0.0811, 0.1026, 0.1026, 0.0937]),\n"," 129: tensor([0.0137, 0.0137, 0.0248, 0.0213, 0.0442, 0.0472, 0.0406, 0.0456, 0.0668,\n","         0.0386, 0.0533, 0.0559, 0.0472, 0.0510, 0.0722, 0.0625, 0.0589, 0.0589,\n","         0.0533, 0.0668, 0.0722, 0.0791, 0.0668, 0.0625, 0.0791, 0.0791, 0.0791,\n","         0.0791, 0.0722, 0.0589, 0.0791]),\n"," 130: tensor([0.0086, 0.0099, 0.0173, 0.0236, 0.0318, 0.0201, 0.0328, 0.0284, 0.0339,\n","         0.0215, 0.0449, 0.0284, 0.0308, 0.0271, 0.0318, 0.0383, 0.0367, 0.0299,\n","         0.0423, 0.0402, 0.0423, 0.0568, 0.0518, 0.0480, 0.0423, 0.0383, 0.0423,\n","         0.0423, 0.0352, 0.0328, 0.0423, 0.0402, 0.0449, 0.0480, 0.0449, 0.0423,\n","         0.0568, 0.0402, 0.0480, 0.0568, 0.0423, 0.0568, 0.0568, 0.0480, 0.0518,\n","         0.0568, 0.0568, 0.0480, 0.0518, 0.0518, 0.0568, 0.0518, 0.0518, 0.0518,\n","         0.0568, 0.0568, 0.0518, 0.0480, 0.0480, 0.0518, 0.0568]),\n"," 131: tensor([0.0187, 0.0118, 0.0205, 0.0198, 0.0328, 0.0419, 0.0398, 0.0456, 0.0443,\n","         0.0577, 0.0609, 0.0550, 0.0550, 0.0577, 0.0745, 0.0645, 0.0816, 0.0690,\n","         0.0645, 0.0745, 0.0745, 0.0816, 0.0816, 0.0816, 0.0816, 0.0745, 0.0816,\n","         0.0745, 0.0816]),\n"," 132: tensor([0.0249, 0.0318, 0.0366, 0.0208, 0.0700, 0.0476, 0.0467, 0.0767, 0.0917,\n","         0.0990, 0.1085, 0.0990, 0.0857, 0.0917, 0.1085, 0.1085]),\n"," 133: tensor([0.0138, 0.0167, 0.0313, 0.0244, 0.0367, 0.0449, 0.0359, 0.0423, 0.0449,\n","         0.0635, 0.0304, 0.0449, 0.0733, 0.0383, 0.0635, 0.0599, 0.0679, 0.0542,\n","         0.0733, 0.0733, 0.0679, 0.0599, 0.0803, 0.0733, 0.0733, 0.0733, 0.0803,\n","         0.0803, 0.0803, 0.0803]),\n"," 134: tensor([0.0169, 0.0361, 0.0281, 0.0361, 0.0791, 0.0945, 0.0606, 0.0668, 0.1021,\n","         0.1021, 0.1118, 0.1021, 0.1118, 0.1021, 0.1118]),\n"," 135: tensor([0.0174, 0.0221, 0.0262, 0.0373, 0.0471, 0.0667, 0.0913, 0.0976, 0.0976,\n","         0.0913, 0.0861, 0.0577, 0.0861, 0.1054]),\n"," 136: tensor([0.0301, 0.0388, 0.0358, 0.0693, 0.0605, 0.1240, 0.0716, 0.0877, 0.0877,\n","         0.1132, 0.1048, 0.1048]),\n"," 137: tensor([0.0136, 0.0199, 0.0221, 0.0238, 0.0625, 0.0429, 0.0236, 0.0377, 0.0490,\n","         0.0510, 0.0472, 0.0559, 0.0625, 0.0589, 0.0533, 0.0589, 0.0533, 0.0791,\n","         0.0533, 0.0510, 0.0559, 0.0722, 0.0668, 0.0589, 0.0722, 0.0791, 0.0722,\n","         0.0722, 0.0791, 0.0722, 0.0722]),\n"," 138: tensor([0.0221, 0.0403, 0.0435, 0.0477, 0.0477, 0.0396, 0.0674, 0.0711, 0.0674,\n","         0.0870, 0.0550, 0.0754, 0.0711, 0.0711, 0.0953, 0.0870, 0.0870, 0.0953,\n","         0.0953, 0.0953, 0.0953]),\n"," 139: tensor([0.0408, 0.0322, 0.0398, 0.0598, 0.0945, 0.0772, 0.0690, 0.0945, 0.0845,\n","         0.0945, 0.1091, 0.1195, 0.1091]),\n"," 140: tensor([0.0240, 0.0328, 0.0415, 0.0371, 0.0657, 0.0379, 0.0396, 0.0619, 0.0657,\n","         0.0619, 0.0830, 0.0479, 0.0619, 0.0479, 0.0587, 0.0758, 0.0758, 0.0619,\n","         0.0830, 0.0702, 0.0758, 0.0830, 0.0830, 0.0830, 0.0830, 0.0758, 0.0830,\n","         0.0830]),\n"," 141: tensor([0.0806, 0.0398, 0.0334, 0.0452, 0.0690, 0.0806, 0.1091, 0.1091, 0.0845,\n","         0.1195, 0.1195, 0.1195, 0.1195]),\n"," 142: tensor([0.0155, 0.0252, 0.0171, 0.0359, 0.0426, 0.0667, 0.0555, 0.0632, 0.0555,\n","         0.0632, 0.0756, 0.0756, 0.0816, 0.0632, 0.0816, 0.0707, 0.0603, 0.0632,\n","         0.0816, 0.0816, 0.0816, 0.0894, 0.0894, 0.0894]),\n"," 143: tensor([0.0173, 0.0378, 0.0368, 0.0378, 0.0430, 0.0674, 0.0913, 0.0674, 0.0745,\n","         0.0745, 0.0745, 0.0913, 0.0845, 0.0913, 0.0913, 0.0791, 0.0913, 0.1000,\n","         0.1000]),\n"," 144: tensor([0.0232, 0.0212, 0.0214, 0.0318, 0.0533, 0.0884, 0.0833, 0.0833, 0.0945,\n","         0.0833, 0.1118, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 145: tensor([0.0118, 0.0266, 0.0398, 0.0471, 0.0323, 0.0488, 0.0488, 0.0645, 0.0577,\n","         0.0577, 0.0430, 0.0816, 0.0645, 0.0816, 0.0816, 0.0471, 0.0745, 0.0816,\n","         0.0690, 0.0745, 0.0816, 0.0690, 0.0745, 0.0745, 0.0816, 0.0745, 0.0816,\n","         0.0745, 0.0816]),\n"," 146: tensor([0.0195, 0.0404, 0.0358, 0.0527, 0.0801, 0.1091, 0.1091, 0.1291, 0.1291,\n","         0.1291, 0.1291]),\n"," 147: tensor([0.0119, 0.0256, 0.0282, 0.0242, 0.0292, 0.0298, 0.0373, 0.0373, 0.0362,\n","         0.0497, 0.0471, 0.0449, 0.0398, 0.0563, 0.0413, 0.0449, 0.0497, 0.0471,\n","         0.0527, 0.0667, 0.0667, 0.0497, 0.0563, 0.0385, 0.0667, 0.0609, 0.0609,\n","         0.0609, 0.0667, 0.0563, 0.0471, 0.0609, 0.0609, 0.0667, 0.0609, 0.0609,\n","         0.0667, 0.0667, 0.0667, 0.0527, 0.0667, 0.0667, 0.0667, 0.0667]),\n"," 148: tensor([0.0181, 0.0282, 0.0302, 0.0290, 0.0410, 0.0570, 0.0674, 0.0503, 0.0711,\n","         0.0711, 0.0754, 0.0570, 0.0754, 0.0754, 0.0953, 0.0953, 0.0754, 0.0870,\n","         0.0754, 0.0953, 0.0953]),\n"," 149: tensor([0.0200, 0.0217, 0.0292, 0.0258, 0.0535, 0.0365, 0.0603, 0.0459, 0.0378,\n","         0.0632, 0.0894, 0.0632, 0.0667, 0.0756, 0.0756, 0.0632, 0.0756, 0.0707,\n","         0.0632, 0.0632, 0.0756, 0.0816, 0.0894, 0.0894]),\n"," 150: tensor([0.0164, 0.0358, 0.0308, 0.0416, 0.0556, 0.0700, 0.0808, 0.0917, 0.1085,\n","         0.0767, 0.1085, 0.0990, 0.0990, 0.0990, 0.1085, 0.1085]),\n"," 151: tensor([0.0120, 0.0277, 0.0232, 0.0255, 0.0496, 0.0536, 0.0657, 0.0371, 0.0657,\n","         0.0536, 0.0758, 0.0496, 0.0619, 0.0758, 0.0758, 0.0536, 0.0758, 0.0830,\n","         0.0619, 0.0587, 0.0830, 0.0830, 0.0758, 0.0830, 0.0758, 0.0758, 0.0758,\n","         0.0830]),\n"," 152: tensor([0.0303, 0.0259, 0.0308, 0.0237, 0.0272, 0.0465, 0.0503, 0.0380, 0.0308,\n","         0.0449, 0.0465, 0.0550, 0.0465, 0.0580, 0.0711, 0.0525, 0.0503, 0.0658,\n","         0.0503, 0.0711, 0.0778, 0.0580, 0.0615, 0.0550, 0.0658, 0.0658, 0.0525,\n","         0.0465, 0.0658, 0.0658, 0.0778, 0.0778]),\n"," 153: tensor([0.0240, 0.0192, 0.0284, 0.0456, 0.0500, 0.0408, 0.0415, 0.0620, 0.0707,\n","         0.0707, 0.0674, 0.1000, 0.0913, 0.0913, 0.1000, 0.1000, 0.0913, 0.1000,\n","         0.1000]),\n"," 154: tensor([0.0218, 0.0465, 0.0455, 0.0501, 0.0514, 0.0563, 0.0690, 0.0658, 0.0772,\n","         0.0825, 0.0891, 0.0976, 0.0690, 0.0976, 0.0891, 0.0976, 0.0891, 0.0891,\n","         0.0976, 0.0976]),\n"," 155: tensor([0.0145, 0.0194, 0.0466, 0.0477, 0.0354, 0.0447, 0.0577, 0.0707, 0.0745,\n","         0.0791, 0.0542, 0.0913, 0.0745, 0.0674, 0.1000, 0.0913, 0.0845, 0.1000,\n","         0.1000]),\n"," 156: tensor([0.0415, 0.0339, 0.0387, 0.0209, 0.0479, 0.0702, 0.0657, 0.0536, 0.0830,\n","         0.0758, 0.0830, 0.0758, 0.0702, 0.0830, 0.0702, 0.0830, 0.0830, 0.0830,\n","         0.0830, 0.0758, 0.0830, 0.0758, 0.0758, 0.0830, 0.0758, 0.0830, 0.0830,\n","         0.0830]),\n"," 157: tensor([0.0152, 0.0347, 0.0490, 0.0292, 0.0654, 0.0544, 0.0439, 0.0490, 0.0566,\n","         0.0654, 0.0450, 0.0654, 0.0801, 0.0877, 0.0506, 0.0877, 0.0693, 0.0801,\n","         0.0693, 0.0801, 0.0877, 0.0877, 0.0877, 0.0877, 0.0877]),\n"," 158: tensor([0.0370, 0.0362, 0.0327, 0.0354, 0.0542, 0.0857, 0.0700, 0.0767, 0.0990,\n","         0.0917, 0.1085, 0.0990, 0.0917, 0.1085, 0.1085, 0.1085]),\n"," 159: tensor([0.0153, 0.0325, 0.0420, 0.0430, 0.0325, 0.0304, 0.0481, 0.0609, 0.0481,\n","         0.0642, 0.0786, 0.0727, 0.0727, 0.0642, 0.0727, 0.0727, 0.0786, 0.0642,\n","         0.0642, 0.0727, 0.0861, 0.0727, 0.0727, 0.0861, 0.0861, 0.0861]),\n"," 160: tensor([0.0370, 0.0208, 0.0330, 0.0422, 0.0572, 0.0808, 0.0495, 0.0648, 0.0529,\n","         0.0606, 0.1085, 0.0731, 0.0990, 0.1085, 0.0990, 0.1085]),\n"," 161: tensor([0.0178, 0.0195, 0.0183, 0.0346, 0.0541, 0.0725, 0.0765, 0.0725, 0.0867,\n","         0.0765, 0.0592, 0.0765, 0.0937, 0.0937, 0.0811, 0.1026, 0.1026, 0.1026]),\n"," 162: tensor([0.0225, 0.0171, 0.0295, 0.0270, 0.0447, 0.0471, 0.0516, 0.0707, 0.0632,\n","         0.0603, 0.0756, 0.0667, 0.0707, 0.0667, 0.0756, 0.0894, 0.0816, 0.0707,\n","         0.0816, 0.0894, 0.0894, 0.0894, 0.0894, 0.0894]),\n"," 163: tensor([0.0124, 0.0330, 0.0272, 0.0430, 0.0351, 0.0680, 0.0642, 0.0680, 0.0401,\n","         0.0556, 0.0454, 0.0534, 0.0481, 0.0727, 0.0609, 0.0727, 0.0680, 0.0786,\n","         0.0786, 0.0580, 0.0727, 0.0861, 0.0861, 0.0861, 0.0727, 0.0861]),\n"," 164: tensor([0.0235, 0.0442, 0.0324, 0.0393, 0.0725, 0.0725, 0.0937, 0.0692, 0.0937,\n","         0.0867, 0.0811, 0.0937, 0.0937, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026]),\n"," 165: tensor([0.0181, 0.0224, 0.0251, 0.0478, 0.0435, 0.0506, 0.0455, 0.0788, 0.0629,\n","         0.0659, 0.0737, 0.0933, 0.0851, 0.0851, 0.0788, 0.0851, 0.0737, 0.0788,\n","         0.0933, 0.0933, 0.0933, 0.0933]),\n"," 166: tensor([0.0190, 0.0224, 0.0252, 0.0239, 0.0290, 0.0294, 0.0452, 0.0369, 0.0488,\n","         0.0436, 0.0436, 0.0510, 0.0639, 0.0345, 0.0535, 0.0563, 0.0598, 0.0756,\n","         0.0639, 0.0690, 0.0756, 0.0598, 0.0563, 0.0756, 0.0598, 0.0690, 0.0756,\n","         0.0756, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 167: tensor([0.0240, 0.0362, 0.0436, 0.0471, 0.0592, 0.1155, 0.0913, 0.0816, 0.1054,\n","         0.0861, 0.0976, 0.0913, 0.1155, 0.1054]),\n"," 168: tensor([0.0118, 0.0142, 0.0189, 0.0333, 0.0365, 0.0506, 0.0456, 0.0690, 0.0577,\n","         0.0745, 0.0609, 0.0690, 0.0609, 0.0550, 0.0550, 0.0816, 0.0609, 0.0645,\n","         0.0690, 0.0816, 0.0816, 0.0745, 0.0745, 0.0745, 0.0745, 0.0816, 0.0745,\n","         0.0816, 0.0816]),\n"," 169: tensor([0.0156, 0.0135, 0.0211, 0.0272, 0.0552, 0.0390, 0.0471, 0.0638, 0.0552,\n","         0.0494, 0.0403, 0.0521, 0.0494, 0.0698, 0.0521, 0.0552, 0.0494, 0.0552,\n","         0.0698, 0.0590, 0.0494, 0.0471, 0.0521, 0.0552, 0.0638, 0.0698, 0.0590,\n","         0.0552, 0.0698, 0.0521, 0.0638, 0.0698, 0.0698, 0.0698, 0.0638, 0.0698,\n","         0.0590, 0.0698, 0.0698, 0.0698]),\n"," 170: tensor([0.0175, 0.0435, 0.0379, 0.0435, 0.0495, 0.0833, 0.0722, 0.0772, 0.0615,\n","         0.0680, 0.0527, 0.0772, 0.0833, 0.0615, 0.0680, 0.0722, 0.0772, 0.0772,\n","         0.0913, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 171: tensor([0.0126, 0.0241, 0.0201, 0.0354, 0.0316, 0.0423, 0.0280, 0.0267, 0.0527,\n","         0.0559, 0.0707, 0.0559, 0.0707, 0.0477, 0.0477, 0.0477, 0.0477, 0.0559,\n","         0.0598, 0.0527, 0.0598, 0.0645, 0.0527, 0.0707, 0.0559, 0.0598, 0.0598,\n","         0.0559, 0.0645, 0.0707, 0.0707, 0.0707, 0.0707, 0.0645, 0.0645, 0.0707,\n","         0.0707, 0.0707, 0.0707]),\n"," 172: tensor([0.0102, 0.0238, 0.0228, 0.0284, 0.0294, 0.0363, 0.0373, 0.0477, 0.0395,\n","         0.0527, 0.0439, 0.0395, 0.0645, 0.0500, 0.0500, 0.0559, 0.0645, 0.0477,\n","         0.0707, 0.0707, 0.0456, 0.0707, 0.0707, 0.0527, 0.0707, 0.0598, 0.0645,\n","         0.0598, 0.0645, 0.0707, 0.0645, 0.0598, 0.0645, 0.0645, 0.0707, 0.0707,\n","         0.0707, 0.0707, 0.0707]),\n"," 173: tensor([0.0159, 0.0183, 0.0481, 0.0438, 0.0527, 0.0711, 0.0503, 0.0786, 0.0711,\n","         0.0556, 0.0589, 0.0786, 0.0654, 0.0891, 0.1054, 0.1054, 0.1054]),\n"," 174: tensor([0.0170, 0.0210, 0.0168, 0.0264, 0.0392, 0.0462, 0.0476, 0.0524, 0.0490,\n","         0.0654, 0.0490, 0.0524, 0.0801, 0.0654, 0.0741, 0.0591, 0.0654, 0.0801,\n","         0.0877, 0.0741, 0.0801, 0.0654, 0.0877, 0.0877, 0.0877]),\n"," 175: tensor([0.0192, 0.0259, 0.0351, 0.0410, 0.0442, 0.0481, 0.0609, 0.0377, 0.0642,\n","         0.0727, 0.0609, 0.0467, 0.0680, 0.0609, 0.0642, 0.0680, 0.0609, 0.0534,\n","         0.0861, 0.0609, 0.0727, 0.0727, 0.0727, 0.0786, 0.0727, 0.0861]),\n"," 176: tensor([0.0142, 0.0268, 0.0415, 0.0294, 0.0450, 0.0450, 0.0657, 0.0496, 0.0496,\n","         0.0379, 0.0464, 0.0657, 0.0758, 0.0758, 0.0830, 0.0619, 0.0619, 0.0830,\n","         0.0758, 0.0758, 0.0830, 0.0758, 0.0758, 0.0758, 0.0758, 0.0758, 0.0830,\n","         0.0830]),\n"," 177: tensor([0.0418, 0.0400, 0.0409, 0.0555, 0.0836, 0.1240, 0.1240, 0.1048, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 178: tensor([0.0205, 0.0171, 0.0298, 0.0316, 0.0707, 0.0378, 0.0436, 0.0667, 0.0707,\n","         0.0632, 0.0816, 0.0577, 0.0603, 0.0894, 0.0485, 0.0756, 0.0603, 0.0894,\n","         0.0632, 0.0894, 0.0816, 0.0894, 0.0894, 0.0894]),\n"," 179: tensor([0.0208, 0.0190, 0.0323, 0.0527, 0.0620, 0.0674, 0.0845, 0.0707, 0.0620,\n","         0.1000, 0.0707, 0.0913, 0.0913, 0.1000, 0.1000, 0.1000, 0.0913, 0.0913,\n","         0.1000]),\n"," 180: tensor([0.0272, 0.0351, 0.0246, 0.0351, 0.0381, 0.0690, 0.0443, 0.0645, 0.0609,\n","         0.0398, 0.0645, 0.0506, 0.0389, 0.0550, 0.0577, 0.0645, 0.0745, 0.0645,\n","         0.0690, 0.0745, 0.0745, 0.0745, 0.0690, 0.0745, 0.0816, 0.0690, 0.0816,\n","         0.0816, 0.0816]),\n"," 181: tensor([0.0229, 0.0367, 0.0496, 0.0423, 0.0668, 0.0845, 0.0690, 0.1091, 0.0891,\n","         0.0845, 0.1091, 0.1195, 0.1091]),\n"," 182: tensor([0.0159, 0.0240, 0.0147, 0.0458, 0.0374, 0.0294, 0.0443, 0.0606, 0.0458,\n","         0.0429, 0.0542, 0.0648, 0.0648, 0.0648, 0.0700, 0.0542, 0.0700, 0.0606,\n","         0.0700, 0.0648, 0.0700, 0.0648, 0.0700, 0.0542, 0.0700, 0.0606, 0.0648,\n","         0.0767, 0.0767, 0.0767, 0.0767, 0.0767, 0.0767]),\n"," 183: tensor([0.0136, 0.0141, 0.0238, 0.0280, 0.0406, 0.0625, 0.0442, 0.0559, 0.0589,\n","         0.0472, 0.0456, 0.0722, 0.0791, 0.0559, 0.0472, 0.0722, 0.0722, 0.0589,\n","         0.0589, 0.0625, 0.0722, 0.0791, 0.0791, 0.0791, 0.0589, 0.0722, 0.0791,\n","         0.0791, 0.0791, 0.0791, 0.0791]),\n"," 184: tensor([0.0199, 0.0468, 0.0811, 0.0377, 0.0526, 0.0725, 0.0662, 0.0811, 0.0501,\n","         0.0765, 0.0867, 0.1026, 0.0867, 0.0937, 0.0937, 0.1026, 0.1026, 0.1026]),\n"," 185: tensor([0.0213, 0.0312, 0.0377, 0.0673, 0.0925, 0.0877, 0.0801, 0.1048, 0.1132,\n","         0.1132, 0.1132, 0.1132]),\n"," 186: tensor([0.0249, 0.0592, 0.0363, 0.0526, 0.0725, 0.0765, 0.0636, 0.0692, 0.0692,\n","         0.0867, 0.1026, 0.0725, 0.0765, 0.1026, 0.0937, 0.0867, 0.0765, 0.1026]),\n"," 187: tensor([0.0157, 0.0251, 0.0370, 0.0350, 0.0542, 0.0767, 0.0588, 0.0917, 0.0917,\n","         0.0990, 0.1085, 0.0990, 0.1085, 0.1085, 0.1085, 0.1085]),\n"," 188: tensor([0.0209, 0.0269, 0.0363, 0.0304, 0.0375, 0.0659, 0.0602, 0.0659, 0.0659,\n","         0.0538, 0.0578, 0.0788, 0.0933, 0.0788, 0.0557, 0.0933, 0.0737, 0.0933,\n","         0.0933, 0.0933, 0.0851, 0.0933]),\n"," 189: tensor([0.0574, 0.0510, 0.0625, 0.0945, 0.0884, 0.1179, 0.1443]),\n"," 190: tensor([0.0218, 0.0249, 0.0249, 0.0325, 0.0304, 0.0452, 0.0598, 0.0436, 0.0488,\n","         0.0325, 0.0388, 0.0410, 0.0331, 0.0410, 0.0469, 0.0598, 0.0423, 0.0535,\n","         0.0469, 0.0535, 0.0639, 0.0639, 0.0510, 0.0535, 0.0639, 0.0535, 0.0756,\n","         0.0563, 0.0639, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 191: tensor([0.0124, 0.0242, 0.0401, 0.0262, 0.0385, 0.0514, 0.0340, 0.0393, 0.0410,\n","         0.0442, 0.0680, 0.0467, 0.0430, 0.0580, 0.0680, 0.0609, 0.0642, 0.0727,\n","         0.0534, 0.0861, 0.0861, 0.0609, 0.0861, 0.0861, 0.0861, 0.0861]),\n"," 192: tensor([0.0221, 0.0268, 0.0248, 0.0700, 0.0680, 0.0962, 0.0801, 0.1291, 0.1291,\n","         0.1179, 0.1291]),\n"," 193: tensor([0.0122, 0.0123, 0.0233, 0.0304, 0.0559, 0.0559, 0.0383, 0.0477, 0.0500,\n","         0.0559, 0.0395, 0.0477, 0.0345, 0.0395, 0.0707, 0.0707, 0.0598, 0.0527,\n","         0.0707, 0.0645, 0.0598, 0.0645, 0.0527, 0.0645, 0.0598, 0.0707, 0.0598,\n","         0.0500, 0.0707, 0.0707, 0.0598, 0.0707, 0.0707, 0.0707, 0.0598, 0.0707,\n","         0.0707, 0.0707, 0.0707]),\n"," 194: tensor([0.0101, 0.0121, 0.0188, 0.0221, 0.0379, 0.0295, 0.0333, 0.0494, 0.0379,\n","         0.0349, 0.0326, 0.0494, 0.0390, 0.0590, 0.0451, 0.0638, 0.0471, 0.0451,\n","         0.0521, 0.0638, 0.0521, 0.0552, 0.0590, 0.0590, 0.0552, 0.0638, 0.0521,\n","         0.0698, 0.0638, 0.0638, 0.0698, 0.0638, 0.0698, 0.0698, 0.0638, 0.0698,\n","         0.0698, 0.0698, 0.0698, 0.0698]),\n"," 195: tensor([0.0252, 0.0301, 0.0197, 0.0468, 0.0574, 0.0811, 0.0526, 0.0613, 0.1026,\n","         0.0692, 0.0725, 0.0937, 0.0811, 0.0811, 0.0937, 0.1026, 0.0937, 0.1026]),\n"," 196: tensor([0.0314, 0.0326, 0.0435, 0.0381, 0.0387, 0.0466, 0.0538, 0.0491, 0.0659,\n","         0.0695, 0.0629, 0.0695, 0.0602, 0.0851, 0.0629, 0.0933, 0.0788, 0.0851,\n","         0.0788, 0.0933, 0.0933, 0.0851]),\n"," 197: tensor([0.0174, 0.0226, 0.0306, 0.0273, 0.0501, 0.0658, 0.0630, 0.0727, 0.0546,\n","         0.0690, 0.0605, 0.0727, 0.0891, 0.0891, 0.0891, 0.0976, 0.0976, 0.0976,\n","         0.0891, 0.0825]),\n"," 198: tensor([0.0290, 0.0259, 0.0370, 0.0410, 0.0534, 0.0514, 0.0580, 0.0377, 0.0609,\n","         0.0727, 0.0497, 0.0534, 0.0642, 0.0727, 0.0580, 0.0642, 0.0642, 0.0786,\n","         0.0642, 0.0727, 0.0786, 0.0727, 0.0861, 0.0786, 0.0861, 0.0861]),\n"," 199: tensor([0.0193, 0.0358, 0.0429, 0.0379, 0.0556, 0.0808, 0.0767, 0.0588, 0.0808,\n","         0.0857, 0.0731, 0.0990, 0.0857, 0.1085, 0.0990, 0.1085]),\n"," 200: tensor([0.0268, 0.0225, 0.0247, 0.0328, 0.0480, 0.0498, 0.0599, 0.0679, 0.0542,\n","         0.0480, 0.0367, 0.0568, 0.0498, 0.0635, 0.0733, 0.0599, 0.0635, 0.0733,\n","         0.0568, 0.0803, 0.0733, 0.0803, 0.0803, 0.0679, 0.0803, 0.0803, 0.0803,\n","         0.0803, 0.0803, 0.0803]),\n"," 201: tensor([0.0275, 0.0409, 0.0322, 0.0476, 0.0591, 0.0591, 0.0620, 0.0620, 0.0524,\n","         0.0591, 0.0741, 0.0654, 0.0654, 0.0620, 0.0654, 0.0476, 0.0877, 0.0741,\n","         0.0693, 0.0741, 0.0877, 0.0801, 0.0741, 0.0654, 0.0877]),\n"," 202: tensor([0.0339, 0.0426, 0.0711, 0.0591, 0.0754, 0.1066, 0.1231, 0.1005, 0.1231,\n","         0.1066]),\n"," 203: tensor([0.0141, 0.0339, 0.0272, 0.0269, 0.0309, 0.0471, 0.0577, 0.0443, 0.0609,\n","         0.0550, 0.0550, 0.0745, 0.0527, 0.0816, 0.0550, 0.0645, 0.0550, 0.0690,\n","         0.0745, 0.0690, 0.0816, 0.0690, 0.0745, 0.0690, 0.0816, 0.0745, 0.0816,\n","         0.0816, 0.0816]),\n"," 204: tensor([0.0160, 0.0196, 0.0174, 0.0345, 0.0514, 0.0364, 0.0546, 0.0428, 0.0690,\n","         0.0354, 0.0465, 0.0465, 0.0546, 0.0630, 0.0445, 0.0445, 0.0690, 0.0546,\n","         0.0546, 0.0630, 0.0514, 0.0546, 0.0583, 0.0583, 0.0583, 0.0630, 0.0690,\n","         0.0630, 0.0583, 0.0546, 0.0630, 0.0690, 0.0583, 0.0690, 0.0690, 0.0630,\n","         0.0630, 0.0690, 0.0630, 0.0690, 0.0690]),\n"," 205: tensor([0.0260, 0.0250, 0.0396, 0.0387, 0.0536, 0.0560, 0.0560, 0.0619, 0.0657,\n","         0.0657, 0.0758, 0.0587, 0.0830, 0.0657, 0.0758, 0.0758, 0.0830, 0.0619,\n","         0.0657, 0.0657, 0.0758, 0.0758, 0.0657, 0.0702, 0.0758, 0.0758, 0.0830,\n","         0.0830]),\n"," 206: tensor([0.0169, 0.0212, 0.0323, 0.0574, 0.0510, 0.0645, 0.0668, 0.0833, 0.1118,\n","         0.0754, 0.0884, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 207: tensor([0.0245, 0.0328, 0.0568, 0.0520, 0.0816, 0.0913, 0.1291, 0.1195, 0.1291]),\n"," 208: tensor([0.0118, 0.0196, 0.0296, 0.0205, 0.0408, 0.0430, 0.0550, 0.0488, 0.0745,\n","         0.0506, 0.0577, 0.0645, 0.0645, 0.0816, 0.0645, 0.0745, 0.0645, 0.0609,\n","         0.0690, 0.0645, 0.0816, 0.0609, 0.0745, 0.0690, 0.0745, 0.0816, 0.0816,\n","         0.0816, 0.0816]),\n"," 209: tensor([0.0106, 0.0139, 0.0226, 0.0236, 0.0307, 0.0334, 0.0334, 0.0357, 0.0334,\n","         0.0299, 0.0371, 0.0334, 0.0445, 0.0472, 0.0423, 0.0472, 0.0445, 0.0505,\n","         0.0423, 0.0445, 0.0403, 0.0546, 0.0423, 0.0445, 0.0505, 0.0423, 0.0472,\n","         0.0546, 0.0505, 0.0505, 0.0472, 0.0472, 0.0598, 0.0472, 0.0546, 0.0472,\n","         0.0598, 0.0546, 0.0598, 0.0423, 0.0546, 0.0598, 0.0505, 0.0546, 0.0598,\n","         0.0598, 0.0598, 0.0598, 0.0598, 0.0598, 0.0598, 0.0598, 0.0598, 0.0598,\n","         0.0598]),\n"," 210: tensor([0.0271, 0.0657, 0.0552, 0.0707, 0.0635, 0.1118, 0.0981]),\n"," 211: tensor([0.0363, 0.0229, 0.0615, 0.0680, 0.1443, 0.1336, 0.1443]),\n"," 212: tensor([0.0150, 0.0170, 0.0215, 0.0336, 0.0400, 0.0392, 0.0358, 0.0566, 0.0490,\n","         0.0620, 0.0654, 0.0620, 0.0620, 0.0591, 0.0877, 0.0741, 0.0620, 0.0801,\n","         0.0741, 0.0801, 0.0801, 0.0877, 0.0741, 0.0877, 0.0877]),\n"," 213: tensor([0.0268, 0.0503, 0.0518, 0.0772, 0.0722, 0.0833, 0.1091, 0.1179, 0.1091,\n","         0.1291, 0.1291]),\n"," 214: tensor([0.0315, 0.0373, 0.0365, 0.0490, 0.0625, 0.0510, 0.0533, 0.1021, 0.0754,\n","         0.0833, 0.0945, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 215: tensor([0.0246, 0.0321, 0.0419, 0.0513, 0.0412, 0.0501, 0.0811, 0.0937, 0.0692,\n","         0.0765, 0.0662, 0.0765, 0.0937, 0.0765, 0.0867, 0.1026, 0.1026, 0.1026]),\n"," 216: tensor([0.0306, 0.0359, 0.0605, 0.0374, 0.0563, 0.0476, 0.0825, 0.0690, 0.0825,\n","         0.0605, 0.0727, 0.0658, 0.0825, 0.0891, 0.0825, 0.0891, 0.0772, 0.0976,\n","         0.0891, 0.0976]),\n"," 217: tensor([0.0417, 0.0367, 0.0510, 0.0400, 0.0615, 0.0408, 0.0445, 0.0400, 0.0680,\n","         0.0481, 0.0566, 0.0722, 0.0722, 0.0645, 0.0772, 0.0913, 0.0772, 0.0833,\n","         0.0772, 0.0833, 0.0833, 0.0913, 0.0913]),\n"," 218: tensor([0.0136, 0.0259, 0.0290, 0.0294, 0.0404, 0.0572, 0.0429, 0.0476, 0.0443,\n","         0.0416, 0.0572, 0.0429, 0.0458, 0.0572, 0.0606, 0.0700, 0.0700, 0.0572,\n","         0.0700, 0.0606, 0.0648, 0.0700, 0.0606, 0.0767, 0.0767, 0.0767, 0.0767,\n","         0.0700, 0.0700, 0.0767, 0.0767, 0.0767, 0.0767]),\n"," 219: tensor([0.0240, 0.0422, 0.0560, 0.0836, 0.0836, 0.1005, 0.1140, 0.1348, 0.1348,\n","         0.1348]),\n"," 220: tensor([0.0125, 0.0224, 0.0396, 0.0305, 0.0657, 0.0619, 0.0758, 0.0830, 0.0587,\n","         0.0657, 0.0619, 0.0619, 0.0830, 0.0702, 0.0560, 0.0702, 0.0657, 0.0702,\n","         0.0830, 0.0830, 0.0830, 0.0657, 0.0702, 0.0830, 0.0758, 0.0830, 0.0830,\n","         0.0830]),\n"," 221: tensor([0.0508, 0.0471, 0.0481, 0.0654, 0.1111, 0.1260, 0.1260, 0.1179]),\n"," 222: tensor([0.0435, 0.0365, 0.0574, 0.0442, 0.0423, 0.0791, 0.0546, 0.0791, 0.0833,\n","         0.0754, 0.0791, 0.0884, 0.1118, 0.1118, 0.1118]),\n"," 223: tensor([0.0394, 0.0320, 0.0577, 0.0328, 0.0471, 0.0816, 0.0645, 0.0976, 0.0816,\n","         0.0976, 0.0976, 0.1155, 0.1155, 0.1155]),\n"," 224: tensor([0.0269, 0.0396, 0.0377, 0.0426, 0.0674, 0.0503, 0.0643, 0.0643, 0.0711,\n","         0.0806, 0.0674, 0.0870, 0.0711, 0.0711, 0.0643, 0.0806, 0.0870, 0.0953,\n","         0.0870, 0.0953, 0.0870]),\n"," 225: tensor([0.0265, 0.0203, 0.0385, 0.0392, 0.0338, 0.0707, 0.0632, 0.0816, 0.0707,\n","         0.0894, 0.0632, 0.0894, 0.0667, 0.0667, 0.0816, 0.0816, 0.0894, 0.0667,\n","         0.0894, 0.0894, 0.0816, 0.0894, 0.0816, 0.0894]),\n"," 226: tensor([0.0321, 0.0331, 0.0342, 0.0307, 0.0725, 0.0662, 0.0692, 0.0574, 0.0613,\n","         0.0937, 0.0662, 0.1026, 0.1026, 0.0867, 0.1026, 0.1026, 0.1026, 0.1026]),\n"," 227: tensor([0.0143, 0.0175, 0.0267, 0.0309, 0.0398, 0.0398, 0.0598, 0.0469, 0.0345,\n","         0.0436, 0.0331, 0.0398, 0.0563, 0.0488, 0.0563, 0.0690, 0.0488, 0.0488,\n","         0.0639, 0.0563, 0.0756, 0.0598, 0.0598, 0.0756, 0.0535, 0.0690, 0.0756,\n","         0.0756, 0.0756, 0.0690, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 228: tensor([0.0233, 0.0426, 0.0591, 0.0615, 0.1140, 0.1005, 0.0870, 0.1005, 0.1231,\n","         0.1231]),\n"," 229: tensor([0.0240, 0.0224, 0.0221, 0.0577, 0.0745, 0.0550, 0.0913, 0.0609, 0.0577,\n","         0.1054, 0.0716, 0.1054, 0.0861, 0.1155]),\n"," 230: tensor([0.0271, 0.0350, 0.0310, 0.0354, 0.0449, 0.0945, 0.1021, 0.0945, 0.1021,\n","         0.0884, 0.0945, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 231: tensor([0.0243, 0.0284, 0.0447, 0.0408, 0.0395, 0.0674, 0.0913, 0.0707, 0.0542,\n","         0.0791, 0.0845, 0.0791, 0.1000, 0.1000, 0.0845, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 232: tensor([0.0328, 0.0312, 0.0449, 0.0334, 0.0533, 0.0481, 0.0791, 0.1118, 0.1118,\n","         0.0945, 0.1021, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 233: tensor([0.0204, 0.0359, 0.0680, 0.0471, 0.0503, 0.0556, 0.0891, 0.0711, 0.0962,\n","         0.1054, 0.0891, 0.0962, 0.1054, 0.1054, 0.1054, 0.1054, 0.0962]),\n"," 234: tensor([0.0148, 0.0178, 0.0350, 0.0442, 0.0765, 0.0592, 0.0937, 0.0662, 0.0867,\n","         0.0765, 0.1026, 0.0937, 0.0811, 0.1026, 0.0937, 0.1026, 0.1026, 0.1026]),\n"," 235: tensor([0.0121, 0.0291, 0.0346, 0.0375, 0.0328, 0.0383, 0.0423, 0.0449, 0.0346,\n","         0.0392, 0.0518, 0.0635, 0.0679, 0.0498, 0.0542, 0.0480, 0.0733, 0.0803,\n","         0.0423, 0.0542, 0.0518, 0.0568, 0.0733, 0.0679, 0.0803, 0.0803, 0.0803,\n","         0.0733, 0.0803, 0.0803]),\n"," 236: tensor([0.0221, 0.0250, 0.0224, 0.0536, 0.0645, 0.1291, 0.1021, 0.1021, 0.1291,\n","         0.1291, 0.1179]),\n"," 237: tensor([0.0208, 0.0362, 0.0410, 0.0495, 0.0542, 0.0808, 0.1085, 0.0808, 0.0731,\n","         0.0767, 0.1085, 0.1085, 0.1085, 0.1085, 0.0857, 0.1085]),\n"," 238: tensor([0.0217, 0.0194, 0.0281, 0.0754, 0.0722, 0.0693, 0.0722, 0.0945, 0.0884,\n","         0.0754, 0.0833, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 239: tensor([0.0212, 0.0259, 0.0510, 0.0390, 0.0574, 0.0559, 0.0668, 0.0884, 0.0884,\n","         0.0791, 0.1118, 0.0884, 0.0833, 0.1118, 0.1118]),\n"," 240: tensor([0.0273, 0.0340, 0.0506, 0.0450, 0.0572, 0.0767, 0.0917, 0.0700, 0.0572,\n","         0.0808, 0.0673, 0.0857, 0.0917, 0.0990, 0.1085, 0.1085]),\n"," 241: tensor([0.0180, 0.0354, 0.0458, 0.0613, 0.1010, 0.1091, 0.1195, 0.1010, 0.1195,\n","         0.1195, 0.1195, 0.1195, 0.1195]),\n"," 242: tensor([0.0458, 0.0546, 0.0339, 0.0514, 0.0630, 0.0630, 0.0714, 0.1010, 0.1195,\n","         0.1010, 0.1091, 0.1091, 0.1195]),\n"," 243: tensor([0.0248, 0.0147, 0.0472, 0.0378, 0.0630, 0.0386, 0.0505, 0.0570, 0.0546,\n","         0.0546, 0.0630, 0.0488, 0.0772, 0.0630, 0.0714, 0.0772, 0.0668, 0.0845,\n","         0.0668, 0.0630, 0.0714, 0.0845, 0.0845, 0.0845, 0.0714, 0.0845, 0.0845]),\n"," 244: tensor([0.0203, 0.0228, 0.0239, 0.0338, 0.0388, 0.0452, 0.0398, 0.0410, 0.0535,\n","         0.0452, 0.0690, 0.0510, 0.0756, 0.0488, 0.0639, 0.0639, 0.0535, 0.0563,\n","         0.0598, 0.0690, 0.0598, 0.0756, 0.0690, 0.0756, 0.0690, 0.0756, 0.0690,\n","         0.0690, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 245: tensor([0.0236, 0.0183, 0.0514, 0.0398, 0.0745, 0.0589, 0.0630, 0.0680, 0.0833,\n","         0.0962, 0.0891, 0.0891, 0.0833, 0.1054, 0.0891, 0.1054, 0.1054]),\n"," 246: tensor([0.0243, 0.0178, 0.0500, 0.0542, 0.0513, 0.0707, 0.0577, 0.0745, 0.0845,\n","         0.1000, 0.0745, 0.1000, 0.0913, 0.1000, 0.0913, 0.0913, 0.1000, 0.0913,\n","         0.1000]),\n"," 247: tensor([0.0417, 0.0548, 0.0745, 0.0642, 0.1111, 0.0808, 0.1111, 0.1361]),\n"," 248: tensor([0.0144, 0.0213, 0.0216, 0.0360, 0.0674, 0.0591, 0.0503, 0.0754, 0.0711,\n","         0.0674, 0.0711, 0.0806, 0.0754, 0.0953, 0.0870, 0.0953, 0.0754, 0.0870,\n","         0.0953, 0.0953, 0.0953]),\n"," 249: tensor([0.0335, 0.0426, 0.0388, 0.0556, 0.0662, 0.0592, 0.0937, 0.0811, 0.0867,\n","         0.0765, 0.0867, 0.0811, 0.0937, 0.0937, 0.0867, 0.0937, 0.1026, 0.1026]),\n"," 250: tensor([0.0232, 0.0225, 0.0323, 0.0340, 0.0625, 0.0490, 0.0510, 0.0456, 0.0625,\n","         0.0472, 0.0442, 0.0490, 0.0625, 0.0510, 0.0668, 0.0722, 0.0668, 0.0722,\n","         0.0722, 0.0722, 0.0791, 0.0722, 0.0722, 0.0791, 0.0668, 0.0791, 0.0722,\n","         0.0791, 0.0668, 0.0791, 0.0791]),\n"," 251: tensor([0.0235, 0.0418, 0.0506, 0.0490, 0.0925, 0.0801, 0.0801, 0.1240, 0.1132,\n","         0.1132, 0.1240, 0.1240]),\n"," 252: tensor([0.0285, 0.0301, 0.0374, 0.0483, 0.0741, 0.0693, 0.0693, 0.0716, 0.0925,\n","         0.1048, 0.1132, 0.1240]),\n"," 253: tensor([0.0169, 0.0217, 0.0340, 0.0373, 0.0589, 0.0722, 0.0945, 0.0945, 0.1021,\n","         0.0668, 0.0884, 0.1021, 0.0945, 0.1021, 0.1021]),\n"," 254: tensor([0.0203, 0.0385, 0.0336, 0.0566, 0.0654, 0.0620, 0.0476, 0.0544, 0.0450,\n","         0.0693, 0.0418, 0.0693, 0.0591, 0.0566, 0.0654, 0.0693, 0.0654, 0.0801,\n","         0.0693, 0.0693, 0.0877, 0.0877, 0.0877, 0.0620, 0.0741]),\n"," 255: tensor([0.0173, 0.0155, 0.0359, 0.0392, 0.0436, 0.0603, 0.0816, 0.0756, 0.0756,\n","         0.0555, 0.0555, 0.0632, 0.0816, 0.0707, 0.0632, 0.0632, 0.0816, 0.0816,\n","         0.0894, 0.0894, 0.0894, 0.0816, 0.0894, 0.0894]),\n"," 256: tensor([0.0176, 0.0213, 0.0258, 0.0388, 0.0937, 0.0811, 0.0811, 0.0592, 0.0867,\n","         0.0725, 0.1026, 0.0765, 0.0765, 0.0937, 0.0937, 0.0867, 0.0937, 0.1026]),\n"," 257: tensor([0.0152, 0.0387, 0.0373, 0.0462, 0.0527, 0.0891, 0.0745, 0.0962, 0.0962,\n","         0.0891, 0.0962, 0.1054, 0.0745, 0.1054, 0.0786, 0.0891, 0.1054]),\n"," 258: tensor([0.0174, 0.0162, 0.0254, 0.0294, 0.0483, 0.0410, 0.0525, 0.0525, 0.0525,\n","         0.0615, 0.0483, 0.0711, 0.0550, 0.0525, 0.0503, 0.0550, 0.0550, 0.0580,\n","         0.0658, 0.0449, 0.0580, 0.0778, 0.0711, 0.0778, 0.0778, 0.0778, 0.0615,\n","         0.0778, 0.0658, 0.0711, 0.0711, 0.0778]),\n"," 259: tensor([0.0324, 0.0423, 0.0430, 0.0404, 0.0430, 0.0745, 0.0891, 0.0891, 0.0711,\n","         0.0962, 0.0609, 0.0962, 0.1054, 0.0891, 0.1054, 0.0891, 0.1054]),\n"," 260: tensor([0.0148, 0.0340, 0.0217, 0.0467, 0.0430, 0.0430, 0.0642, 0.0680, 0.0609,\n","         0.0680, 0.0609, 0.0556, 0.0861, 0.0609, 0.0727, 0.0580, 0.0680, 0.0680,\n","         0.0861, 0.0727, 0.0786, 0.0861, 0.0786, 0.0727, 0.0861, 0.0861]),\n"," 261: tensor([0.0148, 0.0312, 0.0412, 0.0556, 0.0541, 0.0765, 0.0636, 0.0811, 0.0937,\n","         0.0867, 0.0937, 0.0765, 0.0765, 0.0867, 0.0937, 0.0765, 0.1026, 0.1026]),\n"," 262: tensor([0.0186, 0.0367, 0.0304, 0.0635, 0.0464, 0.0480, 0.0436, 0.0412, 0.0359,\n","         0.0334, 0.0480, 0.0679, 0.0803, 0.0803, 0.0733, 0.0599, 0.0733, 0.0599,\n","         0.0733, 0.0679, 0.0733, 0.0568, 0.0733, 0.0733, 0.0733, 0.0803, 0.0803,\n","         0.0803, 0.0803, 0.0803]),\n"," 263: tensor([0.0311, 0.0219, 0.0379, 0.0393, 0.0445, 0.0510, 0.0445, 0.0546, 0.0722,\n","         0.0615, 0.0680, 0.0645, 0.0589, 0.0680, 0.0772, 0.0772, 0.0722, 0.0913,\n","         0.0913, 0.0772, 0.0913, 0.0913, 0.0913]),\n"," 264: tensor([0.0209, 0.0387, 0.0363, 0.0284, 0.0659, 0.0557, 0.0538, 0.0659, 0.0695,\n","         0.0629, 0.0851, 0.0695, 0.0851, 0.0695, 0.0851, 0.0933, 0.0788, 0.0851,\n","         0.0933, 0.0933, 0.0851, 0.0933]),\n"," 265: tensor([0.0248, 0.0278, 0.0471, 0.0328, 0.0408, 0.0381, 0.0443, 0.0430, 0.0609,\n","         0.0609, 0.0488, 0.0609, 0.0816, 0.0816, 0.0690, 0.0745, 0.0745, 0.0816,\n","         0.0745, 0.0745, 0.0745, 0.0690, 0.0816, 0.0816, 0.0745, 0.0745, 0.0745,\n","         0.0816, 0.0816]),\n"," 266: tensor([0.0121, 0.0152, 0.0232, 0.0449, 0.0599, 0.0352, 0.0449, 0.0498, 0.0449,\n","         0.0679, 0.0635, 0.0599, 0.0679, 0.0733, 0.0635, 0.0568, 0.0599, 0.0464,\n","         0.0599, 0.0803, 0.0803, 0.0635, 0.0803, 0.0733, 0.0679, 0.0803, 0.0733,\n","         0.0803, 0.0803, 0.0803]),\n"," 267: tensor([0.0289, 0.0393, 0.0342, 0.0442, 0.0574, 0.0867, 0.0765, 0.0692, 0.0937,\n","         0.0811, 0.0937, 0.0867, 0.0937, 0.1026, 0.0867, 0.0937, 0.0937, 0.1026]),\n"," 268: tensor([0.0301, 0.0227, 0.0535, 0.0452, 0.0741, 0.0668, 0.0845, 0.0741, 0.0845,\n","         0.1010, 0.0945, 0.1010, 0.0945]),\n"," 269: tensor([0.0367, 0.0476, 0.0544, 0.0534, 0.0877, 0.1048, 0.0981, 0.1048, 0.1048,\n","         0.0925, 0.1048, 0.1132]),\n"," 270: tensor([0.0232, 0.0207, 0.0337, 0.0434, 0.0630, 0.0668, 0.0772, 0.0945, 0.0741,\n","         0.0945, 0.1091, 0.1091, 0.1195]),\n"," 271: tensor([0.0674, 0.0471, 0.0477, 0.0550, 0.1231, 0.1066, 0.1066, 0.1231, 0.1140,\n","         0.1231]),\n"," 272: tensor([0.0157, 0.0278, 0.0215, 0.0423, 0.0535, 0.0452, 0.0690, 0.0369, 0.0690,\n","         0.0398, 0.0639, 0.0423, 0.0535, 0.0410, 0.0469, 0.0563, 0.0563, 0.0563,\n","         0.0639, 0.0598, 0.0598, 0.0639, 0.0756, 0.0690, 0.0690, 0.0690, 0.0690,\n","         0.0756, 0.0690, 0.0756, 0.0756, 0.0690, 0.0756, 0.0756]),\n"," 273: tensor([0.0174, 0.0330, 0.0500, 0.0439, 0.0447, 0.0513, 0.0598, 0.0577, 0.0645,\n","         0.0488, 0.0745, 0.1000, 0.0913, 0.0913, 0.0791, 0.0791, 0.0913, 0.0913,\n","         0.1000]),\n"," 274: tensor([0.0283, 0.0467, 0.0642, 0.0808, 0.1005, 0.1111, 0.1260, 0.1491]),\n"," 275: tensor([0.0290, 0.0342, 0.0471, 0.0464, 0.0816, 0.0913, 0.0913, 0.1155, 0.0913,\n","         0.1054, 0.1054, 0.1054, 0.1054, 0.1155]),\n"," 276: tensor([0.0287, 0.0271, 0.0546, 0.0480, 0.1010, 0.1010, 0.1091, 0.0945, 0.1091,\n","         0.0806, 0.1091, 0.1091, 0.1195]),\n"," 277: tensor([0.0174, 0.0312, 0.0263, 0.0363, 0.0331, 0.0363, 0.0406, 0.0574, 0.0434,\n","         0.0468, 0.0406, 0.0372, 0.0372, 0.0450, 0.0489, 0.0450, 0.0662, 0.0662,\n","         0.0613, 0.0541, 0.0346, 0.0613, 0.0513, 0.0662, 0.0513, 0.0513, 0.0613,\n","         0.0513, 0.0662, 0.0662, 0.0613, 0.0725, 0.0662, 0.0662, 0.0725, 0.0725,\n","         0.0725]),\n"," 278: tensor([0.0550, 0.0271, 0.0725, 0.0791, 0.0745, 0.1118, 0.1195, 0.1414, 0.1118]),\n"," 279: tensor([0.0256, 0.0406, 0.0429, 0.0668, 0.0945, 0.0884, 0.0884, 0.0945, 0.1118,\n","         0.0945, 0.1118, 0.1118, 0.0945, 0.1118, 0.1021]),\n"," 280: tensor([0.0155, 0.0447, 0.0365, 0.0447, 0.0535, 0.0756, 0.0667, 0.0535, 0.0603,\n","         0.0756, 0.0894, 0.0500, 0.0894, 0.0816, 0.0816, 0.0816, 0.0756, 0.0707,\n","         0.0894, 0.0894, 0.0816, 0.0894, 0.0894, 0.0894]),\n"," 281: tensor([0.0258, 0.0280, 0.0377, 0.0419, 0.0811, 0.0867, 0.0765, 0.0937, 0.0811,\n","         0.0937, 0.0867, 0.1026, 0.1026, 0.0867, 0.0867, 0.1026, 0.1026, 0.1026]),\n"," 282: tensor([0.0199, 0.0501, 0.0574, 0.0513, 0.0613, 0.0636, 0.0725, 0.0937, 0.0662,\n","         0.0692, 0.0937, 0.0937, 0.1026, 0.0867, 0.0867, 0.0937, 0.0867, 0.1026]),\n"," 283: tensor([0.0307, 0.0398, 0.0449, 0.0598, 0.1336, 0.1581, 0.1581]),\n"," 284: tensor([0.0183, 0.0377, 0.0406, 0.0513, 0.0636, 0.1026, 0.0765, 0.0662, 0.0937,\n","         0.0692, 0.1026, 0.0937, 0.1026, 0.0937, 0.0867, 0.1026, 0.1026, 0.1026]),\n"," 285: tensor([0.0267, 0.0386, 0.0472, 0.0488, 0.0806, 0.0806, 0.1010, 0.0772, 0.0891,\n","         0.1010, 0.1010, 0.1091, 0.1195]),\n"," 286: tensor([0.0374, 0.0417, 0.0514, 0.0488, 0.0945, 0.0845, 0.0845, 0.0945, 0.0806,\n","         0.1195, 0.1091, 0.1195, 0.1195]),\n"," 287: tensor([0.0330, 0.0239, 0.0340, 0.0680, 0.0589, 0.0514, 0.0711, 0.0589, 0.0481,\n","         0.0572, 0.0833, 0.0745, 0.0891, 0.0745, 0.0891, 0.0891, 0.0962]),\n"," 288: tensor([0.0368, 0.0333, 0.0326, 0.0542, 0.1000, 0.0845, 0.0745, 0.0674, 0.0745,\n","         0.0845, 0.1000, 0.0913, 0.0845, 0.0845, 0.1000, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 289: tensor([0.0229, 0.0333, 0.0378, 0.0645, 0.0488, 0.0456, 0.0707, 0.0913, 0.1000,\n","         0.0559, 0.1000, 0.0791, 0.1000, 0.0845, 0.0845, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 290: tensor([0.0225, 0.0383, 0.0449, 0.0412, 0.0359, 0.0402, 0.0635, 0.0423, 0.0542,\n","         0.0518, 0.0599, 0.0542, 0.0480, 0.0599, 0.0679, 0.0635, 0.0568, 0.0733,\n","         0.0803, 0.0599, 0.0599, 0.0733, 0.0679, 0.0803, 0.0733, 0.0679, 0.0803,\n","         0.0803, 0.0803, 0.0803]),\n"," 291: tensor([0.0187, 0.0488, 0.0536, 0.0745, 0.0870, 0.0962, 0.1291, 0.1291, 0.1091,\n","         0.1291, 0.1291]),\n"," 292: tensor([0.0268, 0.0667, 0.0436, 0.0471, 0.0609, 0.0913, 0.0976, 0.0816, 0.0778,\n","         0.0816, 0.1155, 0.1155, 0.1155, 0.1155]),\n"," 293: tensor([0.0274, 0.0574, 0.0625, 0.0657, 0.1443, 0.1336, 0.1118]),\n"," 294: tensor([0.0365, 0.0408, 0.0358, 0.0430, 0.0471, 0.0398, 0.0488, 0.0488, 0.0430,\n","         0.0358, 0.0690, 0.0645, 0.0398, 0.0645, 0.0506, 0.0690, 0.0506, 0.0550,\n","         0.0609, 0.0690, 0.0690, 0.0745, 0.0816, 0.0745, 0.0816, 0.0745, 0.0816,\n","         0.0816, 0.0816]),\n"," 295: tensor([0.0630, 0.0348, 0.0248, 0.0325, 0.0962, 0.0962, 0.1021, 0.1091, 0.1179,\n","         0.1291, 0.0962]),\n"," 296: tensor([0.0542, 0.0513, 0.0791, 0.0674, 0.0953, 0.1000, 0.1414, 0.1414, 0.1414]),\n"," 297: tensor([0.0269, 0.0408, 0.0284, 0.0408, 0.0423, 0.0845, 0.0845, 0.0745, 0.0707,\n","         0.0674, 0.0707, 0.0845, 0.1000, 0.1000, 0.1000, 0.0845, 0.0845, 0.0845,\n","         0.1000]),\n"," 298: tensor([0.0520, 0.0587, 0.0725, 0.0674, 0.1054, 0.1291, 0.1414, 0.1195, 0.1414]),\n"," 299: tensor([0.0287, 0.0290, 0.0503, 0.0383, 0.0674, 0.0550, 0.0806, 0.0711, 0.0953,\n","         0.0711, 0.0870, 0.0674, 0.0643, 0.0711, 0.0953, 0.0953, 0.0953, 0.0953,\n","         0.0953, 0.0953, 0.0953]),\n"," 300: tensor([0.0128, 0.0133, 0.0210, 0.0290, 0.0630, 0.0340, 0.0348, 0.0481, 0.0589,\n","         0.0462, 0.0527, 0.0527, 0.0503, 0.0556, 0.0745, 0.0745, 0.0630, 0.0680,\n","         0.0680, 0.0680, 0.0630, 0.0680, 0.0745, 0.0527, 0.0589, 0.0680, 0.0745,\n","         0.0680, 0.0680, 0.0745, 0.0745, 0.0745, 0.0745, 0.0745, 0.0745]),\n"," 301: tensor([0.0365, 0.0354, 0.0442, 0.0589, 0.0490, 0.0589, 0.0833, 0.0833, 0.0945,\n","         0.1118, 0.1021, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 302: tensor([0.0199, 0.0435, 0.0449, 0.0574, 0.0791, 0.0884, 0.0754, 0.0546, 0.0625,\n","         0.0791, 0.1118, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 303: tensor([0.0152, 0.0253, 0.0239, 0.0423, 0.0514, 0.0786, 0.0745, 0.0745, 0.0711,\n","         0.0711, 0.0962, 0.0962, 0.1054, 0.0891, 0.0962, 0.1054, 0.1054]),\n"," 304: tensor([0.0359, 0.0321, 0.0503, 0.0745, 0.0630, 0.0786, 0.0891, 0.0786, 0.0745,\n","         0.0786, 0.0786, 0.0962, 0.1054, 0.0891, 0.0962, 0.0962, 0.1054]),\n"," 305: tensor([0.0454, 0.0514, 0.0572, 0.0654, 0.0808, 0.1111, 0.0861, 0.1361]),\n"," 306: tensor([0.0157, 0.0206, 0.0193, 0.0476, 0.0556, 0.0731, 0.0917, 0.0990, 0.0556,\n","         0.1085, 0.0767, 0.0990, 0.1085, 0.0990, 0.1085, 0.0990]),\n"," 307: tensor([0.0217, 0.0464, 0.0411, 0.0481, 0.0693, 0.0668, 0.1021, 0.0722, 0.0722,\n","         0.1021, 0.0833, 0.1021, 0.0945, 0.1118, 0.1118]),\n"," 308: tensor([0.0424, 0.0471, 0.0563, 0.0563, 0.0778, 0.0913, 0.0861, 0.0976, 0.0913,\n","         0.0976, 0.0976, 0.0861, 0.1155, 0.1155]),\n"," 309: tensor([0.0178, 0.0313, 0.0383, 0.0368, 0.0598, 0.0598, 0.0527, 0.0791, 0.0791,\n","         0.0674, 0.0745, 0.0745, 0.1000, 0.0791, 0.1000, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 310: tensor([0.0280, 0.0203, 0.0365, 0.0359, 0.0632, 0.0385, 0.0485, 0.0555, 0.0707,\n","         0.0816, 0.0632, 0.0756, 0.0756, 0.0667, 0.0577, 0.0603, 0.0632, 0.0894,\n","         0.0756, 0.0756, 0.0667, 0.0756, 0.0894, 0.0894]),\n"," 311: tensor([0.0242, 0.0265, 0.0330, 0.0364, 0.0680, 0.0891, 0.0654, 0.0891, 0.0833,\n","         0.1054, 0.1054, 0.0962, 0.1054, 0.1054, 0.1054, 0.1054, 0.1054]),\n"," 312: tensor([0.0164, 0.0260, 0.0410, 0.0533, 0.0465, 0.0445, 0.0615, 0.0870, 0.0754,\n","         0.0517, 0.0643, 0.0674, 0.0806, 0.0953, 0.0674, 0.0806, 0.0806, 0.0953,\n","         0.0806, 0.0806, 0.0953]),\n"," 313: tensor([0.0173, 0.0301, 0.0452, 0.0480, 0.0505, 0.0845, 0.1195, 0.0891, 0.1010,\n","         0.1195, 0.1195, 0.1195, 0.1195]),\n"," 314: tensor([0.0162, 0.0464, 0.0395, 0.0449, 0.0693, 0.1021, 0.0945, 0.0791, 0.0884,\n","         0.0884, 0.1118, 0.1021, 0.0945, 0.1118, 0.1118]),\n"," 315: tensor([0.0343, 0.0443, 0.0520, 0.0725, 0.1414, 0.1118, 0.1414, 0.1291, 0.1195]),\n"," 316: tensor([0.0367, 0.0481, 0.0398, 0.0510, 0.1336, 0.0857, 0.1443]),\n"," 317: tensor([0.0290, 0.0364, 0.0386, 0.0496, 0.0583, 0.1010, 0.1010, 0.1010, 0.1010,\n","         0.1195, 0.1091, 0.1195, 0.1195]),\n"," 318: tensor([0.0488, 0.0500, 0.0430, 0.0402, 0.0745, 0.0745, 0.0791, 0.0913, 0.0791,\n","         0.0913, 0.0845, 0.0845, 0.0845, 0.0791, 0.0913, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 319: tensor([0.0183, 0.0284, 0.0295, 0.0589, 0.0833, 0.0745, 0.0556, 0.0833, 0.0654,\n","         0.0786, 0.0833, 0.0891, 0.0833, 0.0833, 0.0962, 0.1054, 0.1054]),\n"," 320: tensor([0.0307, 0.0464, 0.0635, 0.0559, 0.1066, 0.1581, 0.1581]),\n"," 321: tensor([0.0356, 0.0443, 0.0392, 0.0791, 0.0877, 0.1291, 0.1291, 0.1414, 0.1291]),\n"," 322: tensor([0.0173, 0.0378, 0.0613, 0.0465, 0.0772, 0.0668, 0.0806, 0.1091, 0.0891,\n","         0.0945, 0.1195, 0.0945, 0.1195]),\n"," 323: tensor([0.0174, 0.0341, 0.0436, 0.0514, 0.0465, 0.0690, 0.0727, 0.0891, 0.0727,\n","         0.0825, 0.0690, 0.0630, 0.0891, 0.0891, 0.0690, 0.0891, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 324: tensor([0.0382, 0.0503, 0.0662, 0.0488, 0.0913, 0.0615, 0.1179, 0.0913, 0.1091,\n","         0.1179, 0.1291]),\n"," 325: tensor([0.0389, 0.0542, 0.0466, 0.0430, 0.0620, 0.0674, 0.0577, 0.0542, 0.0645,\n","         0.0620, 0.0707, 0.0745, 0.0845, 0.0913, 0.0791, 0.0913, 0.0845, 0.0913,\n","         0.1000]),\n"," 326: tensor([0.0235, 0.0288, 0.0374, 0.0312, 0.0925, 0.0925, 0.1048, 0.1048, 0.1132,\n","         0.1048, 0.1048, 0.1240]),\n"," 327: tensor([0.0383, 0.0396, 0.0533, 0.0465, 0.0533, 0.0503, 0.0517, 0.0806, 0.0570,\n","         0.0517, 0.0711, 0.0711, 0.0615, 0.0615, 0.0806, 0.0806, 0.0674, 0.0953,\n","         0.0870, 0.0806, 0.0953]),\n"," 328: tensor([0.0333, 0.0642, 0.0786, 0.0925, 0.1054, 0.1361, 0.1491, 0.1361]),\n"," 329: tensor([0.0183, 0.0295, 0.0572, 0.0541, 0.0786, 0.0556, 0.0711, 0.0589, 0.0891,\n","         0.1054, 0.0711, 0.0711, 0.1054, 0.0891, 0.1054, 0.0891, 0.1054]),\n"," 330: tensor([0.0324, 0.0639, 0.0702, 0.0630, 0.1048, 0.1543]),\n"," 331: tensor([0.0238, 0.0398, 0.0811, 0.0625, 0.1021, 0.1336, 0.1250]),\n"," 332: tensor([0.0255, 0.0230, 0.0331, 0.0340, 0.0833, 0.0468, 0.0680, 0.0680, 0.0680,\n","         0.0680, 0.0833, 0.0680, 0.0722, 0.0772, 0.0913, 0.0833, 0.0772, 0.0833,\n","         0.0913, 0.0833, 0.0913, 0.0913, 0.0913]),\n"," 333: tensor([0.0293, 0.0426, 0.0397, 0.0393, 0.0602, 0.0833, 0.1021, 0.1179, 0.1291,\n","         0.1291, 0.1179]),\n"," 334: tensor([0.0393, 0.0503, 0.0662, 0.0772, 0.0700, 0.0801, 0.1291, 0.1021, 0.1291,\n","         0.1291, 0.1291]),\n"," 335: tensor([0.0377, 0.0525, 0.0580, 0.0806, 0.0870, 0.0953, 0.0909, 0.1348, 0.1348,\n","         0.1348]),\n"," 336: tensor([0.0609, 0.0667, 0.0599, 0.0786, 0.1491, 0.1111, 0.1361, 0.1361]),\n"," 337: tensor([0.0229, 0.0148, 0.0406, 0.0442, 0.0574, 0.0811, 0.0662, 0.0867, 0.0662,\n","         0.1026, 0.0937, 0.1026, 0.0765, 0.0636, 0.0937, 0.1026, 0.1026, 0.1026]),\n"," 338: tensor([0.0364, 0.0452, 0.0524, 0.0630, 0.0741, 0.0891, 0.0945, 0.0945, 0.0891,\n","         0.1195, 0.1195, 0.1195, 0.1195]),\n"," 339: tensor([0.0193, 0.0312, 0.0533, 0.0574, 0.0546, 0.0754, 0.0625, 0.0884, 0.0945,\n","         0.1118, 0.0945, 0.0833, 0.1021, 0.1021, 0.1118]),\n"," 340: tensor([0.0339, 0.0221, 0.0443, 0.0538, 0.0816, 0.0816, 0.0745, 0.0913, 0.0778,\n","         0.0913, 0.1054, 0.1155, 0.1155, 0.1155]),\n"," 341: tensor([0.0258, 0.0321, 0.0309, 0.0468, 0.0434, 0.0636, 0.0556, 0.0765, 0.1026,\n","         0.0692, 0.0867, 0.0725, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026]),\n"," 342: tensor([0.0398, 0.0559, 0.0745, 0.0535, 0.0659, 0.1195, 0.0845, 0.1118, 0.1414]),\n"," 343: tensor([0.0271, 0.0468, 0.0635, 0.0833, 0.0981, 0.1581, 0.1581]),\n"," 344: tensor([0.0443, 0.0645, 0.0632, 0.0913, 0.1291, 0.1414, 0.1291, 0.1195, 0.1118]),\n"," 345: tensor([0.0281, 0.0217, 0.0328, 0.0574, 0.0625, 0.0945, 0.0668, 0.1021, 0.0945,\n","         0.0791, 0.1021, 0.0945, 0.1021, 0.1118, 0.1118]),\n"," 346: tensor([0.0313, 0.0379, 0.0833, 0.1231, 0.0913]),\n"," 347: tensor([0.0225, 0.0891, 0.0527, 0.0527, 0.1111, 0.1054, 0.1491, 0.1491]),\n"," 348: tensor([0.0362, 0.0283, 0.0521, 0.0481, 0.0786, 0.1361, 0.1491, 0.1361]),\n"," 349: tensor([0.0203, 0.0233, 0.0234, 0.0603, 0.1005, 0.0909, 0.0870, 0.1005, 0.1231,\n","         0.1005]),\n"," 350: tensor([0.0167, 0.0322, 0.0445, 0.0514, 0.0605, 0.0690, 0.0428, 0.0772, 0.0825,\n","         0.0825, 0.0690, 0.0727, 0.0727, 0.0976, 0.0727, 0.0976, 0.0825, 0.0891,\n","         0.0891, 0.0976]),\n"," 351: tensor([0.0306, 0.0420, 0.0465, 0.0380, 0.0501, 0.0690, 0.0583, 0.0727, 0.0605,\n","         0.0825, 0.0825, 0.0772, 0.0690, 0.0976, 0.0891, 0.0825, 0.0772, 0.0976,\n","         0.0976, 0.0891]),\n"," 352: tensor([0.0114, 0.0299, 0.0309, 0.0304, 0.0352, 0.0535, 0.0378, 0.0452, 0.0398,\n","         0.0469, 0.0639, 0.0452, 0.0756, 0.0510, 0.0535, 0.0690, 0.0690, 0.0639,\n","         0.0563, 0.0563, 0.0690, 0.0639, 0.0756, 0.0598, 0.0756, 0.0756, 0.0690,\n","         0.0756, 0.0690, 0.0756, 0.0756, 0.0756, 0.0756, 0.0756]),\n"," 353: tensor([0.0455, 0.0546, 0.0436, 0.0465, 0.0630, 0.0658, 0.0690, 0.0727, 0.0690,\n","         0.0891, 0.0727, 0.0825, 0.0891, 0.0772, 0.0825, 0.0891, 0.0976, 0.0891,\n","         0.0976, 0.0976]),\n"," 354: tensor([0.0388, 0.0490, 0.0483, 0.0605, 0.0741, 0.0981, 0.0769, 0.1132, 0.1132,\n","         0.1240, 0.1132, 0.1048]),\n"," 355: tensor([0.0192, 0.0346, 0.0290, 0.0385, 0.0420, 0.0364, 0.0680, 0.0786, 0.0786,\n","         0.0680, 0.0556, 0.0534, 0.0556, 0.0534, 0.0556, 0.0786, 0.0727, 0.0861,\n","         0.0680, 0.0861, 0.0861, 0.0861, 0.0786, 0.0861, 0.0861, 0.0861]),\n"," 356: tensor([0.0393, 0.0325, 0.0481, 0.0346, 0.0467, 0.0556, 0.0642, 0.0786, 0.0786,\n","         0.0727, 0.0642, 0.0642, 0.0727, 0.0642, 0.0861, 0.0786, 0.0727, 0.0727,\n","         0.0786, 0.0861, 0.0861, 0.0861, 0.0861, 0.0861, 0.0786, 0.0786]),\n"," 357: tensor([0.0536, 0.0510, 0.0566, 0.1021, 0.0745, 0.0662, 0.0913, 0.0870, 0.0962,\n","         0.0962, 0.1091]),\n"," 358: tensor([0.0292, 0.0344, 0.0423, 0.0398, 0.0962, 0.0589, 0.0711, 0.0962, 0.0609,\n","         0.0962, 0.0711, 0.0833, 0.0786, 0.1054, 0.1054, 0.1054, 0.1054]),\n"," 359: tensor([0.0179, 0.0381, 0.0348, 0.0659, 0.0538, 0.0557, 0.0538, 0.0695, 0.0538,\n","         0.0788, 0.0659, 0.0851, 0.0695, 0.0737, 0.0659, 0.0695, 0.0933, 0.0933,\n","         0.0788, 0.0933, 0.0933, 0.0933]),\n"," 360: tensor([0.0258, 0.0555, 0.0439, 0.0498, 0.0591, 0.0693, 0.0836, 0.0925, 0.0769,\n","         0.1132, 0.1048, 0.1240]),\n"," 361: tensor([0.0268, 0.0645, 0.0471, 0.0620, 0.0953, 0.0816, 0.1054, 0.1195, 0.1414]),\n"," 362: tensor([0.0605, 0.0388, 0.0409, 0.0352, 0.0769, 0.1132, 0.0981, 0.1048, 0.1240,\n","         0.1240, 0.1240, 0.1240]),\n"," 363: tensor([0.0265, 0.0174, 0.0471, 0.0538, 0.0690, 0.0861, 0.0913, 0.0913, 0.1155,\n","         0.1054, 0.1155, 0.1155, 0.1054, 0.1155]),\n"," 364: tensor([0.0167, 0.0141, 0.0222, 0.0420, 0.0605, 0.0658, 0.0772, 0.0772, 0.0825,\n","         0.0976, 0.0772, 0.0891, 0.0825, 0.0891, 0.0891, 0.0976, 0.0727, 0.0891,\n","         0.0976, 0.0976]),\n"," 365: tensor([0.0486, 0.0657, 0.0811, 0.0884, 0.1581, 0.1250, 0.1443]),\n"," 366: tensor([0.0125, 0.0209, 0.0144, 0.0415, 0.0426, 0.0364, 0.0619, 0.0702, 0.0587,\n","         0.0560, 0.0657, 0.0587, 0.0758, 0.0657, 0.0702, 0.0702, 0.0758, 0.0758,\n","         0.0702, 0.0702, 0.0830, 0.0657, 0.0758, 0.0830, 0.0830, 0.0830, 0.0830,\n","         0.0830]),\n"," 367: tensor([0.0195, 0.0293, 0.0527, 0.0536, 0.0722, 0.0722, 0.1091, 0.0833, 0.1021,\n","         0.1291, 0.1291]),\n"," 368: tensor([0.0306, 0.0428, 0.0398, 0.0583, 0.0583, 0.0476, 0.0727, 0.0825, 0.0825,\n","         0.0976, 0.0825, 0.0976, 0.0563, 0.0891, 0.0891, 0.0891, 0.0891, 0.0976,\n","         0.0976, 0.0976]),\n"," 369: tensor([0.0375, 0.0572, 0.0765, 0.0765, 0.1260, 0.0861, 0.1111, 0.1491]),\n"," 370: tensor([0.0496, 0.0533, 0.0658, 0.0754, 0.1005, 0.1231, 0.1348, 0.1348, 0.1348,\n","         0.1348]),\n"," 371: tensor([0.0135, 0.0162, 0.0352, 0.0445, 0.0602, 0.0659, 0.0578, 0.0578, 0.0557,\n","         0.0737, 0.0538, 0.0602, 0.0788, 0.0695, 0.0659, 0.0788, 0.0933, 0.0933,\n","         0.0851, 0.0851, 0.0851, 0.0933]),\n"," 372: tensor([0.0195, 0.0674, 0.0658, 0.0711, 0.0674, 0.1005, 0.1348, 0.1140, 0.1140,\n","         0.1066]),\n"," 373: tensor([0.0390, 0.0354, 0.0318, 0.0510, 0.0754, 0.0722, 0.0693, 0.0833, 0.0833,\n","         0.0833, 0.1021, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 374: tensor([0.0169, 0.0240, 0.0398, 0.0546, 0.0514, 0.0563, 0.0772, 0.0772, 0.0605,\n","         0.0976, 0.0891, 0.0727, 0.0690, 0.0825, 0.0976, 0.0976, 0.0891, 0.0976,\n","         0.0825, 0.0976]),\n"," 375: tensor([0.0294, 0.0430, 0.0461, 0.0659, 0.1195, 0.1291, 0.1195, 0.1414, 0.1414]),\n"," 376: tensor([0.0443, 0.0392, 0.0443, 0.0767, 0.0953, 0.1291, 0.1414, 0.1291, 0.1414]),\n"," 377: tensor([0.0370, 0.0273, 0.0340, 0.0410, 0.0917, 0.0917, 0.0857, 0.0857, 0.0917,\n","         0.0917, 0.0990, 0.0990, 0.0990, 0.1085, 0.1085, 0.1085]),\n"," 378: tensor([0.0354, 0.0450, 0.0450, 0.0443, 0.0529, 0.0808, 0.0731, 0.0917, 0.0626,\n","         0.0767, 0.0917, 0.0808, 0.0857, 0.0857, 0.1085, 0.1085]),\n"," 379: tensor([0.0243, 0.0340, 0.0362, 0.0436, 0.0731, 0.0700, 0.0990, 0.0572, 0.1085,\n","         0.0917, 0.1085, 0.0990, 0.0990, 0.0808, 0.1085, 0.1085]),\n"," 380: tensor([0.0369, 0.0501, 0.0488, 0.0529, 0.0727, 0.0690, 0.0630, 0.0727, 0.0465,\n","         0.0563, 0.0772, 0.0690, 0.0891, 0.0976, 0.0891, 0.0976, 0.0976, 0.0891,\n","         0.0976, 0.0891]),\n"," 381: tensor([0.0461, 0.0791, 0.0577, 0.0745, 0.0645, 0.1054, 0.1414, 0.1414, 0.1414]),\n"," 382: tensor([0.0363, 0.0657, 0.0657, 0.0657, 0.1118, 0.1336, 0.1581]),\n"," 383: tensor([0.0213, 0.0374, 0.0570, 0.0598, 0.0891, 0.0806, 0.1010, 0.0945, 0.0891,\n","         0.1091, 0.1195, 0.1195, 0.1195]),\n"," 384: tensor([0.0199, 0.0501, 0.0388, 0.0501, 0.1026, 0.0613, 0.0725, 0.0937, 0.0937,\n","         0.0867, 0.0811, 0.1026, 0.1026, 0.1026, 0.0937, 0.0937, 0.0937, 0.1026]),\n"," 385: tensor([0.0456, 0.0559, 0.0707, 0.0816, 0.0953, 0.1054, 0.1118, 0.1291, 0.1414]),\n"," 386: tensor([0.0350, 0.0415, 0.0758, 0.0745, 0.1826]),\n"," 387: tensor([0.0367, 0.0546, 0.0488, 0.0598, 0.0806, 0.0891, 0.1091, 0.1010, 0.1195,\n","         0.1010, 0.1010, 0.1195, 0.1195]),\n"," 388: tensor([0.0417, 0.0239, 0.0333, 0.0340, 0.0786, 0.0891, 0.0680, 0.0833, 0.1054,\n","         0.0786, 0.0630, 0.0833, 0.0833, 0.0786, 0.0962, 0.0891, 0.1054]),\n"," 389: tensor([0.0309, 0.0344, 0.0410, 0.0423, 0.0589, 0.0962, 0.0745, 0.0680, 0.0833,\n","         0.0745, 0.1054, 0.0833, 0.1054, 0.0891, 0.1054, 0.0962, 0.0962]),\n"," 390: tensor([0.0205, 0.0345, 0.0496, 0.0535, 0.0891, 0.1010, 0.0668, 0.0945, 0.1010,\n","         0.1091, 0.1010, 0.0741, 0.0945]),\n"," 391: tensor([0.0164, 0.0138, 0.0435, 0.0371, 0.0503, 0.0754, 0.0615, 0.0615, 0.0870,\n","         0.0806, 0.0870, 0.0806, 0.0953, 0.0806, 0.0953, 0.0870, 0.0806, 0.0953,\n","         0.0953, 0.0870, 0.0953]),\n"," 392: tensor([0.0496, 0.0414, 0.0542, 0.0754, 0.1005, 0.0909, 0.1140, 0.1348, 0.1348,\n","         0.1348]),\n"," 393: tensor([0.0162, 0.0274, 0.0373, 0.0722, 0.0546, 0.0606, 0.0625, 0.1118, 0.1021,\n","         0.1118, 0.0945, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 394: tensor([0.0218, 0.0234, 0.0294, 0.0392, 0.0583, 0.0727, 0.0891, 0.0727, 0.0825,\n","         0.0976, 0.0891, 0.0727, 0.0891, 0.0976, 0.0690, 0.0825, 0.0976, 0.0891,\n","         0.0891, 0.0976]),\n"," 395: tensor([0.0162, 0.0268, 0.0361, 0.0337, 0.0589, 0.1118, 0.0754, 0.1118, 0.0945,\n","         0.0791, 0.1021, 0.0884, 0.0884, 0.1118, 0.1118]),\n"," 396: tensor([0.0343, 0.0410, 0.0485, 0.0467, 0.0731, 0.0648, 0.0857, 0.0648, 0.0731,\n","         0.0917, 0.0767, 0.0767, 0.1085, 0.0857, 0.0990, 0.0990]),\n"," 397: tensor([0.0402, 0.0559, 0.0363, 0.0674, 0.0577, 0.0466, 0.0620, 0.0645, 0.1000,\n","         0.1000, 0.0745, 0.0791, 0.0913, 0.0913, 0.0791, 0.0845, 0.1000, 0.0913,\n","         0.0791]),\n"," 398: tensor([0.0613, 0.0488, 0.0583, 0.0583, 0.0668, 0.0772, 0.0845, 0.1010, 0.1091,\n","         0.1091, 0.1195, 0.1091, 0.1195]),\n"," 399: tensor([0.0183, 0.0550, 0.0503, 0.0591, 0.0570, 0.0711, 0.0870, 0.0870, 0.0870,\n","         0.0533, 0.0570, 0.0711, 0.0806, 0.0806, 0.0711, 0.0711, 0.0953, 0.0754,\n","         0.0806, 0.0953, 0.0953]),\n"," 400: tensor([0.0313, 0.0518, 0.0722, 0.0510, 0.0566, 0.0870, 0.1179, 0.0700, 0.1179,\n","         0.1291, 0.1291]),\n"," 401: tensor([0.0481, 0.0254, 0.0361, 0.0589, 0.0645, 0.0559, 0.1118, 0.0945, 0.0833,\n","         0.0945, 0.0884, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 402: tensor([0.0200, 0.0219, 0.0385, 0.0443, 0.0976, 0.0861, 0.0778, 0.0913, 0.0913,\n","         0.1054, 0.0976, 0.1054, 0.1155, 0.1155]),\n"," 403: tensor([0.0324, 0.0456, 0.0466, 0.0674, 0.1414, 0.1195, 0.1291, 0.1195, 0.1414]),\n"," 404: tensor([0.0330, 0.0454, 0.0318, 0.0556, 0.0711, 0.0711, 0.0711, 0.0786, 0.0962,\n","         0.0891, 0.1054, 0.0962, 0.0891, 0.1054, 0.0962, 0.1054, 0.1054]),\n"," 405: tensor([0.0187, 0.0417, 0.0566, 0.0630, 0.0870, 0.0913, 0.1091, 0.0913, 0.1021,\n","         0.1291, 0.1291]),\n"," 406: tensor([0.0229, 0.0468, 0.0459, 0.0412, 0.0636, 0.0574, 0.0692, 0.0725, 0.0867,\n","         0.0765, 0.0811, 0.0937, 0.0811, 0.0937, 0.0937, 0.1026, 0.0937, 0.0937]),\n"," 407: tensor([0.0312, 0.0388, 0.0506, 0.0769, 0.1048, 0.1240, 0.0877, 0.1048, 0.0925,\n","         0.1048, 0.1240, 0.1240]),\n"," 408: tensor([0.0468, 0.0546, 0.0811, 0.0707, 0.1336, 0.1443, 0.1443]),\n"," 409: tensor([0.0388, 0.0442, 0.0662, 0.0426, 0.0501, 0.0765, 0.0867, 0.1026, 0.0725,\n","         0.0636, 0.0867, 0.0765, 0.1026, 0.0937, 0.1026, 0.0867, 0.1026, 0.1026]),\n"," 410: tensor([0.0439, 0.0352, 0.0331, 0.0566, 0.0524, 0.0524, 0.0462, 0.0591, 0.0801,\n","         0.0693, 0.0741, 0.0741, 0.0801, 0.0693, 0.0801, 0.0801, 0.0801, 0.0801,\n","         0.0741, 0.0877, 0.0877, 0.0877, 0.0801, 0.0877, 0.0877]),\n"," 411: tensor([0.0301, 0.0472, 0.0488, 0.0668, 0.1010, 0.1195, 0.0806, 0.1010, 0.1195,\n","         0.1010, 0.0845, 0.1010, 0.1195]),\n"," 412: tensor([0.0327, 0.0606, 0.0308, 0.0476, 0.0700, 0.0588, 0.0731, 0.0767, 0.0700,\n","         0.0990, 0.0731, 0.0857, 0.0767, 0.1085, 0.0990, 0.1085]),\n"," 413: tensor([0.0455, 0.0422, 0.0414, 0.0953, 0.1066, 0.1005, 0.1005, 0.1231, 0.1348,\n","         0.1348]),\n"," 414: tensor([0.0309, 0.0338, 0.0630, 0.0745, 0.0833, 0.1054, 0.1179, 0.1491]),\n"," 415: tensor([0.0297, 0.0476, 0.0445, 0.0546, 0.0605, 0.0630, 0.0690, 0.0772, 0.0605,\n","         0.0690, 0.0658, 0.0891, 0.0891, 0.0690, 0.0563, 0.0825, 0.0891, 0.0891,\n","         0.0891, 0.0976]),\n"," 416: tensor([0.0200, 0.0359, 0.0324, 0.0630, 0.0654, 0.0833, 0.0891, 0.0833, 0.0891,\n","         0.1054, 0.1054, 0.1054, 0.0962, 0.1054, 0.0891, 0.1054, 0.1054]),\n"," 417: tensor([0.0239, 0.0491, 0.0398, 0.0609, 0.0572, 0.0891, 0.0891, 0.0891, 0.0786,\n","         0.0962, 0.0833, 0.1054, 0.0833, 0.1054, 0.0745, 0.0962, 0.1054]),\n"," 418: tensor([0.0328, 0.0351, 0.0456, 0.0456, 0.0667, 0.0861, 0.0976, 0.0976, 0.0913,\n","         0.0745, 0.1155, 0.1155, 0.1155, 0.1155]),\n"," 419: tensor([0.0268, 0.0707, 0.0466, 0.0620, 0.1054, 0.0845, 0.1118, 0.1000, 0.1291]),\n"," 420: tensor([0.0411, 0.0334, 0.0406, 0.0833, 0.0559, 0.0833, 0.0791, 0.0884, 0.1021,\n","         0.0791, 0.1118, 0.1118, 0.1021, 0.1118, 0.1021]),\n"," 421: tensor([0.0122, 0.0295, 0.0505, 0.0364, 0.0630, 0.0505, 0.0714, 0.0524, 0.0546,\n","         0.0570, 0.0714, 0.0772, 0.0630, 0.0668, 0.0570, 0.0714, 0.0772, 0.0598,\n","         0.0772, 0.0630, 0.0845, 0.0668, 0.0772, 0.0845, 0.0845, 0.0845, 0.0845]),\n"," 422: tensor([0.0811, 0.0680, 0.0574, 0.0680, 0.0833, 0.1118, 0.1443]),\n"," 423: tensor([0.0203, 0.0422, 0.0542, 0.0870, 0.1005, 0.0953, 0.1005, 0.1348, 0.1348,\n","         0.1348]),\n"," 424: tensor([0.0373, 0.0495, 0.0536, 0.0615, 0.0962, 0.0913, 0.1021, 0.0962, 0.1179,\n","         0.1179, 0.1291]),\n"," 425: tensor([0.0185, 0.0465, 0.0271, 0.0333, 0.0674, 0.0503, 0.0643, 0.0517, 0.0806,\n","         0.0550, 0.0953, 0.0953, 0.0870, 0.0870, 0.0806, 0.0953, 0.0870, 0.0953,\n","         0.0953, 0.0953, 0.0953]),\n"," 426: tensor([0.0231, 0.0256, 0.0953, 0.0711, 0.0870, 0.1005, 0.1005, 0.1231, 0.1348,\n","         0.1348]),\n"," 427: tensor([0.0259, 0.0430, 0.0503, 0.0503, 0.0745, 0.0609, 0.0891, 0.1054, 0.0654,\n","         0.0711, 0.0745, 0.0786, 0.1054, 0.0962, 0.1054, 0.1054, 0.0962]),\n"," 428: tensor([0.0375, 0.0589, 0.0727, 0.0642, 0.1260, 0.1260, 0.1260, 0.1361]),\n"," 429: tensor([0.0250, 0.0510, 0.0423, 0.0625, 0.0521, 0.0722, 0.0645, 0.1021, 0.0754,\n","         0.0693, 0.0791, 0.1118, 0.1021, 0.1021, 0.1118]),\n"," 430: tensor([0.0353, 0.0536, 0.0556, 0.0518, 0.0745, 0.0589, 0.1179, 0.1091, 0.1291,\n","         0.1291, 0.1291]),\n"," 431: tensor([0.0213, 0.0215, 0.0605, 0.0605, 0.0877, 0.0981, 0.0716, 0.0877, 0.0801,\n","         0.0981, 0.1132, 0.1240]),\n"," 432: tensor([0.0410, 0.0287, 0.0302, 0.0293, 0.0591, 0.0643, 0.0455, 0.0591, 0.0615,\n","         0.0953, 0.0806, 0.0870, 0.0870, 0.0754, 0.0870, 0.0953, 0.0953, 0.0953,\n","         0.0953, 0.0806, 0.0953]),\n"," 433: tensor([0.0229, 0.0606, 0.0635, 0.1066, 0.0981, 0.1250, 0.1336]),\n"," 434: tensor([0.0477, 0.0520, 0.0609, 0.0745, 0.1054, 0.1414, 0.1118, 0.1118, 0.1054]),\n"," 435: tensor([0.0259, 0.0442, 0.0449, 0.0599, 0.0808, 0.1054, 0.1111, 0.1491]),\n"," 436: tensor([0.0271, 0.0432, 0.0680, 0.0625, 0.1443, 0.1250, 0.1581]),\n"," 437: tensor([0.0354, 0.0371, 0.0408, 0.0359, 0.0667, 0.0577, 0.0667, 0.0577, 0.0632,\n","         0.0577, 0.0667, 0.0707, 0.0632, 0.0632, 0.0894, 0.0756, 0.0894, 0.0894,\n","         0.0707, 0.0894, 0.0894, 0.0894, 0.0894, 0.0894]),\n"," 438: tensor([0.0464, 0.0456, 0.0449, 0.0481, 0.0754, 0.0833, 0.0645, 0.0754, 0.0945,\n","         0.1021, 0.1021, 0.1021, 0.1118, 0.1021, 0.1118]),\n"," 439: tensor([0.0251, 0.0296, 0.0208, 0.0700, 0.0673, 0.0648, 0.0857, 0.0857, 0.0808,\n","         0.0990, 0.1085, 0.1085, 0.0990, 0.1085, 0.1085, 0.1085]),\n"," 440: tensor([0.0281, 0.0533, 0.0559, 0.0598, 0.1021, 0.0833, 0.1118]),\n"," 441: tensor([0.0353, 0.0389, 0.0488, 0.0801, 0.0772, 0.0913, 0.0962, 0.1291, 0.1091,\n","         0.1291, 0.1291]),\n"," 442: tensor([0.0483, 0.0620, 0.0801, 0.0741, 0.0741, 0.0693, 0.0981, 0.0877, 0.0981,\n","         0.1240, 0.1132, 0.1240]),\n"," 443: tensor([0.0340, 0.0556, 0.0410, 0.0467, 0.0808, 0.0917, 0.0648, 0.1085, 0.0857,\n","         0.0990, 0.1085, 0.0857, 0.1085, 0.1085, 0.1085, 0.0990]),\n"," 444: tensor([0.0333, 0.0443, 0.0383, 0.0443, 0.0808, 0.0626, 0.0626, 0.0606, 0.0572,\n","         0.0808, 0.0917, 0.0990, 0.0990, 0.0857, 0.1085, 0.1085]),\n"," 445: tensor([0.0216, 0.0654, 0.0891, 0.0667, 0.0833, 0.1179, 0.1054, 0.1361]),\n"," 446: tensor([0.0259, 0.0407, 0.0609, 0.0808, 0.0925, 0.1179, 0.1179, 0.1491]),\n"," 447: tensor([0.0435, 0.0577, 0.0870, 0.1021, 0.0962, 0.0962, 0.0913, 0.1021, 0.1021,\n","         0.1179, 0.1291]),\n"," 448: tensor([0.0252, 0.0659, 0.0456, 0.0816, 0.1000, 0.1118, 0.1195, 0.1118, 0.1414]),\n"," 449: tensor([0.0442, 0.0467, 0.0563, 0.1111, 0.1491, 0.1361, 0.1491, 0.1491]),\n"," 450: tensor([0.0496, 0.0576, 0.0679, 0.0756, 0.1336, 0.1429]),\n"," 451: tensor([0.0195, 0.0187, 0.0488, 0.0577, 0.0913, 0.1091, 0.1091, 0.1179, 0.1291,\n","         0.1291, 0.1291]),\n"," 452: tensor([0.0302, 0.0339, 0.0339, 0.0414, 0.1066, 0.1140, 0.1348, 0.0953, 0.1348,\n","         0.1348]),\n"," 453: tensor([0.0290, 0.0488, 0.0816, 0.0577, 0.0745, 0.0976, 0.0976, 0.1054, 0.1054,\n","         0.1155, 0.1155, 0.1054, 0.1155, 0.1155]),\n"," 454: tensor([0.0205, 0.0434, 0.0357, 0.0472, 0.0806, 0.0945, 0.1195, 0.1010, 0.1091,\n","         0.0945, 0.1195, 0.1195, 0.1195]),\n"," 455: tensor([0.0206, 0.0429, 0.0467, 0.0808, 0.0808, 0.0556, 0.0808, 0.0857, 0.0990,\n","         0.0990, 0.0917, 0.0917, 0.0990, 0.1085, 0.1085, 0.1085]),\n"," 456: tensor([0.0207, 0.0277, 0.0452, 0.0488, 0.0668, 0.0714, 0.0891, 0.0741, 0.1091,\n","         0.1091, 0.1091, 0.1091, 0.1195]),\n"," 457: tensor([0.0425, 0.0788, 0.0867, 0.1048, 0.0741, 0.1690]),\n"," 458: tensor([0.0295, 0.0329, 0.0423, 0.0434, 0.0386, 0.0445, 0.0423, 0.0472, 0.0668,\n","         0.0714, 0.0714, 0.0668, 0.0598, 0.0714, 0.0845, 0.0668, 0.0772, 0.0845,\n","         0.0598, 0.0772, 0.0845, 0.0845, 0.0845, 0.0845, 0.0845, 0.0845, 0.0845]),\n"," 459: tensor([0.0551, 0.0639, 0.0945, 0.0825, 0.1543, 0.1690]),\n"," 460: tensor([0.0339, 0.0476, 0.0544, 0.0654, 0.0716, 0.0836, 0.1048, 0.1048, 0.0925,\n","         0.1240, 0.1048, 0.1132]),\n"," 461: tensor([0.0318, 0.0541, 0.0514, 0.0589, 0.0786, 0.0556, 0.0891, 0.0786, 0.0680,\n","         0.0962, 0.0833, 0.0962, 0.0891, 0.1054, 0.1054, 0.1054, 0.1054]),\n"," 462: tensor([0.0333, 0.0216, 0.0338, 0.0491, 0.0962, 0.1491, 0.1179, 0.1179]),\n"," 463: tensor([0.0235, 0.0476, 0.0388, 0.0673, 0.1048, 0.0654, 0.0877, 0.1132, 0.1240,\n","         0.1048, 0.1048, 0.1240]),\n"," 464: tensor([0.0205, 0.0301, 0.0570, 0.0741, 0.0945, 0.1091, 0.0945, 0.1195, 0.1010,\n","         0.0845, 0.0945, 0.1195, 0.1195]),\n"," 465: tensor([0.0136, 0.0386, 0.0308, 0.0395, 0.0490, 0.0625, 0.0456, 0.0589, 0.0559,\n","         0.0625, 0.0490, 0.0472, 0.0510, 0.0668, 0.0589, 0.0722, 0.0559, 0.0791,\n","         0.0791, 0.0722, 0.0791, 0.0625, 0.0722, 0.0791, 0.0791, 0.0722, 0.0791,\n","         0.0791, 0.0791, 0.0791, 0.0791]),\n"," 466: tensor([0.0141, 0.0275, 0.0294, 0.0501, 0.0772, 0.0727, 0.0563, 0.0976, 0.0772,\n","         0.0772, 0.0825, 0.0825, 0.0891, 0.0891, 0.0891, 0.0825, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 467: tensor([0.0556, 0.0733, 0.0690, 0.1443, 0.1543]),\n"," 468: tensor([0.0253, 0.0481, 0.0318, 0.0430, 0.0833, 0.0745, 0.0589, 0.0833, 0.0711,\n","         0.0962, 0.0891, 0.0891, 0.1054, 0.0962, 0.0891, 0.1054, 0.0962]),\n"," 469: tensor([0.0361, 0.0340, 0.0442, 0.0625, 0.0945, 0.0884, 0.0693, 0.0884, 0.0833,\n","         0.1021, 0.0884, 0.0884, 0.1118, 0.1021, 0.1021]),\n"," 470: tensor([0.0477, 0.0692, 0.1066, 0.0953, 0.0909, 0.0909, 0.0909, 0.1140, 0.1348,\n","         0.1231]),\n"," 471: tensor([0.0486, 0.0541, 0.0619, 0.1005, 0.0925, 0.1054, 0.1179, 0.1260]),\n"," 472: tensor([0.0224, 0.0280, 0.0745, 0.0645, 0.0778, 0.0645, 0.0626, 0.0816, 0.0913,\n","         0.0745, 0.0816, 0.1054, 0.1155, 0.1155]),\n"," 473: tensor([0.0158, 0.0286, 0.0481, 0.0456, 0.0566, 0.0722, 0.0645, 0.0722, 0.0772,\n","         0.0833, 0.0913, 0.0913, 0.0645, 0.0913, 0.0772, 0.0913, 0.0913, 0.0913,\n","         0.0913, 0.0772, 0.0913, 0.0913, 0.0913]),\n"," 474: tensor([0.0343, 0.0415, 0.0346, 0.0356]),\n"," 475: tensor([0.0226, 0.0412, 0.0369, 0.0476, 0.0727, 0.0825, 0.0630, 0.0630, 0.0825,\n","         0.0690, 0.0976, 0.0976, 0.0891, 0.0727, 0.0825, 0.0976, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 476: tensor([0.0517, 0.0560, 0.0603, 0.0754, 0.0953, 0.0953, 0.1348, 0.1348, 0.1231,\n","         0.1348]),\n"," 477: tensor([0.0456, 0.0490, 0.0490, 0.0625, 0.0833, 0.0722, 0.0884, 0.0833, 0.0884,\n","         0.1021, 0.1118, 0.1021, 0.1118, 0.1118, 0.1021]),\n"," 478: tensor([0.0132, 0.0377, 0.0377, 0.0741, 0.0566, 0.0741, 0.0439, 0.0506, 0.0654,\n","         0.0741, 0.0693, 0.0741, 0.0877, 0.0654, 0.0693, 0.0801, 0.0801, 0.0877,\n","         0.0877, 0.0877, 0.0877, 0.0741, 0.0741, 0.0877, 0.0877]),\n"," 479: tensor([0.0482, 0.0542, 0.0690, 0.0913, 0.0953, 0.1195, 0.1414, 0.1291, 0.1291]),\n"," 480: tensor([0.0290, 0.0519, 0.0668, 0.0945, 0.1429, 0.1429]),\n"," 481: tensor([0.0346, 0.0325, 0.0733, 0.0913, 0.1443]),\n"," 482: tensor([0.0180, 0.0439, 0.0546, 0.0598, 0.0845, 0.1091, 0.0945, 0.1195, 0.1195,\n","         0.1195, 0.1010, 0.1195, 0.1195]),\n"," 483: tensor([0.0398, 0.0458, 0.0570, 0.0434, 0.0945, 0.0845, 0.0714, 0.1091, 0.0891,\n","         0.1091, 0.1195, 0.1195, 0.1195]),\n"," 484: tensor([0.0193, 0.0334, 0.0574, 0.0589, 0.0546, 0.0945, 0.0833, 0.0791, 0.1021,\n","         0.1021, 0.1021, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 485: tensor([0.0428, 0.0498, 0.0741, 0.0925, 0.0925, 0.0741, 0.1048, 0.1240, 0.1048,\n","         0.1240, 0.1132, 0.1240]),\n"," 486: tensor([0.0195, 0.0404, 0.0556, 0.0518, 0.0913, 0.0913, 0.0870, 0.1021, 0.1291,\n","         0.1291, 0.1179]),\n"," 487: tensor([0.0239, 0.0454, 0.0503, 0.0556, 0.0786, 0.0609, 0.0786, 0.1054, 0.0711,\n","         0.0891, 0.0786, 0.1054, 0.1054, 0.1054, 0.1054, 0.0962, 0.1054]),\n"," 488: tensor([0.0301, 0.0458, 0.0613, 0.0557, 0.0891, 0.0845, 0.1195, 0.1010, 0.1010,\n","         0.1091, 0.1195, 0.1195, 0.1195]),\n"," 489: tensor([0.0398, 0.0581, 0.0657, 0.0680, 0.1336, 0.1581, 0.1250]),\n"," 490: tensor([0.0357, 0.0599, 0.0711, 0.0630, 0.1054, 0.1491, 0.1361, 0.1361]),\n"," 491: tensor([0.0192, 0.0254, 0.0312, 0.0589, 0.0791, 0.0945, 0.0945, 0.0945, 0.0693,\n","         0.1118, 0.1021, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 492: tensor([0.0209, 0.0375, 0.0602, 0.0521, 0.0788, 0.0659, 0.0578, 0.0557, 0.0788,\n","         0.0851, 0.0851, 0.0933, 0.0933, 0.0788, 0.0933, 0.0851, 0.0933, 0.0851,\n","         0.0933, 0.0933, 0.0851, 0.0933]),\n"," 493: tensor([0.0405, 0.0490, 0.0555, 0.0469, 0.0654, 0.0981, 0.0801, 0.1240, 0.1132,\n","         0.1048, 0.1132, 0.1240]),\n"," 494: tensor([0.0383, 0.0464, 0.0303, 0.0527, 0.1581, 0.1581, 0.1581]),\n"," 495: tensor([0.0321, 0.0321, 0.0450, 0.0662, 0.0725, 0.0489, 0.0636, 0.0867, 0.0811,\n","         0.0937, 0.1026, 0.0692, 0.0937, 0.0692, 0.1026, 0.1026, 0.0937, 0.1026]),\n"," 496: tensor([0.0290, 0.0322, 0.0374, 0.0741, 0.0741, 0.1195, 0.1091, 0.0845, 0.0945,\n","         0.0806, 0.1195, 0.1195, 0.1195]),\n"," 497: tensor([0.0467, 0.0667, 0.0891, 0.0808, 0.1054, 0.1361, 0.1361, 0.1491]),\n"," 498: tensor([0.0353, 0.0566, 0.0481, 0.0700, 0.0913, 0.1179, 0.1091, 0.1179, 0.1291,\n","         0.1179, 0.1291]),\n"," 499: tensor([0.0845, 0.0659, 0.0674, 0.0791, 0.1118, 0.0953, 0.1195, 0.1195, 0.1414]),\n"," 500: tensor([0.0619, 0.0599, 0.0609, 0.0667, 0.1179, 0.1491, 0.1361, 0.1491]),\n"," 501: tensor([0.0491, 0.0745, 0.0662, 0.0833, 0.1291]),\n"," 502: tensor([0.0525, 0.0615, 0.0643, 0.0629, 0.1140, 0.0909, 0.1231, 0.1005, 0.0953,\n","         0.1140]),\n"," 503: tensor([0.0374, 0.0515, 0.0591, 0.0981, 0.0769, 0.0981, 0.0981, 0.0877, 0.0877,\n","         0.1132, 0.1240, 0.1240]),\n"," 504: tensor([0.0638, 0.0690, 0.0786, 0.0962, 0.1826]),\n"," 505: tensor([0.0238, 0.0367, 0.0581, 0.1118, 0.0981, 0.1581, 0.1581]),\n"," 506: tensor([0.0421, 0.0602, 0.0630, 0.0722, 0.0745, 0.1021, 0.1291, 0.1291, 0.0870,\n","         0.1291, 0.1291]),\n"," 507: tensor([0.0268, 0.0456, 0.0559, 0.0659, 0.0816, 0.1054, 0.1291, 0.1291, 0.1414]),\n"," 508: tensor([0.0229, 0.0432, 0.0552, 0.0884, 0.0981, 0.1179, 0.1581]),\n"," 509: tensor([0.0164, 0.0206, 0.0443, 0.0606, 0.0476, 0.0606, 0.0990, 0.1085, 0.0990,\n","         0.1085, 0.0808, 0.0990, 0.1085, 0.1085, 0.0990, 0.1085]),\n"," 510: tensor([0.0203, 0.0711, 0.0731, 0.0806, 0.0836, 0.1231, 0.0909, 0.1348, 0.1348,\n","         0.1348]),\n"," 511: tensor([0.0157, 0.0273, 0.0251, 0.0358, 0.0731, 0.0731, 0.0990, 0.0917, 0.0857,\n","         0.0808, 0.0917, 0.0990, 0.0767, 0.0767, 0.0917, 0.1085]),\n"," 512: tensor([0.0645, 0.0443, 0.0426, 0.0620, 0.0767, 0.1414, 0.1414, 0.1414, 0.1414]),\n"," 513: tensor([0.0339, 0.0494, 0.0659, 0.0674, 0.1000, 0.1291, 0.1291, 0.1414, 0.1414]),\n"," 514: tensor([0.0285, 0.0215, 0.0413, 0.0877, 0.1048, 0.0836, 0.1048, 0.1048, 0.0877,\n","         0.0836, 0.0836, 0.1240]),\n"," 515: tensor([0.0289, 0.0602, 0.0962, 0.0566, 0.1091, 0.0962, 0.0772, 0.1291, 0.1021,\n","         0.1291, 0.1291]),\n"," 516: tensor([0.0234, 0.0580, 0.0422, 0.1005, 0.0711, 0.0806, 0.1348, 0.1066, 0.1140,\n","         0.1348]),\n"," 517: tensor([0.0577, 0.0645, 0.0745, 0.0626, 0.0913, 0.0816, 0.0913, 0.1054, 0.1054,\n","         0.0976, 0.1054, 0.1054, 0.1155, 0.1054]),\n"," 518: tensor([0.0392, 0.0513, 0.0434, 0.0690, 0.1195, 0.0791, 0.1414, 0.1414, 0.1414]),\n"," 519: tensor([0.0367, 0.0635, 0.0645, 0.0707, 0.1021, 0.1179, 0.1581]),\n"," 520: tensor([0.0141, 0.0445, 0.0546, 0.0546, 0.0405, 0.0772, 0.0658, 0.0563, 0.0605,\n","         0.0630, 0.0727, 0.0630, 0.0825, 0.0891, 0.0976, 0.0891, 0.0772, 0.0976,\n","         0.0976, 0.0976]),\n"," 521: tensor([0.0343, 0.0395, 0.0690, 0.0725, 0.1000, 0.0816, 0.1054, 0.1195, 0.1195]),\n"," 522: tensor([0.0268, 0.0379, 0.0245, 0.0645, 0.0662, 0.1021, 0.1021, 0.0962, 0.1179,\n","         0.1291, 0.1179]),\n"," 523: tensor([0.0400, 0.0352, 0.0490, 0.0476, 0.0741, 0.0693, 0.0620, 0.0693, 0.0654,\n","         0.0801, 0.0877, 0.0801, 0.0693, 0.0877, 0.0591, 0.0741, 0.0566, 0.0620,\n","         0.0566, 0.0693, 0.0801, 0.0877, 0.0877, 0.0877, 0.0877]),\n"," 524: tensor([0.0695, 0.0962, 0.0786, 0.0786, 0.0891, 0.1179, 0.1054, 0.1111]),\n"," 525: tensor([0.0258, 0.0420, 0.0727, 0.0808, 0.1111, 0.1260, 0.1361, 0.1491]),\n"," 526: tensor([0.0141, 0.0177, 0.0401, 0.0352, 0.0506, 0.0659, 0.0491, 0.0659, 0.0695,\n","         0.0737, 0.0851, 0.0578, 0.0737, 0.0933, 0.0737, 0.0737, 0.0659, 0.0851,\n","         0.0788, 0.0851, 0.0851, 0.0933]),\n"," 527: tensor([0.0277, 0.0238, 0.0469, 0.0636, 0.0925, 0.0769, 0.0877, 0.0981, 0.1048,\n","         0.0981, 0.1132, 0.1240]),\n"," 528: tensor([0.0265, 0.0290, 0.0577, 0.0516, 0.0861, 0.0716, 0.0716, 0.1155, 0.0861,\n","         0.0913, 0.1155, 0.1054, 0.1155, 0.1155]),\n"," 529: tensor([0.0274, 0.0303, 0.0693, 0.0945, 0.1443, 0.1066, 0.1443]),\n"," 530: tensor([0.0458, 0.0386, 0.0668, 0.0524, 0.0741, 0.1195, 0.0741, 0.0945, 0.1195,\n","         0.1091, 0.1195, 0.1091, 0.1195]),\n"," 531: tensor([0.0430, 0.0497, 0.0471, 0.1005, 0.1111, 0.1260, 0.1054, 0.1491]),\n"," 532: tensor([0.0304, 0.0510, 0.0345, 0.0386, 0.0680, 0.0527, 0.0680, 0.0680, 0.0722,\n","         0.0546, 0.0615, 0.0645, 0.0615, 0.0546, 0.0589, 0.0680, 0.0722, 0.0772,\n","         0.0913, 0.0833, 0.0645, 0.0722, 0.0833]),\n"," 533: tensor([0.0316, 0.0448, 0.0833, 0.0833, 0.1826]),\n"," 534: tensor([0.0366, 0.0609, 0.1111, 0.0765, 0.1361, 0.1260, 0.1491, 0.1491]),\n"," 535: tensor([0.0198, 0.0290, 0.0200, 0.0348, 0.0913, 0.0861, 0.0716, 0.0861, 0.0913,\n","         0.0976, 0.1054, 0.1054, 0.1054, 0.1155]),\n"," 536: tensor([0.0292, 0.0727, 0.0690, 0.0679, 0.1260, 0.1543]),\n"," 537: tensor([0.0280, 0.0542, 0.0542, 0.0731, 0.1066, 0.1231, 0.0953, 0.1140, 0.1348,\n","         0.1348]),\n"," 538: tensor([0.0162, 0.0350, 0.0254, 0.0369, 0.1118, 0.0791, 0.0791, 0.0945, 0.0833,\n","         0.0945, 0.1021, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 539: tensor([0.0450, 0.0334, 0.0334, 0.0405, 0.0619, 0.0702, 0.0830, 0.0560, 0.0657,\n","         0.0657, 0.0758, 0.0830, 0.0657, 0.0758, 0.0657, 0.0702, 0.0758, 0.0830,\n","         0.0657, 0.0758, 0.0758, 0.0702, 0.0830, 0.0830, 0.0830, 0.0830, 0.0830,\n","         0.0830]),\n"," 540: tensor([0.0707, 0.0645, 0.0913, 0.0884, 0.1118, 0.1581, 0.1336]),\n"," 541: tensor([0.0379, 0.0443, 0.0588, 0.0572, 0.0673, 0.0990, 0.0731, 0.0767, 0.0808,\n","         0.0990, 0.0857, 0.0990, 0.0990, 0.0917, 0.0808, 0.1085]),\n"," 542: tensor([0.0390, 0.0496, 0.0557, 0.0690, 0.0772, 0.0806, 0.1010, 0.1195, 0.0891,\n","         0.0945, 0.1195, 0.1091, 0.1195]),\n"," 543: tensor([0.0407, 0.0808, 0.0925, 0.0925, 0.1491, 0.1491, 0.1361, 0.1361]),\n"," 544: tensor([0.0187, 0.0238, 0.0374, 0.0620, 0.1132, 0.0591, 0.0769, 0.0836, 0.0925,\n","         0.1132, 0.1132, 0.1240]),\n"," 545: tensor([0.0240, 0.0464, 0.0449, 0.0626, 0.0745, 0.0563, 0.0976, 0.0976, 0.1155,\n","         0.0645, 0.1155, 0.0976, 0.1155, 0.0976]),\n"," 546: tensor([0.0212, 0.0230, 0.0295, 0.0645, 0.0468, 0.0417, 0.0722, 0.0566, 0.0833,\n","         0.0772, 0.0833, 0.0772, 0.0645, 0.0772, 0.0913, 0.0913, 0.0913, 0.0913,\n","         0.0680, 0.0833, 0.0833, 0.0913, 0.0913]),\n"," 547: tensor([0.0362, 0.0454, 0.0338, 0.0680, 0.1260, 0.1260, 0.1361, 0.1361]),\n"," 548: tensor([0.0299, 0.0527, 0.0559, 0.0559, 0.0707, 0.1000, 0.0745, 0.0645, 0.0745,\n","         0.0527, 0.0845, 0.0791, 0.1000, 0.0845, 0.0913, 0.0845, 0.1000, 0.1000,\n","         0.1000]),\n"," 549: tensor([0.0328, 0.0436, 0.0436, 0.0527, 0.1054, 0.0745, 0.0861, 0.0913, 0.0913,\n","         0.1155, 0.0976, 0.0976, 0.1054, 0.1155]),\n"," 550: tensor([0.0342, 0.0589, 0.0745, 0.0861, 0.1005, 0.0891, 0.1491, 0.1491]),\n"," 551: tensor([0.0443, 0.0577, 0.0690, 0.0535, 0.1118, 0.1118, 0.1195, 0.1291, 0.1414]),\n"," 552: tensor([0.0281, 0.0426, 0.0574, 0.0884, 0.1179, 0.1581, 0.1581]),\n"," 553: tensor([0.0240, 0.0456, 0.0693, 0.0636, 0.0877, 0.0769, 0.0877, 0.0925, 0.0925,\n","         0.0981, 0.1048, 0.1240]),\n"," 554: tensor([0.0248, 0.0234, 0.0273, 0.0378, 0.0505, 0.0472, 0.0630, 0.0570, 0.0505,\n","         0.0714, 0.0668, 0.0845, 0.0668, 0.0630, 0.0845, 0.0772, 0.0845, 0.0714,\n","         0.0772, 0.0714, 0.0845, 0.0845, 0.0772, 0.0845, 0.0845, 0.0772, 0.0845]),\n"," 555: tensor([0.0643, 0.0674, 0.0754, 0.0731, 0.0953, 0.1348, 0.1231, 0.1348, 0.1348,\n","         0.1348]),\n"," 556: tensor([0.0674, 0.0609, 0.0913, 0.0690, 0.1291, 0.1054, 0.1291, 0.1414, 0.1414]),\n"," 557: tensor([0.0252, 0.0386, 0.0550, 0.0725, 0.1054, 0.1195, 0.1118, 0.1291, 0.1414]),\n"," 558: tensor([0.0188, 0.0609, 0.0527, 0.0833, 0.0654, 0.0786, 0.0654, 0.0654, 0.0891,\n","         0.0786, 0.0962, 0.1054, 0.1054, 0.1054, 0.1054, 0.1054, 0.1054]),\n"," 559: tensor([0.0204, 0.0572, 0.0630, 0.0833, 0.0541, 0.0745, 0.0962, 0.0680, 0.0711,\n","         0.0654, 0.0680, 0.0833, 0.0786, 0.0745, 0.0891, 0.1054, 0.0891]),\n"," 560: tensor([0.0207, 0.0301, 0.0613, 0.0741, 0.1091, 0.0806, 0.1010, 0.1091, 0.1010,\n","         0.1010, 0.1195, 0.1195, 0.1195]),\n"," 561: tensor([0.0410, 0.0535, 0.0741, 0.1091, 0.1195, 0.1140]),\n"," 562: tensor([0.0408, 0.0465, 0.0465, 0.0480, 0.0945, 0.0845, 0.0741, 0.0945, 0.1091,\n","         0.0891, 0.1091, 0.1091, 0.1195]),\n"," 563: tensor([0.0195, 0.0580, 0.0339, 0.0731, 0.0909, 0.1231, 0.1231, 0.1348, 0.1348,\n","         0.1348]),\n"," 564: tensor([0.0132, 0.0358, 0.0428, 0.0364, 0.0490, 0.0566, 0.0741, 0.0506, 0.0544,\n","         0.0801, 0.0654, 0.0877, 0.0801, 0.0877, 0.0693, 0.0801, 0.0693, 0.0877,\n","         0.0801, 0.0801, 0.0741, 0.0877, 0.0877, 0.0877, 0.0877]),\n"," 565: tensor([0.0203, 0.0256, 0.0460, 0.0323, 0.0836, 0.0836, 0.1348, 0.1348, 0.1348,\n","         0.1348]),\n"," 566: tensor([0.0221, 0.0397, 0.0468, 0.0745, 0.0913, 0.1091, 0.1291, 0.1291, 0.1291,\n","         0.1291, 0.1291]),\n"," 567: tensor([0.0442, 0.0503, 0.0711, 0.0609, 0.1111, 0.1491, 0.1361, 0.1111]),\n"," 568: tensor([0.0913, 0.0735, 0.1026, 0.1581]),\n"," 569: tensor([0.0456, 0.0490, 0.0429, 0.0606, 0.0693, 0.0546, 0.0791, 0.0833, 0.1021,\n","         0.1021, 0.1118, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 570: tensor([0.0324, 0.0577, 0.0500, 0.0767, 0.0690, 0.1000, 0.1291, 0.1414, 0.1414]),\n"," 571: tensor([0.0917, 0.0891, 0.0690, 0.0741, 0.1336, 0.1195]),\n"," 572: tensor([0.0313, 0.0527, 0.0326, 0.0430, 0.0559, 0.0707, 0.0707, 0.0791, 0.0845,\n","         0.0791, 0.1000, 0.0791, 0.0913, 0.1000, 0.0913, 0.1000, 0.1000, 0.1000,\n","         0.0913]),\n"," 573: tensor([0.0325, 0.0556, 0.0816, 0.0962, 0.1667]),\n"," 574: tensor([0.0164, 0.0350, 0.0533, 0.0489, 0.0570, 0.0615, 0.0870, 0.0711, 0.0870,\n","         0.0477, 0.0615, 0.0953, 0.0953, 0.0806, 0.0711, 0.0711, 0.0953, 0.0953,\n","         0.0870, 0.0953, 0.0953]),\n"," 575: tensor([0.0857, 0.0772, 0.0625, 0.0791, 0.1336, 0.1581, 0.1581]),\n"," 576: tensor([0.0636, 0.0476, 0.0591, 0.0490, 0.0877, 0.1240, 0.1240, 0.1240, 0.0925,\n","         0.1048, 0.1048, 0.1240]),\n"," 577: tensor([0.0659, 0.1118, 0.0767, 0.1195, 0.1054, 0.1291, 0.1291, 0.1195, 0.1291]),\n"," 578: tensor([0.0258, 0.0400, 0.0578, 0.0693, 0.0877, 0.0716, 0.1048, 0.1132, 0.1132,\n","         0.0981, 0.1132, 0.1240]),\n"," 579: tensor([0.0386, 0.0514, 0.0480, 0.0524, 0.0891, 0.0945, 0.0806, 0.1010, 0.1195,\n","         0.1010, 0.1195, 0.1195, 0.1195]),\n"," 580: tensor([0.0539, 0.0456, 0.0559, 0.1066, 0.1581, 0.1581, 0.1336]),\n"," 581: tensor([0.0363, 0.0439, 0.0635, 0.0772, 0.1250, 0.1336, 0.1581]),\n"," 582: tensor([0.0245, 0.0559, 0.0877, 0.0535, 0.1195, 0.1291, 0.1414, 0.1414, 0.1414]),\n"," 583: tensor([0.0293, 0.0337, 0.0472, 0.0772, 0.0546, 0.1195, 0.0891, 0.1010, 0.1195,\n","         0.1091, 0.1195, 0.1195, 0.1195]),\n"," 584: tensor([0.0423, 0.0433, 0.0374, 0.0673, 0.1048, 0.1132, 0.1240, 0.1132, 0.0981,\n","         0.1240, 0.1240, 0.1240]),\n"," 585: tensor([0.0521, 0.0500, 0.0913, 0.0754, 0.1066, 0.1581, 0.1581]),\n"," 586: tensor([0.0234, 0.0386, 0.0359, 0.0306, 0.0727, 0.0825, 0.0976, 0.0690, 0.0727,\n","         0.0891, 0.0825, 0.0891, 0.0976, 0.0825, 0.0825, 0.0891, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 587: tensor([0.0340, 0.0456, 0.0395, 0.0406, 0.0945, 0.1021, 0.0833, 0.1021, 0.0754,\n","         0.0884, 0.1021, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 588: tensor([0.0366, 0.0765, 0.0599, 0.1054, 0.0680, 0.1111, 0.1054, 0.1491]),\n"," 589: tensor([0.0271, 0.0772, 0.0589, 0.0833, 0.0857, 0.1581, 0.1581]),\n"," 590: tensor([0.0245, 0.0268, 0.0816, 0.0877, 0.0845, 0.1291, 0.1291, 0.1414, 0.1414]),\n"," 591: tensor([0.0293, 0.0405, 0.1140, 0.0976, 0.1010, 0.1048]),\n"," 592: tensor([0.0690, 0.1048, 0.0788, 0.1195, 0.1336, 0.1690]),\n"," 593: tensor([0.0174, 0.0167, 0.0443, 0.0609, 0.0626, 0.1054, 0.1155, 0.0861, 0.0976,\n","         0.1054, 0.1155, 0.1155, 0.1155, 0.1155]),\n"," 594: tensor([0.0250, 0.0722, 0.0662, 0.0662, 0.1021, 0.0630, 0.0962, 0.0870, 0.1179,\n","         0.1291, 0.1291]),\n"," 595: tensor([0.0212, 0.0464, 0.0510, 0.0589, 0.0754, 0.0833, 0.0833, 0.0884, 0.1021,\n","         0.1118, 0.0945, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 596: tensor([0.0533, 0.0318, 0.0373, 0.0693, 0.0833, 0.0884, 0.0693, 0.0884, 0.1021,\n","         0.1118, 0.1118, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 597: tensor([0.0181, 0.0265, 0.0398, 0.0589, 0.0630, 0.0609, 0.0745, 0.0711, 0.0891,\n","         0.0609, 0.0745, 0.0891, 0.0962, 0.1054, 0.1054, 0.0962, 0.1054]),\n"," 598: tensor([0.0563, 0.0808, 0.0925, 0.0680, 0.1361, 0.1361, 0.1491, 0.1491]),\n"," 599: tensor([0.0244, 0.0480, 0.0679, 0.0639, 0.1429, 0.1543]),\n"," 600: tensor([0.0185, 0.0271, 0.0383, 0.0615, 0.0643, 0.0674, 0.0643, 0.0754, 0.0643,\n","         0.0570, 0.0870, 0.0806, 0.0870, 0.0953, 0.0953, 0.0953, 0.0806, 0.0953,\n","         0.0953, 0.0953, 0.0953]),\n"," 601: tensor([0.0312, 0.0423, 0.0423, 0.0668, 0.0884, 0.0754, 0.0754, 0.0884, 0.0693,\n","         0.1021, 0.0884, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 602: tensor([0.0609, 0.0680, 0.0808, 0.0727, 0.0861, 0.1179, 0.1361, 0.1491]),\n"," 603: tensor([0.0165, 0.0181, 0.0383, 0.0418, 0.0533, 0.0591, 0.0806, 0.0754, 0.0711,\n","         0.0806, 0.0870, 0.0870, 0.0870, 0.0953, 0.0953, 0.0711, 0.0953, 0.0953,\n","         0.0953, 0.0953, 0.0953]),\n"," 604: tensor([0.0658, 0.0692, 0.0629, 0.0658, 0.0870, 0.0909, 0.1140, 0.1231, 0.1140,\n","         0.1348]),\n"," 605: tensor([0.0233, 0.0410, 0.0306, 0.0778, 0.1066, 0.0953, 0.1066, 0.1231, 0.1231,\n","         0.1348]),\n"," 606: tensor([0.0293, 0.0679, 0.0679, 0.1010, 0.1140, 0.1429]),\n"," 607: tensor([0.0550, 0.0913, 0.0745, 0.1021, 0.1826]),\n"," 608: tensor([0.0193, 0.0481, 0.0668, 0.0490, 0.0884, 0.0945, 0.0722, 0.0791, 0.0693,\n","         0.0791, 0.0791, 0.0884, 0.1118, 0.0884, 0.1118]),\n"," 609: tensor([0.0312, 0.0506, 0.0620, 0.0636, 0.0981, 0.0925, 0.1132, 0.1048, 0.1048,\n","         0.0925, 0.1132, 0.1048]),\n"," 610: tensor([0.0454, 0.0454, 0.0481, 0.0711, 0.0745, 0.0891, 0.0745, 0.0962, 0.0745,\n","         0.0962, 0.0891, 0.1054, 0.0962, 0.1054, 0.1054, 0.0962, 0.0962]),\n"," 611: tensor([0.0258, 0.0321, 0.0372, 0.0556, 0.0501, 0.0592, 0.0592, 0.1026, 0.1026,\n","         0.0867, 0.1026, 0.0811, 0.1026, 0.1026, 0.1026, 0.1026, 0.0937, 0.1026]),\n"," 612: tensor([0.0541, 0.0745, 0.0937, 0.0990, 0.1826]),\n"," 613: tensor([0.0157, 0.0495, 0.0379, 0.0506, 0.0700, 0.0767, 0.0588, 0.0767, 0.0808,\n","         0.0917, 0.0731, 0.0857, 0.0917, 0.0990, 0.1085, 0.1085]),\n"," 614: tensor([0.0256, 0.0548, 0.0786, 0.0833, 0.1260, 0.1361, 0.1361, 0.1361]),\n"," 615: tensor([0.0281, 0.0328, 0.0481, 0.0625, 0.0833, 0.0546, 0.0884, 0.0945, 0.0833,\n","         0.0833, 0.1118, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 616: tensor([0.0667, 0.0727, 0.0727, 0.0833, 0.1111, 0.1491, 0.1491, 0.1361]),\n"," 617: tensor([0.0203, 0.0380, 0.0407, 0.0560, 0.1066, 0.1231, 0.1005, 0.1231, 0.1348,\n","         0.1348]),\n"," 618: tensor([0.0339, 0.0658, 0.0383, 0.0591, 0.0953, 0.1348, 0.1231, 0.1140, 0.0953,\n","         0.1231]),\n"," 619: tensor([0.0178, 0.0197, 0.0258, 0.0468, 0.0556, 0.0692, 0.0765, 0.0867, 0.0811,\n","         0.1026, 0.1026, 0.1026, 0.1026, 0.0937, 0.0811, 0.0867, 0.0937, 0.1026]),\n"," 620: tensor([0.0205, 0.0436, 0.0645, 0.0592, 0.0861, 0.0861, 0.0690, 0.1155, 0.0861,\n","         0.0816, 0.0778, 0.1155, 0.1155, 0.1155]),\n"," 621: tensor([0.0379, 0.0367, 0.0386, 0.0680, 0.0615, 0.0680, 0.0589, 0.0913, 0.0913,\n","         0.0833, 0.0833, 0.0772, 0.0833, 0.0913, 0.0913, 0.0833, 0.0833, 0.0913,\n","         0.0833, 0.0913, 0.0833, 0.0913, 0.0913]),\n"," 622: tensor([0.0362, 0.0416, 0.0808, 0.0556, 0.0808, 0.0857, 0.0990, 0.0767, 0.0917,\n","         0.0700, 0.0990, 0.0808, 0.0990, 0.1085, 0.0808, 0.1085]),\n"," 623: tensor([0.0635, 0.1118, 0.0625, 0.1021, 0.1250, 0.1336, 0.1581]),\n"," 624: tensor([0.0497, 0.0417, 0.0619, 0.0497, 0.1005, 0.1361, 0.1491, 0.1260]),\n"," 625: tensor([0.0309, 0.0353, 0.0602, 0.0662, 0.0962, 0.1091, 0.1021, 0.1021, 0.1291,\n","         0.1291, 0.1291]),\n"," 626: tensor([0.0230, 0.0645, 0.0367, 0.0556, 0.0962, 0.1021, 0.1179, 0.0722, 0.1091,\n","         0.1291, 0.1291]),\n"," 627: tensor([0.0296, 0.0372, 0.0468, 0.0662, 0.0556, 0.0725, 0.0811, 0.0811, 0.0765,\n","         0.0937, 0.0867, 0.1026, 0.0937, 0.0937, 0.0937, 0.0937, 0.1026, 0.0937]),\n"," 628: tensor([0.0167, 0.0200, 0.0365, 0.0592, 0.0913, 0.1054, 0.0778, 0.0745, 0.0913,\n","         0.0861, 0.1054, 0.1054, 0.0976, 0.1054]),\n"," 629: tensor([0.0313, 0.0192, 0.0913, 0.0378, 0.0577, 0.0745, 0.0707, 0.0791, 0.0845,\n","         0.0791, 0.0913, 0.0913, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n","         0.1000]),\n"," 630: tensor([0.0447, 0.0725, 0.0913, 0.0913, 0.1000, 0.1118, 0.1291, 0.1414, 0.1414]),\n"," 631: tensor([0.0365, 0.0533, 0.0449, 0.0574, 0.0722, 0.0833, 0.0645, 0.0722, 0.1118,\n","         0.1021, 0.0884, 0.1118, 0.1021, 0.1118, 0.1118]),\n"," 632: tensor([0.0342, 0.0434, 0.0556, 0.0541, 0.0867, 0.0765, 0.0765, 0.1026, 0.0937,\n","         0.0811, 0.1026, 0.0811, 0.0811, 0.1026, 0.1026, 0.1026, 0.1026, 0.1026]),\n"," 633: tensor([0.0245, 0.0609, 0.0767, 0.0690, 0.1000, 0.1195, 0.1414, 0.0953, 0.1414]),\n"," 634: tensor([0.0274, 0.0495, 0.0645, 0.0811, 0.1118, 0.1581, 0.1581]),\n"," 635: tensor([0.0235, 0.0392, 0.0769, 0.0654, 0.0877, 0.0836, 0.0925, 0.1132, 0.1132,\n","         0.0877, 0.1132, 0.1240]),\n"," 636: tensor([0.0258, 0.0357, 0.0580, 0.0962, 0.1491, 0.1361, 0.1491, 0.1361]),\n"," 637: tensor([0.0205, 0.0472, 0.0452, 0.0583, 0.0690, 0.1010, 0.1010, 0.1091, 0.1010,\n","         0.1091, 0.1195, 0.1195, 0.1195]),\n"," 638: tensor([0.0443, 0.0645, 0.0632, 0.0745, 0.0953, 0.1000, 0.1291, 0.1054, 0.1054]),\n"," 639: tensor([0.0333, 0.0572, 0.0599, 0.0589, 0.0891, 0.1179, 0.1260, 0.1361]),\n"," 640: tensor([0.0443, 0.0690, 0.0577, 0.0577, 0.0816, 0.0716, 0.0976, 0.0913, 0.1054,\n","         0.0816, 0.1054, 0.1155, 0.1155, 0.1054]),\n"," 641: tensor([0.0361, 0.0668, 0.0606, 0.0559, 0.0833, 0.0884, 0.0884, 0.0754, 0.0833,\n","         0.0668, 0.1021, 0.0945, 0.1021, 0.1021, 0.1118]),\n"," 642: tensor([0.0174, 0.0415, 0.0577, 0.0439, 0.0745, 0.0845, 0.0745, 0.0845, 0.0707,\n","         0.0707, 0.0913, 0.0845, 0.0791, 0.0913, 0.0845, 0.0913, 0.1000, 0.1000,\n","         0.1000]),\n"," 643: tensor([0.0690, 0.0609, 0.0707, 0.0745, 0.1000, 0.1118, 0.0877, 0.0953, 0.1414]),\n"," 644: tensor([0.0680, 0.0481, 0.0891, 0.0619, 0.0786, 0.1054, 0.1111, 0.1361]),\n"," 645: tensor([0.0265, 0.0205, 0.0456, 0.0690, 0.0778, 0.0913, 0.0861, 0.0976, 0.1054,\n","         0.1054, 0.0976, 0.1155, 0.1155, 0.1155]),\n"," 646: tensor([0.0132, 0.0221, 0.0243, 0.0331, 0.0591, 0.0693, 0.0693, 0.0693, 0.0654,\n","         0.0591, 0.0801, 0.0620, 0.0741, 0.0877, 0.0693, 0.0693, 0.0741, 0.0620,\n","         0.0801, 0.0877, 0.0801, 0.0741, 0.0654, 0.0877, 0.0877]),\n"," 647: tensor([0.0240, 0.0219, 0.0262, 0.0645, 0.0778, 0.0690, 0.0745, 0.1054, 0.1054,\n","         0.1054, 0.1155, 0.0913, 0.1155, 0.1155]),\n"," 648: tensor([0.0283, 0.0407, 0.0654, 0.0861, 0.1179, 0.1260, 0.1361, 0.1491]),\n"," 649: tensor([0.0434, 0.0367, 0.0480, 0.0570, 0.1195, 0.0845, 0.0945, 0.0891, 0.1091,\n","         0.1091, 0.1091, 0.1010, 0.1195]),\n"," 650: tensor([0.0258, 0.0290, 0.0221, 0.0563, 0.0976, 0.0913, 0.0976, 0.0861, 0.1155,\n","         0.1054, 0.1155, 0.1054, 0.1155, 0.1155]),\n"," 651: tensor([0.0331, 0.0583, 0.0630, 0.0806, 0.0772, 0.0945, 0.0741, 0.0806, 0.0891,\n","         0.1010, 0.1195, 0.1195, 0.1195]),\n"," 652: tensor([0.0445, 0.0299, 0.0398, 0.0630, 0.0481, 0.0630, 0.0891, 0.1054, 0.0745,\n","         0.0609, 0.0891, 0.0786, 0.1054, 0.0891, 0.0962, 0.1054, 0.1054]),\n"," 653: tensor([0.0563, 0.0830, 0.0690, 0.1118]),\n"," 654: tensor([0.0205, 0.0550, 0.0877, 0.0707, 0.1054, 0.1195, 0.1118, 0.1414, 0.1414]),\n"," 655: tensor([0.0393, 0.0419, 0.0526, 0.0354, 0.0765, 0.0662, 0.0765, 0.0765, 0.0937,\n","         0.1026, 0.0765, 0.0937, 0.1026, 0.0937, 0.0937, 0.1026, 0.0937, 0.1026]),\n"," 656: tensor([0.0367, 0.0516, 0.0811, 0.0981, 0.1250, 0.1443, 0.1581]),\n"," 657: tensor([0.0288, 0.0620, 0.0769, 0.0636, 0.0981, 0.0925, 0.1048, 0.1240, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 658: tensor([0.0477, 0.0772, 0.0645, 0.0693, 0.0913, 0.1118, 0.1581]),\n"," 659: tensor([0.0338, 0.0765, 0.0808, 0.0861, 0.1260, 0.1491, 0.1491, 0.1491]),\n"," 660: tensor([0.0925, 0.0680, 0.1260, 0.0619, 0.1179, 0.1260, 0.1491, 0.1491]),\n"," 661: tensor([0.0371, 0.0636, 0.0555, 0.0741, 0.1048, 0.0925, 0.1132, 0.0981, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 662: tensor([0.0229, 0.0452, 0.0524, 0.0505, 0.0891, 0.0945, 0.1010, 0.1010, 0.0945,\n","         0.0945, 0.1010, 0.1091, 0.1195]),\n"," 663: tensor([0.0619, 0.0711, 0.0654, 0.0572, 0.1179, 0.1111, 0.1260, 0.1491]),\n"," 664: tensor([0.0636, 0.0566, 0.0490, 0.0462, 0.0981, 0.0673, 0.1048, 0.1240, 0.1132,\n","         0.1240, 0.1132, 0.1240]),\n"," 665: tensor([0.0340, 0.0808, 0.0606, 0.0626, 0.0857, 0.0700, 0.0700, 0.0990, 0.0808,\n","         0.0917, 0.1085, 0.0990, 0.0990, 0.0990, 0.1085, 0.1085]),\n"," 666: tensor([0.0271, 0.0406, 0.0645, 0.0472, 0.0833, 0.0722, 0.0754, 0.0833, 0.1021,\n","         0.0884, 0.1118, 0.0833, 0.1021, 0.1118, 0.1118]),\n"," 667: tensor([0.0422, 0.0259, 0.0445, 0.0731, 0.0953, 0.1140, 0.0953, 0.1231, 0.1348,\n","         0.1348]),\n"," 668: tensor([0.0450, 0.0450, 0.0578, 0.0716, 0.0801, 0.1048, 0.0981, 0.1240, 0.1240,\n","         0.1240, 0.1240, 0.1240]),\n"," 669: tensor([0.0415, 0.0425, 0.0845, 0.0917, 0.1543, 0.1429]),\n"," 670: tensor([0.0256, 0.0259, 0.0525, 0.1005, 0.0909, 0.1005, 0.1140, 0.1231, 0.1348,\n","         0.1348]),\n"," 671: tensor([0.0283, 0.0711, 0.0833, 0.1054, 0.0891, 0.1260, 0.1361, 0.1491]),\n"," 672: tensor([0.0225, 0.0333, 0.0458, 0.1054, 0.1179, 0.1491, 0.1491, 0.1491]),\n"," 673: tensor([0.0213, 0.0221, 0.0498, 0.0605, 0.0801, 0.0925, 0.1048, 0.1240, 0.0981,\n","         0.1132, 0.1240, 0.1240]),\n"," 674: tensor([0.0765, 0.1005, 0.0630, 0.0808, 0.1179, 0.1111, 0.1361, 0.1491]),\n"," 675: tensor([0.0294, 0.0471, 0.0877, 0.1000, 0.1291, 0.1118, 0.1195, 0.1414, 0.1414]),\n"," 676: tensor([0.0548, 0.0563, 0.0861, 0.0786, 0.1054, 0.1179, 0.1179, 0.1361]),\n"," 677: tensor([0.0402, 0.0568, 0.0527, 0.0707, 0.1414, 0.1000, 0.1195, 0.1414, 0.1291]),\n"," 678: tensor([0.0408, 0.0714, 0.0505, 0.0648, 0.0772, 0.1091, 0.1091, 0.1195, 0.1195,\n","         0.1195, 0.1195, 0.1091, 0.1195]),\n"," 679: tensor([0.0200, 0.0315, 0.0716, 0.0861, 0.0913, 0.0976, 0.0816, 0.0913, 0.0778,\n","         0.1155, 0.1155, 0.1155, 0.1155, 0.1054]),\n"," 680: tensor([0.0205, 0.0461, 0.0707, 0.0767, 0.0745, 0.1054, 0.1195, 0.1291, 0.1414]),\n"," 681: tensor([0.0187, 0.0488, 0.0870, 0.0801, 0.1291, 0.0913, 0.0801, 0.1291, 0.1091,\n","         0.1291, 0.1291]),\n"," 682: tensor([0.0148, 0.0377, 0.0338, 0.0450, 0.0692, 0.0811, 0.0725, 0.0692, 0.0811,\n","         0.0725, 0.0867, 0.0867, 0.0811, 0.0811, 0.1026, 0.1026, 0.1026, 0.1026]),\n"," 683: tensor([0.0233, 0.0754, 0.0615, 0.0778, 0.0953, 0.0909, 0.0909, 0.1348, 0.1348,\n","         0.1231]),\n"," 684: tensor([0.0293, 0.0658, 0.0891, 0.1336, 0.1690, 0.1690]),\n"," 685: tensor([0.0274, 0.0913, 0.0945, 0.0857, 0.0791, 0.1443, 0.1581]),\n"," 686: tensor([0.0477, 0.0657, 0.0945, 0.0884, 0.1581, 0.1118, 0.1443]),\n"," 687: tensor([0.0225, 0.0206, 0.0358, 0.0626, 0.0917, 0.0917, 0.0857, 0.0917, 0.0857,\n","         0.0731, 0.0917, 0.0990, 0.0917, 0.0990, 0.1085, 0.1085]),\n"," 688: tensor([0.0481, 0.0467, 0.0786, 0.0680, 0.1179, 0.1179, 0.1491, 0.1491]),\n"," 689: tensor([0.0489, 0.0533, 0.0465, 0.0731, 0.0731, 0.1348, 0.1066, 0.1348, 0.1348,\n","         0.1348]),\n"," 690: tensor([0.0159, 0.0344, 0.0556, 0.0654, 0.0833, 0.0962, 0.0891, 0.0786, 0.0745,\n","         0.1054, 0.0891, 0.1054, 0.0962, 0.0962, 0.1054, 0.1054, 0.1054]),\n"," 691: tensor([0.0425, 0.0825, 0.1195, 0.1260, 0.1690, 0.1543]),\n"," 692: tensor([0.0626, 0.0315, 0.0550, 0.0716, 0.0816, 0.0816, 0.0976, 0.1155, 0.1054,\n","         0.0913, 0.0976, 0.1155, 0.1155, 0.1155]),\n"," 693: tensor([0.0292, 0.0293, 0.0845, 0.0945, 0.1690, 0.1690]),\n"," 694: tensor([0.0225, 0.0497, 0.0786, 0.0680, 0.0962, 0.1491, 0.1260, 0.1361]),\n"," 695: tensor([0.0435, 0.0674, 0.0674, 0.0525, 0.0953, 0.0953, 0.1066, 0.1066, 0.1231,\n","         0.1348]),\n"," 696: tensor([0.0302, 0.0496, 0.0339, 0.0806, 0.1005, 0.1348, 0.1231, 0.1231, 0.1348,\n","         0.1140]),\n"," 697: tensor([0.0754, 0.0533, 0.0542, 0.0674, 0.0953, 0.1005, 0.1066, 0.1348, 0.1348,\n","         0.1348]),\n"," 698: tensor([0.0429, 0.0668, 0.0722, 0.0533, 0.0754, 0.0625, 0.1118, 0.0833, 0.1118,\n","         0.0722, 0.1021, 0.0833, 0.0945, 0.0945, 0.1118]),\n"," 699: tensor([0.0256, 0.0265, 0.0286, 0.1111, 0.0727, 0.1361, 0.1491, 0.1491]),\n"," 700: tensor([0.0213, 0.1054, 0.0816, 0.0953, 0.1414, 0.1195, 0.1414, 0.1414, 0.1414]),\n"," 701: tensor([0.0491, 0.0556, 0.0398, 0.0786, 0.0711, 0.0711, 0.0745, 0.0745, 0.0891,\n","         0.0962, 0.0891, 0.0745, 0.0833, 0.0833, 0.1054, 0.1054, 0.1054]),\n"," 702: tensor([0.0357, 0.0745, 0.0786, 0.1054, 0.0925, 0.1361, 0.1260, 0.1491]),\n"," 703: tensor([0.0383, 0.0570, 0.0542, 0.0591, 0.1140, 0.1005, 0.1066, 0.1348, 0.1348,\n","         0.1348]),\n"," 704: tensor([0.0331, 0.0490, 0.0334, 0.0574, 0.0791, 0.0645, 0.0833, 0.1021, 0.1021,\n","         0.1021, 0.1118, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 705: tensor([0.0234, 0.0489, 0.0778, 0.0754, 0.0870, 0.0870, 0.1348, 0.1348, 0.1231,\n","         0.1231]),\n"," 706: tensor([0.0347, 0.0568, 0.0550, 0.1000, 0.1054, 0.1054, 0.1291, 0.1291, 0.1414]),\n"," 707: tensor([0.0707, 0.0833, 0.0693, 0.0913, 0.1066, 0.1021, 0.1581]),\n"," 708: tensor([0.0410, 0.0503, 0.0462, 0.0503, 0.0833, 0.0711, 0.0891, 0.0786, 0.0786,\n","         0.0745, 0.0962, 0.0962, 0.1054, 0.0891, 0.0833, 0.0962, 0.1054]),\n"," 709: tensor([0.0273, 0.0588, 0.0517, 0.0556, 0.0626, 0.0700, 0.0808, 0.0857, 0.0808,\n","         0.0700, 0.0767, 0.1085, 0.0990, 0.1085, 0.1085, 0.1085]),\n"," 710: tensor([0.0274, 0.0465, 0.0480, 0.0648, 0.0945, 0.1091, 0.0945, 0.0845, 0.1010,\n","         0.1091, 0.1091, 0.1195, 0.1195]),\n"," 711: tensor([0.0152, 0.0556, 0.0445, 0.0745, 0.0891, 0.0745, 0.0891, 0.1054, 0.0962,\n","         0.0962, 0.0891, 0.0891, 0.1054, 0.1054, 0.0891, 0.1054, 0.1054]),\n"," 712: tensor([0.0234, 0.0465, 0.0711, 0.0754, 0.0754, 0.1348, 0.1066, 0.1348, 0.1348,\n","         0.1140]),\n"," 713: tensor([0.0497, 0.0538, 0.0456, 0.0506, 0.1054, 0.0778, 0.0913, 0.1155, 0.1155,\n","         0.1155, 0.1054, 0.1054, 0.1155, 0.1155]),\n"," 714: tensor([0.0416, 0.0443, 0.0572, 0.0556, 0.0917, 0.0990, 0.1085, 0.1085, 0.1085,\n","         0.1085, 0.0917, 0.1085, 0.1085, 0.1085, 0.0990, 0.1085]),\n"," 715: tensor([0.0265, 0.0200, 0.0861, 0.0538, 0.1054, 0.0861, 0.0816, 0.0816, 0.1155,\n","         0.0976, 0.1155, 0.1155, 0.1155, 0.1155]),\n"," 716: tensor([0.0231, 0.0195, 0.0658, 0.0643, 0.1231, 0.1066, 0.0953, 0.1348, 0.1348,\n","         0.1348]),\n"," 717: tensor([0.0630, 0.0397, 0.0722, 0.0833, 0.1179, 0.1091, 0.0913, 0.0870, 0.1291,\n","         0.1091, 0.1179]),\n"," 718: tensor([0.0556, 0.0602, 0.0722, 0.0745, 0.1091, 0.0913, 0.1021, 0.0772, 0.1179,\n","         0.1091, 0.1291]),\n"," 719: tensor([0.0271, 0.0383, 0.0456, 0.0857, 0.1179, 0.1336, 0.1581]),\n"," 720: tensor([0.1140, 0.0891, 0.0891, 0.1091, 0.1429, 0.1690]),\n"," 721: tensor([0.0481, 0.0598, 0.0884, 0.0981, 0.1179, 0.1336, 0.1581]),\n"," 722: tensor([0.0449, 0.0525, 0.0570, 0.0692, 0.1140, 0.0953, 0.1231, 0.1140, 0.1231,\n","         0.1348]),\n"," 723: tensor([0.0423, 0.0808, 0.0654, 0.1005, 0.0925, 0.1054, 0.1491, 0.1491]),\n"," 724: tensor([0.0302, 0.0426, 0.0731, 0.0711, 0.1005, 0.1348, 0.1066, 0.1231, 0.1348,\n","         0.1348]),\n"," 725: tensor([0.0439, 0.0465, 0.0891, 0.0690, 0.0806, 0.1010, 0.1010, 0.0891, 0.1091,\n","         0.1195, 0.1010, 0.1195, 0.1195]),\n"," 726: tensor([0.0213, 0.0367, 0.0981, 0.0450, 0.0693, 0.0925, 0.0877, 0.1048, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 727: tensor([0.0917, 0.0702, 0.1010, 0.0945, 0.1336, 0.1429]),\n"," 728: tensor([0.0674, 0.0609, 0.0745, 0.0816, 0.1291, 0.1195, 0.1195, 0.1414, 0.1414]),\n"," 729: tensor([0.0375, 0.0430, 0.0695, 0.0642, 0.1361, 0.1179, 0.1491, 0.1361]),\n"," 730: tensor([0.0192, 0.0259, 0.0449, 0.0395, 0.0754, 0.0833, 0.1021, 0.0693, 0.0884,\n","         0.1118, 0.0945, 0.0945, 0.1118, 0.1021, 0.1118]),\n"," 731: tensor([0.0324, 0.0271, 0.0674, 0.0953, 0.0725, 0.1054, 0.1291, 0.1414, 0.1414]),\n"," 732: tensor([0.0334, 0.0347, 0.0498, 0.0693, 0.1048, 0.1240, 0.1132, 0.1240, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 733: tensor([0.0445, 0.0945, 0.0772, 0.0884, 0.1443, 0.1179, 0.1443]),\n"," 734: tensor([0.0546, 0.0772, 0.0615, 0.0722, 0.1021, 0.1179, 0.0913, 0.1179, 0.1179,\n","         0.1179, 0.1091]),\n"," 735: tensor([0.0331, 0.0481, 0.0423, 0.0693, 0.0945, 0.0884, 0.0945, 0.1118, 0.0833,\n","         0.0833, 0.0945, 0.1021, 0.1021, 0.1021, 0.1118]),\n"," 736: tensor([0.0449, 0.0745, 0.0642, 0.0695, 0.0962, 0.0925, 0.1260, 0.1491]),\n"," 737: tensor([0.0342, 0.1179, 0.0375, 0.0962, 0.1111, 0.0962, 0.1179, 0.1491]),\n"," 738: tensor([0.1005, 0.0891, 0.0680, 0.0833, 0.1179, 0.1361, 0.1491, 0.1491]),\n"," 739: tensor([0.0213, 0.0494, 0.0845, 0.1054, 0.1291, 0.1291, 0.1414, 0.1291, 0.1414]),\n"," 740: tensor([0.0213, 0.0513, 0.0913, 0.0745, 0.1054, 0.1291, 0.1054, 0.1414, 0.1291]),\n"," 741: tensor([0.0632, 0.0745, 0.0845, 0.0659, 0.0845, 0.1054, 0.1291, 0.1414, 0.1414]),\n"," 742: tensor([0.0456, 0.0566, 0.0636, 0.0693, 0.1048, 0.1048, 0.1240, 0.1048, 0.1240,\n","         0.1048, 0.1240, 0.1240]),\n"," 743: tensor([0.0195, 0.0426, 0.0680, 0.0566, 0.0962, 0.0745, 0.1291, 0.1021, 0.0870,\n","         0.1179, 0.0962]),\n"," 744: tensor([0.0203, 0.0643, 0.0806, 0.0731, 0.1140, 0.1005, 0.1231, 0.1066, 0.1005,\n","         0.1348]),\n"," 745: tensor([0.0293, 0.0430, 0.0488, 0.0700, 0.1021, 0.0962, 0.0833, 0.1179, 0.0962,\n","         0.1091, 0.1291]),\n"," 746: tensor([0.0256, 0.0216, 0.0430, 0.0833, 0.1260, 0.1179, 0.0861, 0.1491]),\n"," 747: tensor([0.0503, 0.0680, 0.0630, 0.0772, 0.1179, 0.0870, 0.1091, 0.1091, 0.1179,\n","         0.1291, 0.1291]),\n"," 748: tensor([0.0510, 0.0477, 0.0711, 0.0909, 0.1005, 0.1005, 0.1231, 0.1231, 0.1231,\n","         0.1348]),\n"," 749: tensor([0.0937, 0.0870, 0.0990, 0.0870, 0.1826]),\n"," 750: tensor([0.0408, 0.0495, 0.0417, 0.0546, 0.0645, 0.0722, 0.0772, 0.0772, 0.0589,\n","         0.0680, 0.0833, 0.0833, 0.0772, 0.0722, 0.0913, 0.0913, 0.0680, 0.0913,\n","         0.0833, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 751: tensor([0.0520, 0.0535, 0.0816, 0.0791, 0.0953, 0.1118, 0.1414, 0.1414, 0.1414]),\n"," 752: tensor([0.0245, 0.0513, 0.0402, 0.1000, 0.0816, 0.1118, 0.1118, 0.1414, 0.1414]),\n"," 753: tensor([0.0390, 0.0398, 0.0390, 0.0772, 0.0845, 0.1195, 0.1010, 0.1091, 0.0806,\n","         0.1091, 0.1010, 0.0945, 0.1195]),\n"," 754: tensor([0.0913, 0.0772, 0.0722, 0.0913, 0.1443, 0.1021, 0.1443]),\n"," 755: tensor([0.0145, 0.0174, 0.0349, 0.0423, 0.0559, 0.0620, 0.0745, 0.0913, 0.0745,\n","         0.0845, 0.0707, 0.1000, 0.0791, 0.0845, 0.0913, 0.0913, 0.0845, 0.1000,\n","         0.0913]),\n"," 756: tensor([0.0680, 0.0635, 0.0754, 0.0657, 0.1443, 0.1581, 0.1581]),\n"," 757: tensor([0.0364, 0.0496, 0.0301, 0.0570, 0.1195, 0.1010, 0.0891, 0.1091, 0.1010,\n","         0.1010, 0.1010, 0.1195, 0.1195]),\n"," 758: tensor([0.0447, 0.0447, 0.0577, 0.0725, 0.1195, 0.1118, 0.1291, 0.1414, 0.1414]),\n"," 759: tensor([0.0199, 0.0429, 0.0449, 0.0722, 0.0945, 0.0693, 0.0945, 0.0833, 0.0693,\n","         0.0945, 0.1021, 0.0945, 0.1021, 0.1118, 0.1118]),\n"," 760: tensor([0.0230, 0.0722, 0.0645, 0.0870, 0.0913, 0.0962, 0.0870, 0.0962, 0.0962,\n","         0.1091, 0.1091]),\n"," 761: tensor([0.0342, 0.0486, 0.0521, 0.0745, 0.1260, 0.1179, 0.1179, 0.1111]),\n"," 762: tensor([0.0225, 0.0430, 0.0589, 0.0765, 0.0861, 0.1260, 0.1491, 0.1491]),\n"," 763: tensor([0.0324, 0.0461, 0.0725, 0.0577, 0.1291, 0.1118, 0.1000, 0.1414, 0.1414]),\n"," 764: tensor([0.0267, 0.0364, 0.0535, 0.0714, 0.0891, 0.1010, 0.0741, 0.1091, 0.1091,\n","         0.1091, 0.1091, 0.1195, 0.1195]),\n"," 765: tensor([0.0359, 0.0495, 0.0857, 0.0857, 0.1179, 0.1250, 0.1443]),\n"," 766: tensor([0.0488, 0.0772, 0.1195, 0.1336, 0.1336, 0.1543]),\n"," 767: tensor([0.0327, 0.0434, 0.0334, 0.0505, 0.0945, 0.1010, 0.1010, 0.1091, 0.1195,\n","         0.1195, 0.0845, 0.1195, 0.1195]),\n"," 768: tensor([0.0234, 0.0323, 0.0550, 0.0953, 0.1140, 0.0836, 0.1140, 0.1005, 0.1231,\n","         0.1348]),\n"," 769: tensor([0.0289, 0.0503, 0.0619, 0.0891, 0.1179, 0.1491, 0.1491, 0.1491]),\n"," 770: tensor([0.0224, 0.0293, 0.0536, 0.0870, 0.1179, 0.1091, 0.0870, 0.1021, 0.1091,\n","         0.1291, 0.1291]),\n"," 771: tensor([0.0510, 0.0945, 0.1336, 0.0884, 0.1336, 0.1581, 0.1581]),\n"," 772: tensor([0.0621, 0.0867, 0.0891, 0.0917, 0.1543, 0.1429]),\n"," 773: tensor([0.0587, 0.0632, 0.0620, 0.0559, 0.1000, 0.1195, 0.1414, 0.1414, 0.1291]),\n"," 774: tensor([0.0976, 0.0741, 0.0976, 0.1048, 0.1429, 0.1336]),\n"," 775: tensor([0.0213, 0.0205, 0.0659, 0.0745, 0.1118, 0.1000, 0.0877, 0.1414, 0.1414]),\n"," 776: tensor([0.0275, 0.0645, 0.0870, 0.1054, 0.1826]),\n"," 777: tensor([0.0328, 0.0707, 0.0645, 0.1118, 0.1118, 0.1179, 0.1443]),\n"," 778: tensor([0.0464, 0.0625, 0.0472, 0.0559, 0.0722, 0.0668, 0.0945, 0.1021, 0.1118,\n","         0.1021, 0.1118, 0.1118, 0.1021, 0.1021, 0.1118]),\n"," 779: tensor([0.0213, 0.0430, 0.0408, 0.1054, 0.1195, 0.0953, 0.1291, 0.1000, 0.1118]),\n"," 780: tensor([0.0422, 0.0588, 0.0410, 0.0731, 0.0808, 0.0588, 0.0917, 0.0731, 0.0857,\n","         0.1085, 0.0917, 0.0990, 0.0857, 0.1085, 0.1085, 0.1085]),\n"," 781: tensor([0.0309, 0.0541, 0.0445, 0.0833, 0.1111, 0.1260, 0.1361, 0.1491]),\n"," 782: tensor([0.0472, 0.0680, 0.0791, 0.1118, 0.1250, 0.1443, 0.1581]),\n"," 783: tensor([0.0378, 0.0648, 0.0648, 0.0690, 0.0806, 0.0891, 0.0772, 0.1010, 0.1195,\n","         0.1195, 0.1010, 0.1195, 0.1091]),\n"," 784: tensor([0.0213, 0.0245, 0.0535, 0.0845, 0.1291, 0.1414, 0.1054, 0.0953, 0.1291]),\n"," 785: tensor([0.0205, 0.0374, 0.0613, 0.0630, 0.0690, 0.0945, 0.0690, 0.1091, 0.1091,\n","         0.1195, 0.1010, 0.1195, 0.1195]),\n"," 786: tensor([0.1048, 0.0945, 0.0976, 0.0945, 0.1543, 0.1690]),\n"," 787: tensor([0.0162, 0.0445, 0.0408, 0.0481, 0.0913, 0.0546, 0.0833, 0.0589, 0.0833,\n","         0.0833, 0.0913, 0.0772, 0.0913, 0.0645, 0.0772, 0.0833, 0.0833, 0.0913,\n","         0.0833, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 788: tensor([0.0449, 0.0581, 0.1066, 0.0981, 0.1581, 0.1581, 0.1581]),\n"," 789: tensor([0.0589, 0.0572, 0.0833, 0.1111, 0.1491, 0.1361, 0.1491, 0.1491]),\n"," 790: tensor([0.0448, 0.0937, 0.0870, 0.1179, 0.1443]),\n"," 791: tensor([0.0213, 0.0179, 0.0358, 0.0591, 0.0981, 0.1132, 0.1132, 0.1048, 0.1048,\n","         0.1240, 0.1240, 0.1240]),\n"," 792: tensor([0.0300, 0.0693, 0.0945, 0.0884, 0.1250, 0.1581, 0.1581]),\n"," 793: tensor([0.0392, 0.0557, 0.0727, 0.1429, 0.1429, 0.1690]),\n"," 794: tensor([0.0309, 0.0861, 0.0680, 0.0891, 0.0925, 0.1111, 0.1491, 0.1491]),\n"," 795: tensor([0.0179, 0.0221, 0.0605, 0.0981, 0.0836, 0.0769, 0.0925, 0.0981, 0.1240,\n","         0.1132, 0.1240, 0.1240]),\n"," 796: tensor([0.0229, 0.0495, 0.0722, 0.1179, 0.1250, 0.0945, 0.1581]),\n"," 797: tensor([0.0417, 0.0471, 0.0680, 0.0727, 0.1054, 0.1260, 0.1491, 0.1361]),\n"," 798: tensor([0.0317, 0.0711, 0.0733, 0.1091, 0.1826]),\n"," 799: tensor([0.0466, 0.0443, 0.0632, 0.0645, 0.1195, 0.1195, 0.1118, 0.1118, 0.1414]),\n"," 800: tensor([0.0200, 0.0362, 0.0403, 0.0816, 0.1054, 0.0976, 0.0778, 0.0690, 0.1155,\n","         0.1155, 0.1155, 0.0976, 0.1155, 0.1155]),\n"," 801: tensor([0.0267, 0.0345, 0.0524, 0.0668, 0.1010, 0.1010, 0.1195, 0.0891, 0.1195,\n","         0.1195, 0.1195, 0.1195, 0.1195]),\n"," 802: tensor([0.0200, 0.0362, 0.0351, 0.0479, 0.0816, 0.0976, 0.0976, 0.0976, 0.1155,\n","         0.0861, 0.0861, 0.1155, 0.1155, 0.1155]),\n"," 803: tensor([0.0404, 0.0536, 0.0630, 0.0680, 0.0722, 0.0833, 0.1091, 0.1291, 0.1021,\n","         0.1091, 0.1291]),\n"," 804: tensor([0.0498, 0.0981, 0.0836, 0.0693, 0.1048, 0.0925, 0.0836, 0.1132, 0.0877,\n","         0.1048, 0.1240, 0.1240]),\n"," 805: tensor([0.1021, 0.0662, 0.0816, 0.0990, 0.1443]),\n"," 806: tensor([0.0674, 0.0435, 0.0711, 0.0643, 0.1066, 0.0836, 0.1005, 0.1231, 0.1348,\n","         0.1348]),\n"," 807: tensor([0.0438, 0.0602, 0.0913, 0.1091, 0.1826]),\n"," 808: tensor([0.0351, 0.0639, 0.0867, 0.0917, 0.1690, 0.1543]),\n"," 809: tensor([0.0312, 0.0693, 0.0605, 0.0654, 0.0877, 0.1132, 0.1132, 0.1132, 0.1240,\n","         0.1240, 0.1240, 0.1240]),\n"," 810: tensor([0.0423, 0.0572, 0.0962, 0.1054, 0.1443]),\n"," 811: tensor([0.0406, 0.0343, 0.0693, 0.0589, 0.1118, 0.0645, 0.1118, 0.1118, 0.1021,\n","         0.1021, 0.1118, 0.1118, 0.1118, 0.1021, 0.1021]),\n"," 812: tensor([0.0410, 0.0496, 0.0658, 0.0679, 0.1690, 0.1690]),\n"," 813: tensor([0.0194, 0.0361, 0.0340, 0.0668, 0.0884, 0.0833, 0.0884, 0.1118, 0.1021,\n","         0.0945, 0.0884, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 814: tensor([0.0625, 0.0668, 0.0857, 0.1066, 0.1581, 0.1443, 0.1581]),\n"," 815: tensor([0.0456, 0.1066, 0.0811, 0.0833, 0.1250, 0.1250, 0.1581]),\n"," 816: tensor([0.0525, 0.0306, 0.0806, 0.0836, 0.1231, 0.1231, 0.1231, 0.0953, 0.1140,\n","         0.1348]),\n"," 817: tensor([0.0311, 0.0284, 0.0326, 0.0466, 0.0788, 0.0737, 0.0737, 0.0737, 0.0659,\n","         0.0851, 0.0933, 0.0557, 0.0788, 0.0933, 0.0851, 0.0933, 0.0737, 0.0851,\n","         0.0933, 0.0933, 0.0851, 0.0933]),\n"," 818: tensor([0.0559, 0.0857, 0.1443, 0.0981, 0.1581, 0.1581, 0.1581]),\n"," 819: tensor([0.0745, 0.0527, 0.0620, 0.0913, 0.0767, 0.1291, 0.1414, 0.1414, 0.1291]),\n"," 820: tensor([0.0491, 0.0745, 0.0962, 0.1231, 0.1826]),\n"," 821: tensor([0.0418, 0.0388, 0.0469, 0.0693, 0.0836, 0.1132, 0.0877, 0.1132, 0.1132,\n","         0.0981, 0.1240, 0.1240]),\n"," 822: tensor([0.0305, 0.0589, 0.0884, 0.0625, 0.0722, 0.0754, 0.0945, 0.1021, 0.0791,\n","         0.1118, 0.0945, 0.0945, 0.1118, 0.1118, 0.1118]),\n"," 823: tensor([0.0707, 0.1085, 0.1000, 0.1026]),\n"," 824: tensor([0.0309, 0.0745, 0.0962, 0.0833, 0.1260, 0.1361, 0.1491, 0.1491]),\n"," 825: tensor([0.0309, 0.0560, 0.0692, 0.0711, 0.1140, 0.1005, 0.1231, 0.1140, 0.1348,\n","         0.1348]),\n"," 826: tensor([0.0330, 0.0404, 0.0330, 0.0454, 0.0745, 0.0711, 0.0786, 0.0711, 0.1054,\n","         0.0745, 0.0962, 0.0833, 0.0962, 0.1054, 0.0962, 0.0962, 0.1054]),\n"," 827: tensor([0.0147, 0.0277, 0.0345, 0.0690, 0.0514, 0.0630, 0.0605, 0.0825, 0.0825,\n","         0.0772, 0.0825, 0.0825, 0.0976, 0.0976, 0.0976, 0.0891, 0.0891, 0.0976,\n","         0.0976, 0.0976]),\n"," 828: tensor([0.0494, 0.0632, 0.0659, 0.0953, 0.1291, 0.1118, 0.1414, 0.1195, 0.1414]),\n"," 829: tensor([0.0591, 0.0836, 0.0741, 0.0741, 0.0801, 0.0925, 0.1048, 0.1048, 0.1132,\n","         0.0925, 0.1132, 0.1240]),\n"," 830: tensor([0.0274, 0.0690, 0.0707, 0.0791, 0.1414, 0.1291, 0.1414, 0.1195, 0.1414]),\n"," 831: tensor([0.0461, 0.0513, 0.0659, 0.0725, 0.0913, 0.1054, 0.1195, 0.1414, 0.1291]),\n"," 832: tensor([0.0581, 0.0981, 0.0693, 0.0693, 0.1250, 0.1179, 0.1336]),\n"," 833: tensor([0.1091, 0.0727, 0.0639, 0.0945, 0.1690, 0.1543]),\n"," 834: tensor([0.0240, 0.0374, 0.0471, 0.0383, 0.1140, 0.1066, 0.1231, 0.1231, 0.1348,\n","         0.1231]),\n"," 835: tensor([0.0654, 0.0833, 0.1005, 0.0727, 0.1260, 0.1054, 0.1361, 0.1491]),\n"," 836: tensor([0.0621, 0.0510, 0.0867, 0.0741, 0.1429, 0.1690]),\n"," 837: tensor([0.0454, 0.0481, 0.0423, 0.1005, 0.0925, 0.1111, 0.1260, 0.1491]),\n"," 838: tensor([0.0658, 0.1140, 0.0754, 0.0806, 0.0870, 0.1140, 0.1348, 0.1066, 0.0870,\n","         0.1348]),\n"," 839: tensor([0.0754, 0.0857, 0.0722, 0.1118, 0.1336, 0.1443, 0.1581]),\n"," 840: tensor([0.1155, 0.1118, 0.1195, 0.1414]),\n"," 841: tensor([0.0659, 0.0550, 0.0577, 0.0745, 0.1195, 0.1291, 0.1195, 0.1414, 0.1414]),\n"," 842: tensor([0.0356, 0.0587, 0.0690, 0.0816, 0.1054, 0.1291, 0.1291, 0.1414, 0.1291]),\n"," 843: tensor([0.0324, 0.1054, 0.0816, 0.0845, 0.1054, 0.1414, 0.1414, 0.1195, 0.1195]),\n"," 844: tensor([0.0215, 0.0534, 0.0654, 0.0716, 0.1048, 0.1240, 0.1132, 0.1240, 0.1132,\n","         0.1240, 0.1240, 0.1240]),\n"," 845: tensor([0.0563, 0.0546, 0.0630, 0.0501, 0.0772, 0.0658, 0.0727, 0.0891, 0.0772,\n","         0.0976, 0.0772, 0.0825, 0.0891, 0.0825, 0.0976, 0.0976, 0.0891, 0.0976,\n","         0.0976, 0.0976]),\n"," 846: tensor([0.0861, 0.1026, 0.1118, 0.1000]),\n"," 847: tensor([0.0348, 0.0861, 0.0626, 0.0690, 0.0816, 0.1155, 0.0976, 0.1054, 0.0716,\n","         0.0913, 0.1054, 0.1155, 0.1155, 0.1155]),\n"," 848: tensor([0.0679, 0.0945, 0.0917, 0.1048, 0.1140, 0.1690]),\n"," 849: tensor([0.0765, 0.0833, 0.1054, 0.1111, 0.1054, 0.1361, 0.1361, 0.1361]),\n"," 850: tensor([0.0521, 0.0390, 0.0625, 0.0754, 0.0722, 0.0833, 0.1021, 0.1021, 0.0884,\n","         0.1118, 0.0945, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 851: tensor([0.0581, 0.0456, 0.0693, 0.0772, 0.1336, 0.1443, 0.1443]),\n"," 852: tensor([0.0373, 0.0495, 0.0700, 0.0962, 0.1291, 0.1091, 0.0913, 0.0962, 0.1291,\n","         0.1291, 0.1291]),\n"," 853: tensor([0.0277, 0.0534, 0.1048, 0.0566, 0.0981, 0.0981, 0.0981, 0.1240, 0.1240,\n","         0.1132, 0.1240, 0.1240]),\n"," 854: tensor([0.0401, 0.0765, 0.0833, 0.0891, 0.1179, 0.1361, 0.1111, 0.1361]),\n"," 855: tensor([0.0572, 0.0891, 0.0816, 0.1443, 0.1291]),\n"," 856: tensor([0.0731, 0.0711, 0.0692, 0.0692, 0.1005, 0.1140, 0.1066, 0.1348, 0.1348,\n","         0.1348]),\n"," 857: tensor([0.0429, 0.0546, 0.0533, 0.0722, 0.1118, 0.0754, 0.0945, 0.1021, 0.0945,\n","         0.1021, 0.1118, 0.1118, 0.1118, 0.1118, 0.1118]),\n"," 858: tensor([0.0454, 0.0619, 0.0962, 0.0833, 0.1361, 0.1361, 0.1260, 0.1491]),\n"," 859: tensor([0.0568, 0.0500, 0.0609, 0.0725, 0.1195, 0.1291, 0.1414, 0.1414, 0.1291]),\n"," 860: tensor([0.0443, 0.0423, 0.0707, 0.0707, 0.0877, 0.0877, 0.1291, 0.1054, 0.1291]),\n"," 861: tensor([0.0229, 0.0477, 0.0811, 0.0811, 0.1179, 0.1581, 0.1336]),\n"," 862: tensor([0.0489, 0.0711, 0.0731, 0.0711, 0.1140, 0.0731, 0.1140, 0.1231, 0.1066,\n","         0.1348]),\n"," 863: tensor([0.1155, 0.1240, 0.0803, 0.0913]),\n"," 864: tensor([0.0648, 0.0546, 0.0891, 0.0546, 0.1091, 0.1091, 0.1091, 0.1195, 0.1091,\n","         0.0891, 0.1091, 0.1195, 0.1195]),\n"," 865: tensor([0.0256, 0.0642, 0.0962, 0.0563, 0.1179, 0.1361, 0.1361, 0.1179]),\n"," 866: tensor([0.0472, 0.1195, 0.0976, 0.1260, 0.1429, 0.1690]),\n"," 867: tensor([0.0598, 0.0725, 0.0745, 0.0845, 0.1000, 0.1291, 0.1291, 0.1291, 0.1414]),\n"," 868: tensor([0.0238, 0.0635, 0.0945, 0.0884, 0.0791, 0.1581, 0.1581]),\n"," 869: tensor([0.0538, 0.0609, 0.0816, 0.0592, 0.0690, 0.0550, 0.0861, 0.0667, 0.1155,\n","         0.0976, 0.1155, 0.1155, 0.1054, 0.1155]),\n"," 870: tensor([0.0587, 0.1000, 0.1000, 0.0725, 0.1195, 0.0953, 0.1195, 0.1414, 0.1291]),\n"," 871: tensor([0.0245, 0.0527, 0.0577, 0.0772, 0.1091, 0.1291, 0.1291, 0.1179, 0.1291,\n","         0.1291, 0.1291]),\n"," 872: tensor([0.0303, 0.0527, 0.0833, 0.0833, 0.1250, 0.1443, 0.1336]),\n"," 873: tensor([0.0606, 0.0645, 0.0772, 0.0833, 0.1443, 0.1581, 0.1336]),\n"," 874: tensor([0.0264, 0.0937, 0.0913, 0.1054, 0.1231]),\n"," 875: tensor([0.0476, 0.0312, 0.0620, 0.0693, 0.1132, 0.1132, 0.0925, 0.1048, 0.1240,\n","         0.1048, 0.1240, 0.1132]),\n"," 876: tensor([0.0449, 0.0422, 0.0407, 0.0533, 0.1231, 0.0806, 0.1140, 0.1348, 0.1140,\n","         0.1348]),\n"," 877: tensor([0.0245, 0.0791, 0.1291, 0.0816, 0.0845, 0.1291, 0.1414, 0.1414, 0.1291]),\n"," 878: tensor([0.0621, 0.0772, 0.0891, 0.0945, 0.1195, 0.1140]),\n"," 879: tensor([0.1336, 0.0714, 0.0891, 0.1010, 0.1336, 0.1543]),\n"," 880: tensor([0.0471, 0.0609, 0.0711, 0.0962, 0.1361, 0.1361, 0.1361, 0.1361]),\n"," 881: tensor([0.0449, 0.0550, 0.0674, 0.0615, 0.1005, 0.0754, 0.1066, 0.1066, 0.1140,\n","         0.1348]),\n"," 882: tensor([0.0435, 0.0426, 0.0510, 0.0772, 0.1179, 0.0772, 0.0870, 0.1021, 0.0962,\n","         0.1091, 0.1179]),\n"," 883: tensor([0.0538, 0.1118, 0.1195, 0.1195]),\n"," 884: tensor([0.0402, 0.0577, 0.0645, 0.0816, 0.1195, 0.0845, 0.1195, 0.1195, 0.1414]),\n"," 885: tensor([0.0328, 0.0702, 0.0867, 0.1260, 0.1690, 0.1690]),\n"," 886: tensor([0.0292, 0.0318, 0.0423, 0.0572, 0.0833, 0.0891, 0.0786, 0.0962, 0.0609,\n","         0.1054, 0.0962, 0.0891, 0.0891, 0.1054, 0.1054, 0.1054, 0.1054]),\n"," 887: tensor([0.0408, 0.0758, 0.0690, 0.1179, 0.1826]),\n"," 888: tensor([0.0745, 0.0962, 0.0925, 0.1054, 0.1179, 0.1361, 0.1491, 0.1491]),\n"," 889: tensor([0.0519, 0.0639, 0.0891, 0.0825, 0.1336, 0.1690]),\n"," 890: tensor([0.0267, 0.0301, 0.0398, 0.0845, 0.0806, 0.1010, 0.1010, 0.1010, 0.1010,\n","         0.0845, 0.1091, 0.1091, 0.1195]),\n"," 891: tensor([0.0410, 0.0445, 0.0870, 0.0806, 0.0870, 0.1066, 0.0953, 0.1231, 0.1231,\n","         0.1348]),\n"," 892: tensor([0.0231, 0.0380, 0.0674, 0.0778, 0.0953, 0.0836, 0.1066, 0.1348, 0.1348,\n","         0.1348]),\n"," 893: tensor([0.0264, 0.0990, 0.0662, 0.1054, 0.1826]),\n"," 894: tensor([0.0350, 0.0246, 0.0857, 0.0673, 0.0990, 0.0917, 0.1085, 0.0857, 0.0767,\n","         0.0917, 0.1085, 0.1085, 0.0990, 0.0990, 0.1085, 0.1085]),\n"," 895: tensor([0.0356, 0.0620, 0.0877, 0.1054, 0.1118, 0.1195, 0.1054, 0.1195, 0.1414]),\n"," 896: tensor([0.0556, 0.0248, 0.1021, 0.0722, 0.1091, 0.1021, 0.1291, 0.1091, 0.1179,\n","         0.1179, 0.1291]),\n"," 897: tensor([0.0294, 0.0245, 0.0461, 0.0913, 0.1000, 0.1414, 0.1118, 0.1291, 0.1195]),\n"," 898: tensor([0.0516, 0.0693, 0.1021, 0.1179, 0.0791, 0.1250, 0.1581]),\n"," 899: tensor([0.0274, 0.0811, 0.0945, 0.0857, 0.1179, 0.1443, 0.1443]),\n"," 900: tensor([0.0707, 0.1000, 0.0767, 0.1054, 0.1291, 0.0953, 0.1054, 0.1291, 0.1414]),\n"," 901: tensor([0.0548, 0.1054, 0.1111, 0.0727, 0.1361, 0.1260, 0.1491, 0.1491]),\n"," 902: tensor([0.0214, 0.0369, 0.0833, 0.0693, 0.0791, 0.0791, 0.1021, 0.0754, 0.0791,\n","         0.1118, 0.0791, 0.1021, 0.1118, 0.1118, 0.1118]),\n"," 903: tensor([0.0599, 0.0521, 0.1111, 0.1054, 0.1111, 0.1491, 0.1361, 0.1491]),\n"," 904: tensor([0.0529, 0.0679, 0.0945, 0.1140, 0.1260, 0.1690]),\n"," 905: tensor([0.0398, 0.0481, 0.0722, 0.1021, 0.1250, 0.1250, 0.1581]),\n"," 906: tensor([0.0238, 0.0635, 0.0811, 0.1179, 0.1179, 0.1179, 0.1443]),\n"," 907: tensor([0.0392, 0.0443, 0.0542, 0.0690, 0.1414, 0.1195, 0.1414, 0.1414, 0.1414]),\n"," 908: tensor([0.0255, 0.0259, 0.0331, 0.0345, 0.0680, 0.0527, 0.0680, 0.0527, 0.0680,\n","         0.0833, 0.0833, 0.0589, 0.0589, 0.0913, 0.0833, 0.0722, 0.0833, 0.0913,\n","         0.0913, 0.0913, 0.0913, 0.0913, 0.0913]),\n"," 909: tensor([0.0173, 0.0613, 0.0630, 0.0690, 0.1010, 0.1010, 0.0845, 0.0806, 0.0845,\n","         0.0945, 0.1195, 0.1195, 0.1195]),\n"," 910: tensor([0.0215, 0.0534, 0.0605, 0.0741, 0.0925, 0.0741, 0.1048, 0.1240, 0.1240,\n","         0.1132, 0.1048, 0.1240]),\n"," 911: tensor([0.0333, 0.0430, 0.0491, 0.0514, 0.0891, 0.1054, 0.0962, 0.0833, 0.1054,\n","         0.0891, 0.0891, 0.0891, 0.1054, 0.1054, 0.1054, 0.0962, 0.1054]),\n"," 912: tensor([0.0274, 0.0635, 0.0833, 0.1118, 0.1443, 0.1443, 0.1336]),\n"," 913: tensor([0.0674, 0.0659, 0.0690, 0.0791, 0.1414, 0.1195, 0.1414, 0.1414, 0.1291]),\n"," 914: tensor([0.0317, 0.0645, 0.0745, 0.0589, 0.1021, 0.0833, 0.0913, 0.0745, 0.1291,\n","         0.1291, 0.1291]),\n"," 915: tensor([0.0327, 0.0692, 0.1066, 0.0711, 0.1005, 0.0953, 0.1066, 0.1348, 0.1140,\n","         0.1348]),\n"," 916: tensor([0.1021, 0.1231, 0.0786, 0.1543, 0.1826]),\n"," 917: tensor([0.0615, 0.0680, 0.0791, 0.0884, 0.1336, 0.1581, 0.1581]),\n"," 918: tensor([0.0346, 0.0503, 0.1005, 0.1005, 0.1179, 0.0833, 0.1111, 0.1179]),\n"," 919: tensor([0.0816, 0.0894, 0.1000, 0.1414]),\n"," 920: tensor([0.0516, 0.0495, 0.0791, 0.1021, 0.1250, 0.1179, 0.1250]),\n"," 921: tensor([0.0194, 0.0212, 0.0481, 0.0395, 0.0945, 0.0754, 0.0833, 0.0693, 0.0833,\n","         0.0884, 0.0884, 0.1021, 0.1021, 0.1021, 0.1118]),\n"," 922: tensor([0.0269, 0.0445, 0.0455, 0.0550, 0.0674, 0.0489, 0.0870, 0.0953, 0.0711,\n","         0.0754, 0.0754, 0.0806, 0.0806, 0.0870, 0.0754, 0.0953, 0.0953, 0.0953,\n","         0.0953, 0.0870, 0.0953]),\n"," 923: tensor([0.0520, 0.0577, 0.0877, 0.0953, 0.1118, 0.0877, 0.1000, 0.1291, 0.1414]),\n"," 924: tensor([0.0225, 0.0786, 0.1179, 0.0680, 0.0861, 0.1111, 0.1179, 0.1491]),\n"," 925: tensor([0.0316, 0.0937, 0.0758, 0.0891, 0.1543]),\n"," 926: tensor([0.0791, 0.0657, 0.0913, 0.0913, 0.1336, 0.1118, 0.1581]),\n"," 927: tensor([0.0290, 0.1336, 0.0825, 0.1140, 0.1336, 0.1690]),\n"," 928: tensor([0.0472, 0.0613, 0.0891, 0.0917, 0.1543, 0.1690]),\n"," 929: tensor([0.1066, 0.0737, 0.0707, 0.0981, 0.1066, 0.1336, 0.1581]),\n"," 930: tensor([0.0477, 0.0581, 0.0945, 0.0913, 0.1118, 0.1581, 0.1581]),\n"," 931: tensor([0.0259, 0.0454, 0.0375, 0.0745, 0.1361, 0.1179, 0.1260, 0.1260]),\n"," 932: tensor([0.0495, 0.0546, 0.0945, 0.1021, 0.1336, 0.1336, 0.1581]),\n"," 933: tensor([0.0806, 0.0590, 0.0845, 0.0714, 0.1195, 0.1690]),\n"," 934: tensor([0.0307, 0.0500, 0.0521, 0.1250, 0.1250, 0.1336, 0.1443]),\n"," 935: tensor([0.0521, 0.0625, 0.0884, 0.1250, 0.1066, 0.1250, 0.1443]),\n"," 936: tensor([0.0200, 0.0577, 0.0609, 0.0563, 0.0861, 0.1054, 0.1155, 0.0861, 0.1155,\n","         0.0976, 0.1054, 0.1155, 0.1155, 0.1155]),\n"," 937: tensor([0.0630, 0.0816, 0.1443, 0.1443, 0.1667]),\n"," 938: tensor([0.0223, 0.0389, 0.0680, 0.0962, 0.1021, 0.1179, 0.1091, 0.1291, 0.1291,\n","         0.1291, 0.1291]),\n"," 939: tensor([0.0264, 0.0745, 0.0801, 0.0962, 0.1826]),\n"," 940: tensor([0.0615, 0.0503, 0.0909, 0.1140, 0.0909, 0.0778, 0.1140, 0.1348, 0.1066,\n","         0.1231]),\n"," 941: tensor([0.0494, 0.0913, 0.0913, 0.0877, 0.1054, 0.1054, 0.1054, 0.1054, 0.1000]),\n"," 942: tensor([0.0385, 0.0690, 0.0745, 0.0527, 0.0976, 0.0861, 0.0976, 0.0861, 0.0745,\n","         0.1054, 0.1155, 0.1054, 0.1054, 0.1155]),\n"," 943: tensor([0.0245, 0.0443, 0.0632, 0.1054, 0.1118, 0.1414, 0.1414, 0.1414, 0.1291]),\n"," 944: tensor([0.0392, 0.0976, 0.1195, 0.1195, 0.1429, 0.1195]),\n"," 945: tensor([0.0344, 0.0469, 0.0925, 0.0836, 0.0925, 0.1048, 0.1240, 0.1240, 0.1048,\n","         0.1240, 0.1048, 0.1240]),\n"," 946: tensor([0.0497, 0.0626, 0.0645, 0.0861, 0.0913, 0.1155, 0.0816, 0.0976, 0.1054,\n","         0.1155, 0.1155, 0.0913, 0.1155, 0.1155]),\n"," 947: tensor([0.0258, 0.0407, 0.0808, 0.0808, 0.1491, 0.1361, 0.1361, 0.1361]),\n"," 948: tensor([0.0568, 0.1195, 0.1195, 0.1414]),\n"," 949: tensor([0.0281, 0.0615, 0.0657, 0.1179, 0.1179, 0.1443, 0.1581]),\n"," 950: tensor([0.0674, 0.0609, 0.0791, 0.1195, 0.1054, 0.1414, 0.1195, 0.1291, 0.1414]),\n"," 951: tensor([0.0363, 0.0398, 0.0645, 0.0772, 0.1443, 0.1581, 0.1581]),\n"," 952: tensor([0.0255, 0.0292, 0.0476, 0.0563, 0.1429, 0.1690]),\n"," 953: tensor([0.0195, 0.0546, 0.0870, 0.0630, 0.1179, 0.1179, 0.1291, 0.1179, 0.1291,\n","         0.1179, 0.1291]),\n"," 954: tensor([0.0223, 0.0224, 0.0722, 0.0772, 0.0962, 0.1021, 0.1021, 0.0833, 0.0913,\n","         0.1291, 0.1291]),\n"," 955: tensor([0.0205, 0.0434, 0.0620, 0.0632, 0.1291, 0.0877, 0.1118, 0.1291, 0.1414]),\n"," 956: tensor([0.0346, 0.0589, 0.0833, 0.1179, 0.1111, 0.1491, 0.1491, 0.1361]),\n"," 957: tensor([0.0449, 0.0690, 0.0538, 0.0913, 0.0778, 0.0667, 0.1054, 0.1155, 0.0976,\n","         0.1054, 0.0861, 0.0976, 0.1155, 0.1155]),\n"," 958: tensor([0.0467, 0.0542, 0.0542, 0.0767, 0.0857, 0.0990, 0.1085, 0.0990, 0.0917,\n","         0.0857, 0.1085, 0.1085, 0.0917, 0.1085, 0.1085, 0.1085]),\n"," 959: tensor([0.0268, 0.0397, 0.0468, 0.0630, 0.1091, 0.0913, 0.0833, 0.1091, 0.1291,\n","         0.1091, 0.1179]),\n"," 960: tensor([0.0290, 0.0529, 0.0514, 0.1048, 0.1260, 0.1543]),\n"," 961: tensor([0.0281, 0.0635, 0.0635, 0.0981, 0.1443, 0.1443, 0.1581]),\n"," 962: tensor([0.1010, 0.0806, 0.1195, 0.0945, 0.1195, 0.1195]),\n"," 963: tensor([0.0877, 0.0791, 0.0745, 0.1000, 0.1000, 0.1414, 0.1414, 0.1414, 0.1414]),\n"," 964: tensor([0.0321, 0.0786, 0.0572, 0.0654, 0.0541, 0.0745, 0.0891, 0.0891, 0.0680,\n","         0.0891, 0.0891, 0.0962, 0.0962, 0.0962, 0.1054, 0.1054, 0.1054]),\n"," 965: tensor([0.0572, 0.0690, 0.1132, 0.1091, 0.1826]),\n"," 966: tensor([0.0534, 0.0555, 0.0490, 0.0925, 0.1240, 0.0836, 0.1048, 0.1048, 0.1048,\n","         0.1240, 0.1240, 0.1240]),\n"," 967: tensor([0.0426, 0.0472, 0.0791, 0.0772, 0.1443, 0.1581, 0.1250]),\n"," 968: tensor([0.0389, 0.0259, 0.0449, 0.0591, 0.1005, 0.1140, 0.0953, 0.1231, 0.0909,\n","         0.1348]),\n"," 969: tensor([0.0339, 0.0483, 0.0524, 0.0654, 0.0836, 0.0769, 0.1048, 0.0836, 0.1132,\n","         0.1240, 0.1048, 0.1240]),\n"," 970: tensor([0.0386, 0.0529, 0.0398, 0.0546, 0.0891, 0.0772, 0.0772, 0.0772, 0.0891,\n","         0.0976, 0.0772, 0.0976, 0.0825, 0.0825, 0.0976, 0.0891, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 971: tensor([0.0645, 0.0645, 0.0884, 0.0722, 0.1250, 0.1581, 0.1581]),\n"," 972: tensor([0.0976, 0.0945, 0.1336, 0.1195, 0.1195, 0.1336]),\n"," 973: tensor([0.0234, 0.0533, 0.0259, 0.0410, 0.0909, 0.1066, 0.1231, 0.1140, 0.1005,\n","         0.1348]),\n"," 974: tensor([0.0252, 0.0426, 0.1054, 0.0674, 0.1291, 0.0913, 0.1118, 0.1291, 0.1414]),\n"," 975: tensor([0.0225, 0.1179, 0.1005, 0.0962, 0.0962, 0.1260, 0.1491, 0.1491]),\n"," 976: tensor([0.0203, 0.0909, 0.0836, 0.0754, 0.1231, 0.1348, 0.1231, 0.1231, 0.1348,\n","         0.1348]),\n"," 977: tensor([0.0674, 0.0707, 0.0816, 0.0745, 0.1054, 0.1118, 0.1291, 0.1414, 0.1291]),\n"," 978: tensor([0.0415, 0.1054, 0.1118, 0.1118]),\n"," 979: tensor([0.0981, 0.0605, 0.0578, 0.0925, 0.0877, 0.0741, 0.1132, 0.1240, 0.1132,\n","         0.0925, 0.1132, 0.1132]),\n"," 980: tensor([0.0505, 0.0458, 0.0613, 0.0845, 0.0714, 0.1010, 0.1091, 0.0806, 0.0945,\n","         0.1091, 0.0945, 0.1195, 0.1195]),\n"," 981: tensor([0.0587, 0.0535, 0.0845, 0.0816, 0.0953, 0.1195, 0.1195, 0.1414, 0.1414]),\n"," 982: tensor([0.0630, 0.0891, 0.1179, 0.0833, 0.1005, 0.1005, 0.1361, 0.1491]),\n"," 983: tensor([0.0289, 0.0417, 0.0727, 0.1260, 0.1260, 0.1179, 0.1179, 0.1361]),\n"," 984: tensor([0.0786, 0.0711, 0.0375, 0.0711, 0.1179, 0.1179, 0.0925, 0.1491]),\n"," 985: tensor([0.0756, 0.0806, 0.0825, 0.1195, 0.1543, 0.1543]),\n"," 986: tensor([0.0654, 0.0695, 0.1111, 0.0833, 0.1260, 0.1361, 0.1260, 0.1491]),\n"," 987: tensor([0.0556, 0.0700, 0.0772, 0.0722, 0.0962, 0.0772, 0.1021, 0.1291, 0.1091,\n","         0.1179, 0.1291]),\n"," 988: tensor([0.0533, 0.0913, 0.1250, 0.0857, 0.1581, 0.1179, 0.1443]),\n"," 989: tensor([0.0510, 0.0801, 0.1021, 0.0870, 0.1021, 0.0962, 0.1179, 0.1179, 0.1091,\n","         0.1091, 0.1291]),\n"," 990: tensor([0.0267, 0.0557, 0.0714, 0.0845, 0.0690, 0.0845, 0.0945, 0.1195, 0.1010,\n","         0.0891, 0.1091, 0.1091, 0.1195]),\n"," 991: tensor([0.0722, 0.0645, 0.0630, 0.0833, 0.0962, 0.0772, 0.1021, 0.1179, 0.1291,\n","         0.1291, 0.1179]),\n"," 992: tensor([0.0765, 0.1005, 0.0833, 0.1179, 0.1179, 0.1491, 0.1491, 0.1491]),\n"," 993: tensor([0.0327, 0.0533, 0.0870, 0.0754, 0.0909, 0.1005, 0.1005, 0.1231, 0.1348,\n","         0.1348]),\n"," 994: tensor([0.0510, 0.0754, 0.0754, 0.0778, 0.0836, 0.0870, 0.1066, 0.1231, 0.1348,\n","         0.1348]),\n"," 995: tensor([0.0392, 0.0769, 0.0620, 0.0836, 0.0836, 0.0981, 0.0877, 0.1048, 0.1240,\n","         0.1240, 0.0981, 0.1240]),\n"," 996: tensor([0.0501, 0.0488, 0.0398, 0.0727, 0.0605, 0.0583, 0.0727, 0.0976, 0.0630,\n","         0.0976, 0.0825, 0.0976, 0.0825, 0.0772, 0.0976, 0.0976, 0.0976, 0.0976,\n","         0.0976, 0.0976]),\n"," 997: tensor([0.0572, 0.0350, 0.1091, 0.0870, 0.1826]),\n"," 998: tensor([0.0333, 0.0891, 0.0654, 0.0745, 0.1361, 0.1491, 0.1491, 0.1491]),\n"," 999: tensor([0.0609, 0.0833, 0.1005, 0.0833, 0.1260, 0.1005, 0.1361, 0.1491]),\n"," ...}"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"UzjNLKBj6cdN"},"source":["# try"]},{"cell_type":"code","metadata":{"id":"0v5ybCqk6cdO"},"source":["output = DrBC_module(trainDatas[0])\n","trues = trainDatas[0].scoreList\n","loss = lossfun(output, trues)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJnYy-Xj6cdO","outputId":"d067ae63-b088-402f-8f01-3c639852228b"},"source":["loss"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[214.4099]], device='cuda:0', grad_fn=<MulBackward0>)"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"e9KDXOD66cdO"},"source":["loss.backward()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyIRe7Mc6cdO","outputId":"9d8acb2e-bf75-4887-8bd9-6662f0b55234"},"source":["list(DrBC_module.parameters())[20].grad"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.4153,  4.5197,  0.0918,  ...,  0.0864,  0.3594,  4.6415],\n","        ...,\n","        [-0.5673, -6.7819, -0.1336,  ..., -0.1331, -0.5012, -6.9675],\n","        [-0.0663, -1.4174, -0.0211,  ..., -0.0273, -0.0702, -1.4608],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","       device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"id":"KaAJyav36cdO","outputId":"670f424b-5c7b-4ceb-c67f-6b18b8b2b90a"},"source":["x = torch.tensor([5])\n","x.item()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"hOSLCURs6cdP"},"source":["importlib.reload(Dm)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_36A1K08jnz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MV-wwpM88jsq"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","DrBC_module = Dm.DrBC_module(Layer=5, device=device).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m16ukb_68jvX","executionInfo":{"elapsed":1434,"status":"ok","timestamp":1615879994333,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"fa25dcac-d7b6-4abc-c411-6c71eebfd823"},"source":["DrBC_module.load_state_dict(torch.load('./modules/5_Layer_5000_point/DrBC_5Layer.pt'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Z0DbQzRp8wet"},"source":["D = torch.load('./ff.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiHFYX998wrD"},"source":["myG = fc.myGraph()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zV1KsuaZ8wtz"},"source":["myG.scoreList = D['betweenness_vec'].T.tolist()[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UROvj9C8wy9"},"source":["adj = D['adjacency_matrix']\n","myG.nodeDict = {}\n","for i in range(adj.shape[0]):\n","    c = []\n","    for j in range(adj.shape[1]):\n","        if adj[i, j] == 1.:\n","            c.append(j)\n","    myG.nodeDict[i] = c"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xfjoouQm9MMm"},"source":["myG.degreeCoeffient = D['neighbor_matrix']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEsD59P29gh8","executionInfo":{"elapsed":1300,"status":"ok","timestamp":1615880455314,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"6ab67405-d447-4467-89f5-9aa65f5ca4e2"},"source":["output = DrBC_module(myG)\n","output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5000, 1])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIBN6fbt-CMK","executionInfo":{"elapsed":675,"status":"ok","timestamp":1615880653164,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"124d88e9-d497-4ac8-c1fb-72299bbb657c"},"source":["pred = output.cpu().detach()[:, 0]\n","truths = np.array(myG.scoreList)\n","accuracy = func.top_n_accuracy(pred, truths, n=250)\n","accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NyBUR7v-9RD","executionInfo":{"elapsed":647,"status":"ok","timestamp":1615880751829,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"37ebe572-d1d0-4f6d-efb3-84989d6f64a6"},"source":["torch.sum(adj[0, :]), torch.sum(adj.T[0, :])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(138.), tensor(138.))"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"YJ0R-n7i_v8U"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"NZV2GC5h6ySP","executionInfo":{"elapsed":2093,"status":"ok","timestamp":1615963431525,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"cb21119e-aab2-4fe6-dfdb-701c33ff87db"},"source":["os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TUk_TWRR7RoG","executionInfo":{"elapsed":1513,"status":"ok","timestamp":1615965867337,"user":{"displayName":"汪玄同","photoUrl":"","userId":"02762474676861075463"},"user_tz":-480},"outputId":"6a7dc723-f280-4d43-f960-d32aa02995f2"},"source":["os.listdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'gdrive', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"rjv8As3wEkcs"},"source":[""],"execution_count":null,"outputs":[]}]}